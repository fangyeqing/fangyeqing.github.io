<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
    
    <entry>
      <title><![CDATA[Vmware虚拟机安装Ubuntu]]></title>
      <url>https://fangyeqing.github.io/2017/02/10/Vmware%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AE%89%E8%A3%85Ubuntu/</url>
      <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br>最近有一个项目，在windows下开发实在搞不定了，就用虚拟机装了个桌面版的linux-ubuntu，折腾了一天。</excerpt></p>
<h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p>ubuntu下载地址：<a href="http://cn.ubuntu.com/download/" target="_blank" rel="external">http://cn.ubuntu.com/download/</a><br>版本：<a href="http://releases.ubuntu.com/16.04/ubuntu-16.04-desktop-amd64.iso" target="_blank" rel="external">Ubuntu 16.04 LTS(长期支持)版本</a>  </p>
<p>VMware下载地址：<br><a href="https://www.ruooo.com/software/852.html" target="_blank" rel="external">VMware v12.1.0 简体中文精简特别版</a><br><a id="more"></a>  </p>
<the rest="" of="" contents="" |="" 余下全文=""> 

<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>打开VMware</p>
<h3 id="创建虚拟机"><a href="#创建虚拟机" class="headerlink" title="创建虚拟机"></a>创建虚拟机</h3><ul>
<li>创建新的虚拟机</li>
<li>选择典型(推荐)</li>
<li>浏览本地刚下载的Ubuntu镜像</li>
<li>输入linux名、用户名、密码</li>
<li>输入虚拟机名称、位置</li>
<li>指定虚拟机磁盘大小，64位建议20G，磁盘存储为单个文件</li>
<li>创建完成</li>
</ul>
<p>出现问题：</p>
<blockquote>
<p>已将虚拟机配置为使用64位客户机操作系统。但是，无法执行64位操作<br>此主机支持 Intel VT-x，但 Intel VT-x 处于禁用状态。</p>
</blockquote>
<p>解决：支持虚拟化  </p>
<ul>
<li>进入BIOS，其中联想为F2</li>
<li>Configuration</li>
<li>Intel Virtual Technology设置为Enabled</li>
<li>F10保存并退出</li>
</ul>
<h3 id="安装操作系统"><a href="#安装操作系统" class="headerlink" title="安装操作系统"></a>安装操作系统</h3><ul>
<li>虚拟机开机后，会自动进行 Ubuntu 的安装。</li>
<li>安装完成后，虚拟机会自动重启</li>
<li>使用刚才设置的密码进入系统</li>
</ul>
<h3 id="更改系统设置"><a href="#更改系统设置" class="headerlink" title="更改系统设置"></a>更改系统设置</h3><p>右上角“设置”按钮</p>
<h4 id="系统下载设置"><a href="#系统下载设置" class="headerlink" title="系统下载设置"></a>系统下载设置</h4><ul>
<li>选择「System Settings」</li>
<li>选择「Software &amp; Updates」</li>
<li>下载服务器选择 「other」，然后选择中国地区服务器，选择China-mirrors.aliyun.com</li>
</ul>
<h4 id="语言设置"><a href="#语言设置" class="headerlink" title="语言设置"></a>语言设置</h4><ul>
<li>选择「Language Support」</li>
<li>弹出窗口“The language support is not installed completely”，选择「Install」安装</li>
<li>Install/Remove Lauguages</li>
<li>选择Chinese(simplified)并Apply</li>
<li>用鼠标将简体中文拖动到语言列表最顶端，然后「Apply System-Wide」</li>
<li>右上角设置-log out再重新进入系统才会生效</li>
</ul>
<h3 id="安装-VMware-Tools"><a href="#安装-VMware-Tools" class="headerlink" title="安装 VMware Tools"></a>安装 VMware Tools</h3><p>只有在VMware虚拟机中安装好了VMware Tools，才能实现主机与虚拟机之间的文件共享，同时可支持自由拖拽的功能，鼠标也可在虚拟机与主机之前自由移动（不用再按ctrl+alt），且虚拟机屏幕也可实现全屏化</p>
<p>系统会自动进行 VMware Tools 的安装，如果没有自动安装的话，选择 VMware 工具栏的「虚拟机」→「安装 VMware Tools」，Ubuntu 会自动弹出 VMware Tools 的安装文件夹。但是这种我试了下，速度太慢了，后来直接手动安装。</p>
<p>下载<a href="http://pan.baidu.com/s/1hrLC0ja" target="_blank" rel="external">VMwareTools-10.0.10-4301679.tar.gz 密码:3nb1</a>，下载内容放/Home<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">tar -zxvf VMwareTools-10.0.10-4301679.tar.gz</div><div class="line">cd vmware-tools-distrib/</div><div class="line">sudo su              # 切换到root用户</div><div class="line">./vmware-install.pl  # 一路的回车确认至出现Enjoy</div></pre></td></tr></table></figure></p>
<p>安装完成后「虚拟机」→「安装 VMware Tools」变为「重新安装 VMware Tools」，说明安装成功。</p>
<p>设置–系统设置–显示–分辨率调大到适合值–应用–WMware主界面进入全屏模式</p>
<h3 id="虚拟机联网模式"><a href="#虚拟机联网模式" class="headerlink" title="虚拟机联网模式"></a>虚拟机联网模式</h3><p>VMWare虚拟机分为三种网络模式，具体参见<a href="http://blog.csdn.net/leexide/article/details/17199083" target="_blank" rel="external">博客</a></p>
<ul>
<li>bridged(桥接模式)。</li>
<li>NAT(网络地址转换模式)。</li>
<li>host-only(主机模式)。  </li>
</ul>
<p>在虚拟系统中不用进行任何手工配置就能直接访问互联网，建议采用NAT模式。</p>
<h4 id="NAT模式联网支持域名解析"><a href="#NAT模式联网支持域名解析" class="headerlink" title="NAT模式联网支持域名解析"></a>NAT模式联网支持域名解析</h4><p>首先，在Windows中确认“VMware DHCP Service”和“VMware NAT Service”已正常启动<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cmd</div><div class="line">services.msc</div></pre></td></tr></table></figure></p>
<p>WMware顶部–编辑–虚拟网络编辑器—选中VMnet8点“NAT设置”—将里面显示的网关地址记录，例如：192.168.184.2—然后编辑<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo vi /etc/resolv.conf</div><div class="line">#加入内容</div><div class="line">nameserver 192.168.184.2</div></pre></td></tr></table></figure></p>
<p>然后就可以<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ping baidu.com</div></pre></td></tr></table></figure></p>
<p>可以解决在python程序中遇到的如下问题</p>
<blockquote>
<p>ERROR:root:<urlopen error="" [errno="" -3]="" temporary="" failure="" in="" name="" resolution=""></urlopen></p>
</blockquote>
<h3 id="安装常用软件"><a href="#安装常用软件" class="headerlink" title="安装常用软件"></a>安装常用软件</h3><p>编辑器<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo update-alternatives --config editor    # 默认为nano，替换为vim</div></pre></td></tr></table></figure></p>
<p>git<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt install git</div></pre></td></tr></table></figure></p>
<p>java<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sudo apt-get update</div><div class="line">sudo apt-get install openjdk-8-jdk</div></pre></td></tr></table></figure></p>
<p>python环境：自带<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">python  #2.7.12</div><div class="line">python3  #3.5.2</div></pre></td></tr></table></figure></p>
<p><a href="https://www.jetbrains.com/pycharm/download/#section=linux" target="_blank" rel="external">pycharm</a>:安装免费的社区版，下载好包自己装<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">tar -zxvf pycharm-community-2016.3.2.tar.gz</div><div class="line">cd pycharm-community-2016.3.2/</div><div class="line">bin/pycharm.sh</div></pre></td></tr></table></figure></p>
<p>pycharm以root身份启动，不然每次pip安装东西都要输密码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sudo apt install gksu  #sudogk：与sudo类似，只是sudo用于命令行，sudogk用于GUI</div><div class="line">vi ~/.local/share/applications/jetbrains-pycharm-ce.desktop</div></pre></td></tr></table></figure></p>
<p>修改desktop文件内容如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">[Desktop Entry]</div><div class="line">Version=1.0</div><div class="line">Type=Application</div><div class="line">Name=PyCharm Community Edition</div><div class="line">Icon=/home/fyq/coding/pycharm-community-2016.3.2/bin/pycharm.png</div><div class="line">Exec=gksudo -k -u root &quot;/home/fyq/coding/pycharm-community-2016.3.2/bin/pycharm.sh&quot; %f</div><div class="line">Comment=The Drive to Develop</div><div class="line">Categories=Development;IDE;</div><div class="line">Terminal=false</div><div class="line">StartupWMClass=jetbrains-pycharm-ce</div></pre></td></tr></table></figure></p>
<p>其实点击图标就是执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">gksudo -k -u root /home/fyq/coding/pycharm-community-2016.3.2/bin/pycharm.sh</div></pre></td></tr></table></figure></p>
<p>快捷键与ubuntu的GNOME桌面的冲突<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Files--Settings---Keymap---Default for DNOMe</div></pre></td></tr></table></figure></p>
<p>其中，前进后退变成：Alt+Shift+方向左右键</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://www.jianshu.com/p/3379892948da" target="_blank" rel="external">简书：VMware 虚拟机安装 Ubuntu 简单教程</a><br><a href="http://www.kali.org.cn/thread-22929-1-1.html" target="_blank" rel="external">VMware tools安装</a><br><a href="https://www.tlanyan.me/work-with-linux-without-root-permission/" target="_blank" rel="external">linux下非root用户安装软件入门</a><br><a href="http://blog.sina.com.cn/s/blog_828e50020101e81i.html" target="_blank" rel="external">让vmware（开启nat模式）中的linux虚拟机支持域名解析功能</a></p>
</the>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[spark---RDD]]></title>
      <url>https://fangyeqing.github.io/2017/01/08/spark---RDD/</url>
      <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br>现有的数据流系统（例如MapReduce）需要将数据输出到磁盘，然后在每次查询时重新加载，这带来较大的开销。因此，对以下两种应用的处理并不高效：</excerpt></p>
<ul>
<li>迭代算法，图算法等需要重复利用数据的应用类型</li>
<li>交互式数据挖掘工具，用户反复查询一个数据子集</li>
</ul>
<p>RDD针对上述情况，有一些改进：</p>
<a id="more"></a>  
<the rest="" of="" contents="" |="" 余下全文=""> 

<h2 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a>RDD</h2><p>现有的数据流系统（例如MapReduce）需要将数据输出到磁盘，然后在每次查询时重新加载，这带来较大的开销。因此，对以下两种应用的处理并不高效：</p>
<ul>
<li>迭代算法，图算法等需要重复利用数据的应用类型</li>
<li>交互式数据挖掘工具，用户反复查询一个数据子集</li>
</ul>
<p>RDD针对上述情况，有一些改进：</p>
<ul>
<li>RDD可以被cache在内存中。这种机制无疑可以简单有效地解决MapReduce在迭代计算时反复读取写出磁盘的问题，但同时大大增大了内存开销。</li>
<li>RDD帮助Fault Recovery. RDD可存储lineage信息来重建lost partitions. 比如记录RDD的转化过程。MapReduce采用的是checkpointing机制，代价要大很多。</li>
<li>RDD是一个logical单元，甚至不需要实例化，而只需包含从磁盘重建workset的信息。</li>
</ul>
<h2 id="RDD组成"><a href="#RDD组成" class="headerlink" title="RDD组成"></a>RDD组成</h2><p>RDD，弹性分布式数据集。是设计用来表示数据集的一种数据结构。为了让 RDD 能 handle 更多的问题，规定 RDD 应该是只读的，分区记录的一种数据集合。</p>
<p>每个RDD都包含：</p>
<ul>
<li>一组RDD分区（partition），即数据集的原子组成部分</li>
<li>一个函数，即在父RDD上执行何种计算；</li>
<li>对父RDD的一组依赖，这些依赖描述了RDD的Lineage</li>
<li>元数据，描述分区模式和数据存放的位置，可选择的。</li>
<li>一个对于key-value类型的RDD的Partitioner，可选择的。</li>
</ul>
<p>例如，一个表示HDFS文件的RDD包含：各个数据块的一个分区，并知道各个数据块放在哪些节点上。而且这个RDD上的map操作结果也具有同样的分区，map函数是在父数据上执行的。</p>
<h2 id="RDD-产生"><a href="#RDD-产生" class="headerlink" title="RDD 产生"></a>RDD 产生</h2><p>RDD产生有两种方式：</p>
<ul>
<li>通过集合类生成：sc.parallelize。把 driver 端定义的一个数据集，或者一个获取数据集的生成器，分发到 worker 上的 executor 中，以供后续分析。这种方式在测试代码逻辑时经常用到。</li>
<li>从数据源读取：本地文件，HDFS(hdfs://), Cassandra, HBase, Amazon S3(s3n://)等<ul>
<li>文本文件：textFile方法</li>
<li>SequenceFiles： sequenceFile[K, V]方法读取</li>
<li>其他Hadoop输入格式：hadoopRDD方法  </li>
</ul>
</li>
</ul>
<p>RDD保存：  </p>
<ul>
<li>文本：JavaRDD.saveAsTextFile。<ul>
<li>会按照执行task的多少生成多少个文件，比如part-00000到part-0000n，n是task的个数，亦是最后的stage的分区数。coalesce可以调整生成的文件数。</li>
</ul>
</li>
<li>对象：JavaRDD.saveAsObjectFile、JavaSparkContext.objectFile</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">public class RDDInit &#123;</div><div class="line">    public static void main(String[] args) &#123;</div><div class="line">        SparkConf conf = new SparkConf().setAppName(&quot;RDDInit&quot;).setMaster(&quot;local&quot;).set(&quot;spark.some.config&quot;,&quot;forRunInYarn&quot;);</div><div class="line">        JavaSparkContext sc = new JavaSparkContext(conf);</div><div class="line">        //RDD生成</div><div class="line">        List&lt;Integer&gt; data = Arrays.asList(1, 2, 3, 4, 5);</div><div class="line">        JavaRDD&lt;Integer&gt; distData = sc.parallelize(data);</div><div class="line">        System.out.println(distData.take(5));</div><div class="line">        //RDD保存</div><div class="line">        distData.coalesce(1).saveAsTextFile(&quot;output/RDDWordCount/textFile&quot;);</div><div class="line">        distData.saveAsObjectFile(&quot;output/RDDWordCount/object&quot;);</div><div class="line">        //读取保存的RDD</div><div class="line">        JavaRDD&lt;Integer&gt; readObject = sc.objectFile(&quot;output/RDDWordCount/object/part-00000&quot;);</div><div class="line">        System.out.println(readObject.take(3));</div><div class="line">        sc.stop();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="RDD-操作"><a href="#RDD-操作" class="headerlink" title="RDD 操作"></a>RDD 操作</h2><h3 id="两类算子"><a href="#两类算子" class="headerlink" title="两类算子"></a>两类算子</h3><p>RDD存在两类算子:</p>
<ul>
<li>transformation,主要是用于对RDD进行数据转换，生成一个新的RDD。包括：map, flatMap, filter, union, sample, join, groupByKey, cogroup, ReduceByKey, cros, sortByKey, mapValues等</li>
<li>action，是要将转换好的RDD再转换成原始数据。 包括：collect（返回元素本身）, reduce, count（返回RDD中的元素个数）, save（将RDD输出到存储系统）,first，take， lookupKey等。 </li>
</ul>
<h3 id="惰性运算"><a href="#惰性运算" class="headerlink" title="惰性运算"></a>惰性运算</h3><p>spark运算是一种懒惰运算，其程序执行逻辑是：</p>
<ul>
<li>对于一系列transformation算子，在遇到action算子之前，这些transformation是不会执行的，而会生成一个运算逻辑图。  </li>
<li>当遇到一个action算子的时候，才根据前面的运算逻辑图执行程序。  </li>
<li>这样如果有台机器宕机了之后，只需要根据逻辑图将宕机中的RDD进行重新计算就可以了（窄依赖的情况下，宽依赖的情况下计算代价要更高。）</li>
</ul>
<p>下面有一个求所有字符长度的例子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">/**</div><div class="line"> * length count:所有字符的length</div><div class="line"> */</div><div class="line">//生成RDD</div><div class="line">List&lt;String&gt; data = Arrays.asList(&quot;hello world&quot;, &quot;hello spark&quot;,&quot;hello rdd&quot;, &quot;hello spark rdd&quot;);</div><div class="line">JavaRDD&lt;String&gt; lines = sc.parallelize(data);</div><div class="line">//transformation算子</div><div class="line">JavaRDD&lt;Integer&gt; lineLengths = lines.map(s -&gt; s.length());</div><div class="line">//action算子</div><div class="line">int totalLength = lineLengths.reduce((a, b) -&gt; a + b);</div><div class="line">System.out.println(totalLength);//输出：46</div></pre></td></tr></table></figure></p>
<h2 id="RDD关系"><a href="#RDD关系" class="headerlink" title="RDD关系"></a>RDD关系</h2><h3 id="DAG有向无环图"><a href="#DAG有向无环图" class="headerlink" title="DAG有向无环图"></a>DAG有向无环图</h3><p>DAG - Direct Acyclic Graph，有向无环图。假设图二中的A,B,C,D,E都代表spark里不同的RDD。 </p>
<p><img src="http://note.youdao.com/yws/public/resource/efa1b55d3bb99ae353eb25a3f422bc8c/xmlnote/9527EAE7B4204B02A3994CE89748115C/28417" alt="image">    </p>
<p>说明：</p>
<ul>
<li>图：图是表达RDD Lineage信息的一个结构。在spark中，大部分 RDD 都是通过其他 RDD 进行转换而来的，比如说图二中，B和D都是通过A转换而来的，而C是通过B转换而来，E的话是通过B和D一起转换来的。</li>
<li>有向：有向就更容易理解了，简单来说就是 lineage 是一个 top-down 的结构，而且是时间序列上的 top-down 结构。一个时间上的先来后到，即祖先与子孙的关系，是不可逆的。</li>
<li>无环：spark 的优化器在这里也发挥了很大的作用。假设有图三中左下 B,D,E 这样一个 RDD 转换图，那当我们的需要执行 D.collect 操作的时候，就会引发一个死循环了。</li>
</ul>
<h3 id="RDD依赖"><a href="#RDD依赖" class="headerlink" title="RDD依赖"></a>RDD依赖</h3><p>依赖主要分为两类：窄依赖和宽依赖。</p>
<table>
<thead>
<tr>
<th>对比项</th>
<th>窄依赖</th>
<th>宽依赖</th>
</tr>
</thead>
<tbody>
<tr>
<td>定义</td>
<td>子RDD的每个分区依赖于常数个父分区（即与数据规模无关）</td>
<td>子RDD的每个分区依赖于所有父RDD分区</td>
</tr>
<tr>
<td>举例</td>
<td>逐个元素地执行map、然后filter操作</td>
<td>部分join，需要shuffle的依赖，与MapReduce类似</td>
</tr>
<tr>
<td>计算</td>
<td>可以在某一个计算节点上直接通过父RDD的某几块数据（通常是一块）计算得到子RDD某一块的数据</td>
<td>子RDD某一块数据的计算必须等到它的父RDD所有数据都计算完成之后才可以进行，而且需要对父RDD的计算结果进行hash并传递到对应的节点之上</td>
</tr>
<tr>
<td>容错性</td>
<td>当父RDD的某分片丢失时，只有丢失的那一块数据需要被重新计算</td>
<td>当父RDD的某分片丢失时，需要把父RDD的所有分区数据重新计算一次，计算量明显比窄依赖情况下大很多</td>
</tr>
</tbody>
</table>
<p>如下图：方框表示RDD，实心矩形表示分区<br><img src="http://note.youdao.com/yws/public/resource/efa1b55d3bb99ae353eb25a3f422bc8c/xmlnote/50D165CF707E4C1BB08B4F6C183A894A/28451" alt="image">  </p>
<ul>
<li>对于map和filter形式的转换来说，它们只是将Partition的数据根据转换的规则进行转化，并不涉及其他的处理，可以简单地认为只是将数据从一个形式转换到另一个形式。</li>
<li>对于union，只是将多个RDD合并成一个，parent RDD的Partition(s)不会有任何的变化，可以认为只是把parent RDD的Partition(s)简单进行复制与合并。</li>
<li>对于join，如果每个Partition仅仅和已知的、特定的Partition进行join，那么这个依赖关系也是窄依赖。对于这种有规则的数据的join，并不会引入昂贵的Shuffle。对于窄依赖，由于RDD每个Partition依赖固定数量的parent RDD(s)的Partition(s)，因此可以通过一个计算任务来处理这些Partition，并且这些Partition相互独立，这些计算任务也就可以并行执行了。</li>
<li>对于groupByKey，子RDD的所有Partition(s)会依赖于parent RDD的所有Partition(s)，子RDD的Partition是parent RDD的所有Partition Shuffle的结果，因此这两个RDD是不能通过一个计算任务来完成的。同样，对于需要parent RDD的所有Partition进行join的转换，也是需要Shuffle，这类join的依赖就是宽依赖而不是前面提到的窄依赖了。</li>
</ul>
<h2 id="任务调度"><a href="#任务调度" class="headerlink" title="任务调度"></a>任务调度</h2><p>Spark调度器根据目标RDD的Lineage图创建一个由stage构成的无回路有向图（DAG）。每个stage内部尽可能多地包含一组具有窄依赖关系的转换，并将它们流水线并行化（pipeline）。stage的边界有两种情况：一是宽依赖上的Shuffle操作；二是已缓存分区，它可以缩短父RDD的计算过程。</p>
<p><img src="http://note.youdao.com/yws/public/resource/efa1b55d3bb99ae353eb25a3f422bc8c/xmlnote/D94936A5CC8044D7A95A59A7E9E0830D/28487" alt="image"></p>
<p>实线方框表示RDD，实心矩形表示分区（黑色表示该分区被缓存）。要在RDD G上执行一个动作，调度器根据宽依赖创建一组stage，并在每个stage内部将具有窄依赖的转换流水线化（pipeline）。 本例不用再执行stage 1，因为B已经存在于缓存中了，所以只需要运行2和3。</p>
<h2 id="故障恢复"><a href="#故障恢复" class="headerlink" title="故障恢复"></a>故障恢复</h2><p>Spark故障恢复提供两种方式</p>
<ul>
<li>Linage：通过数据的血缘关系，再执行一遍前面的处理</li>
<li>Checkpoint：Lineage链较长、宽依赖的RDD需要采用检查点机制。将数据集存储到持久存储中。</li>
</ul>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://litaotao.github.io/spark-what-is-rdd" target="_blank" rel="external">博客：spark 之 RDD</a>  </p>
<p><a href="http://shiyanjun.cn/archives/744.html" target="_blank" rel="external">博客：RDD论文中文版</a>  </p>
<p><a href="https://www.zhihu.com/question/26568496" target="_blank" rel="external">知乎：与 Hadoop 对比，如何看待 Spark 技术？</a></p>
<p><a href="http://www.cnblogs.com/zlslch/p/5723403.html" target="_blank" rel="external">博客：RDD依赖关系</a></p>
<p><a href="https://github.com/JerryLead/SparkInternals/blob/master/markdown/2-JobLogicalPlan.md" target="_blank" rel="external">博客：Job 逻辑执行图</a></p>
</the>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[spark---hello spark java版]]></title>
      <url>https://fangyeqing.github.io/2017/01/07/spark---hello_spark_java%E7%89%88/</url>
      <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br>看了几个spark入门，大都是linux环境下scala和python版本的。自己在windows下折腾了一番才跑通，还是觉得有必要写一个windows/java版本的，希望对有相同需求的人有所帮助。</excerpt></p>
<p>由于开发在windows下进行，提交任务时在线上linux集群。需要配置linux线上环境和window的开发环境。各种版本如下：</p>
<ul>
<li>spark版本：spark-2.1.0</li>
<li>hadoop版本：hadoop-2.7.3</li>
<li>jdk版本：1.8.0_65</li>
</ul>
<a id="more"></a>  
<the rest="" of="" contents="" |="" 余下全文=""> 

<h2 id="linux下配置"><a href="#linux下配置" class="headerlink" title="linux下配置"></a>linux下配置</h2><h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><p><a href="http://spark.apache.org/downloads.html" target="_blank" rel="external">spark官网</a>、<a href="http://hadoop.apache.org/" target="_blank" rel="external">hadoop官网</a>找到下载链接，下载<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">wget http://d3kbcqa49mib13.cloudfront.net/spark-2.1.0-bin-hadoop2.7.tgz</div><div class="line">tar -zxvf spark-2.1.0-bin-hadoop2.7.tgz</div><div class="line"></div><div class="line">wget http://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-2.7.3/hadoop-2.7.3.tar.gz </div><div class="line">tar -zxvf hadoop-2.7.3.tar.gz</div></pre></td></tr></table></figure></p>
<h3 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h3><p>环境变量设置，修改~/.bash_profile<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"># spark</div><div class="line">export SPARK_HOME=/disk2/fangyq/test/spark-2.1.0-bin-hadoop2.7</div><div class="line">export PATH=$SPARK_HOME/bin:$PATH</div><div class="line"># hadoop</div><div class="line">export HADOOP_HOME=/disk2/fangyq/test/hadoop-2.7.3</div><div class="line">export HADOOP_CONF_DIR=/home/fangyeqing/hadoop-conf</div><div class="line">export PATH=$PATH:$HADOOP_HOME/bin</div><div class="line">export HADOOP_CLASSPATH=$JAVA_HOME/lib/tools.jar</div></pre></td></tr></table></figure></p>
<h3 id="日志配置"><a href="#日志配置" class="headerlink" title="日志配置"></a>日志配置</h3><p>配置日志输出：编辑log4j文件，将log4j.rootCategory由INFO改为WARN，不然日志非常多<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">cd spark-2.1.0-bin-hadoop2.7.tgz</div><div class="line">cp conf/log4j.properties.template conf/log4j.properties</div><div class="line">vi log4j.properties</div><div class="line"></div><div class="line">log4j.rootCategory=WARN, console</div></pre></td></tr></table></figure></p>
<h4 id="错误说明"><a href="#错误说明" class="headerlink" title="错误说明"></a>错误说明</h4><p>如果需要以yarn模式运行，没配置HADOOP_CONF_DIR会出现如下错误</p>
<blockquote>
<p>Exception in thread “main” java.lang.Exception: When running with master ‘yarn-client’ either HADOOP_CONF_DIR or YARN_CONF_DIR must be set in the environment.</p>
</blockquote>
<h2 id="windows下开发设置"><a href="#windows下开发设置" class="headerlink" title="windows下开发设置"></a>windows下开发设置</h2><h3 id="下载-1"><a href="#下载-1" class="headerlink" title="下载"></a>下载</h3><p>spark下载：<a href="http://spark.apache.org/downloads.html" target="_blank" rel="external">官网地址</a>，其中spark-2.1.0-bin-hadoop2.7.tgz<a href="http://d3kbcqa49mib13.cloudfront.net/spark-2.1.0-bin-hadoop2.7.tgz" target="_blank" rel="external">下载地址</a><br>hadoop下载：<a href="http://hadoop.apache.org/releases.html" target="_blank" rel="external">官网地址</a>，其中hadoop-2.7.3.tar.gz<a href="http://d3kbcqa49mib13.cloudfront.net/spark-2.0.2-bin-hadoop2.7.tgz" target="_blank" rel="external">下载地址</a><br>winutils下载：<a href="https://github.com/steveloughran/winutils" target="_blank" rel="external">github地址</a>，找到对应hadoop版本的，hadoop2.7.3用2.7.1的也可以。将winutils放在hadoop的bin目录下。<br>hadoop.dll下载：<a href="https://github.com/steveloughran/winutils/tree/master/hadoop-2.7.1/bin" target="_blank" rel="external">github地址</a>，同样放在hadoop的bin目录下。（跑hadoop任务需要，只跑spark不需要，看需下载）</p>
<h3 id="环境变量-1"><a href="#环境变量-1" class="headerlink" title="环境变量"></a>环境变量</h3><p>设置环境变量，将代码中的spark_dir,hadoop_dir换成自己的安装路径。将以下内容保存为ANSI编码的spark-evn.bat文件,运行即可<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">@echo off</div><div class="line">color 02</div><div class="line"></div><div class="line">::设置spark安装路径，路径不能有空格</div><div class="line">set spark_dir=D:\spark\spark-2.1.0-bin-hadoop2.7</div><div class="line">set hadoop_dir=D:\spark\hadoop-2.7.3</div><div class="line"></div><div class="line">::环境变量如果有的话，先删除</div><div class="line">wmic ENVIRONMENT where &quot;name=&apos;SPARK_HOME&apos;&quot; delete</div><div class="line">wmic ENVIRONMENT where &quot;name=&apos;HADOOP_HOME&apos;&quot; delete</div><div class="line"></div><div class="line">::创建JAVA_HOME、HADOOP_HOME、PYTHONPATH</div><div class="line">wmic ENVIRONMENT create name=&quot;SPARK_HOME&quot;,username=&quot;&lt;system&gt;&quot;,VariableValue=&quot;%spark_dir%&quot;</div><div class="line">wmic ENVIRONMENT create name=&quot;HADOOP_HOME&quot;,username=&quot;&lt;system&gt;&quot;,VariableValue=&quot;%hadoop_dir%&quot;</div><div class="line"></div><div class="line">::设置Path环境变量</div><div class="line">call set xx=%spark_dir%\bin;%hadoop_dir%\bin;%Path%</div><div class="line">wmic ENVIRONMENT where &quot;name=&apos;Path&apos; and username=&apos;&lt;system&gt;&apos;&quot; set VariableValue=&quot;%xx%&quot;</div><div class="line"></div><div class="line">pause</div></pre></td></tr></table></figure></p>
<h2 id="hello-spark"><a href="#hello-spark" class="headerlink" title="hello spark"></a>hello spark</h2><p>在idea中，可以通过将之前修改完的log4j.properties拷贝到resources目录下过滤掉多余的日志。</p>
<p>本地运行时需要指定Master(“local”)。本例子是统计所有包含a或b的行。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">public class SimpleApp &#123;</div><div class="line">    public static void main(String[] args) &#123;</div><div class="line">        SparkConf conf = new SparkConf().setAppName(&quot;Simple Application&quot;).setMaster(&quot;local&quot;).set(&quot;spark.some.config&quot;,&quot;forRunInYarn&quot;);</div><div class="line">        JavaSparkContext sc = new JavaSparkContext(conf);</div><div class="line">        String path = &quot;file:///&quot;+System.getenv(&quot;SPARK_HOME&quot;)+&quot;/README.md&quot;;</div><div class="line">        </div><div class="line">        JavaRDD&lt;String&gt; logData = sc.textFile(path).cache();</div><div class="line">        long numAs = logData.filter(s -&gt; s.contains(&quot;a&quot;)).count();</div><div class="line">        long numBs = logData.filter(s -&gt; s.contains(&quot;b&quot;)).count();</div><div class="line">        System.out.println(&quot;Lines with a: &quot; + numAs + &quot;, lines with b: &quot; + numBs);</div><div class="line"></div><div class="line">        sc.stop();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>也可以打包之后运行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mvn package</div><div class="line">spark-submit --class &quot;com.fqy.spark.example.SimpleApp&quot; --master local target/xxxx-SNAPSHOT.jar</div></pre></td></tr></table></figure></p>
<h3 id="执行方式配置"><a href="#执行方式配置" class="headerlink" title="执行方式配置"></a>执行方式配置</h3><ul>
<li>程序内通过setMaster()指定，一般只有在idea中直接运行才这样设置。</li>
<li>spark-submit提交任务时，通过–master指定。如果不指定，程序里也没有setMaster()默认local模式。<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">spark-submit --master local</div><div class="line">spark-submit --master yarn --deploy-mode client</div></pre></td></tr></table></figure>
</li>
</ul>
<table>
<thead>
<tr>
<th>Master URL</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>local</td>
<td>local:1个线程，local[K]：K个线程，local[*]：与核心数相同的线程</td>
</tr>
<tr>
<td><a href="http://spark.apache.org/docs/latest/running-on-yarn.html" target="_blank" rel="external">yarn</a></td>
<td>通过–deploy-mode client/cluster指定工作模式</td>
</tr>
<tr>
<td>spark</td>
<td>Connect to the given Spark standalone cluster master</td>
</tr>
<tr>
<td>mesos</td>
<td>Connect to the given Mesos cluster</td>
</tr>
</tbody>
</table>
<p>spark on yarn说明：</p>
<ul>
<li>driver： 负责向YARN申请资源，并监督作业的运行情况</li>
<li>yarn-cluster: 适用于生产环境。driver运行在AM中。client可以离开。</li>
<li>yarn-client: 适用于交互和调试。driver运行在client中。client不能离开。</li>
</ul>
<h3 id="其他配置"><a href="#其他配置" class="headerlink" title="其他配置"></a>其他配置</h3><p>根据实际情况配置</p>
<table>
<thead>
<tr>
<th>配置名</th>
<th>默认值 </th>
</tr>
</thead>
<tbody>
<tr>
<td>spark.driver.cores</td>
<td>1</td>
</tr>
<tr>
<td>spark.driver.memory</td>
<td>1G</td>
</tr>
<tr>
<td>spark.executor.memory</td>
<td>1G</td>
</tr>
</tbody>
</table>
<h3 id="文件读取"><a href="#文件读取" class="headerlink" title="文件读取"></a>文件读取</h3><p>包括</p>
<ul>
<li>程序提交时额外的jar包通过–jar</li>
<li>程序内部使用的文件、数据来源等</li>
</ul>
<table>
<thead>
<tr>
<th>读取方式</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr>
<td>file:</td>
<td>file:///表示本地的路径</td>
</tr>
<tr>
<td>hdfs:,http:,https:,ftp:</td>
<td>表示从hdfs等读取</td>
</tr>
<tr>
<td>local:</td>
<td>表示从集群中的一台读取</td>
</tr>
</tbody>
</table>
<p>说明：支持*通配符</p>
<h3 id="maven依赖"><a href="#maven依赖" class="headerlink" title="maven依赖"></a>maven依赖</h3><p>没用到spark-sql的话可以不添加spark-sql<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">&lt;dependency&gt; &lt;!-- Spark dependency, _2.1x表示scala版本 --&gt;</div><div class="line">    &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;spark-core_2.11&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;2.1.0&lt;/version&gt;</div><div class="line">&lt;/dependency&gt;</div><div class="line"></div><div class="line">&lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-sql_2.11 --&gt;</div><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;spark-sql_2.11&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;2.1.0&lt;/version&gt;</div><div class="line">&lt;/dependency&gt;</div><div class="line"></div><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;org.scala-lang&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;scala-library&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;2.11.8&lt;/version&gt;</div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://spark.apache.org/" target="_blank" rel="external">spark官网</a><br><a href="http://www.codexiu.cn/spark/blog/14534/" target="_blank" rel="external">spark在windows下开发</a><br><a href="https://www.iteblog.com/archives/1223" target="_blank" rel="external">yarn-client和yarn-cluster区别</a></p>
</the>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[druid.io实践4---druid监控]]></title>
      <url>https://fangyeqing.github.io/2017/01/07/druid.io%E5%AE%9E%E8%B7%B54---druid%E7%9B%91%E6%8E%A7/</url>
      <content type="html"><![CDATA[<excerpt in="" index="" |="" 首页摘要="">   

<p>druid监控指标可以通过graphite-emitter插件很方便地直接发送到Graphite，再配合其他的展示和报警工具。</p>
<p>这里提供一个Graphite+Grafana+Seyren这三个开源框架的组合来监控druid的思路。<br><img src="http://note.youdao.com/yws/public/resource/32442f2d923ee4564e15f34e1a33fdd5/8B8C7A2657A947698CBE20E605EED648" alt="image"></p>
<a id="more"></a>  
<the rest="" of="" contents="" |="" 余下全文=""> 

<h2 id="Druid监控指标发送到Graphite"><a href="#Druid监控指标发送到Graphite" class="headerlink" title="Druid监控指标发送到Graphite"></a>Druid监控指标发送到Graphite</h2><p>Graphite是Python编写的、面向监控的工具， 是一个时间序列数据库，可以将数据可视化为图表的工具。</p>
<h3 id="添加依赖"><a href="#添加依赖" class="headerlink" title="添加依赖"></a>添加依赖</h3><p>添加至extensions<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">druid.extensions.loadList=[..., &quot;graphite-emitter&quot;]</div></pre></td></tr></table></figure></p>
<h3 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h3><p>修改druid节点启动配置_common/common.runtime.properties：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">druid.monitoring.monitors=[&quot;com.metamx.metrics.JvmMonitor&quot;]</div><div class="line">druid.emitter=composing</div><div class="line">druid.emitter.composing.emitters=[&quot;logging&quot;,&quot;graphite&quot;]</div><div class="line">druid.emitter.graphite.hostname=graphite.xxx.com</div><div class="line">druid.emitter.graphite.port=2004</div><div class="line">druid.emitter.graphite.eventConverter=&#123;&quot;type&quot;:&quot;whiteList&quot;, &quot;namespacePrefix&quot;: &quot;druid-graphite&quot;, &quot;ignoreHostname&quot;:false, &quot;ignoreServiceName&quot;:false, &quot;mapPath&quot;:&quot;/home/druid-conf/common-0.9.1.1/whiteList&quot;&#125;</div><div class="line">druid.emitter.logging.logLevel=info</div></pre></td></tr></table></figure></p>
<p>druid的metrics结构为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&lt;namespacePrefix&gt;.[&lt;druid service name&gt;].[&lt;druid hostname&gt;].&lt;dimensions values ordered by dimension&apos;s name&gt;.&lt;metric&gt;</div></pre></td></tr></table></figure></p>
<h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><p>graphite端口需要注意，druid发送的是pickled之后的数据。graphite的<a href="http://graphite.readthedocs.io/en/latest/feeding-carbon.html#the-pickle-protocol" target="_blank" rel="external">pickled protocal</a>默认是2004端口，plaintext protocal才是2003端口。</p>
<p>否则graphite会遇见下述错误：<br>less /disk1/xxx/graphite-virtualenv/carbon-relay.out | grep druid<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">22/01/2017 15:02:29 :: [listener] invalid line (tta(S&apos;druid-graphite.druid/broker.jvm/gc/time&apos;) received from client xx.xxx.xx.xx:38901, ignoring</div><div class="line">22/01/2017 15:02:29 :: [listener] invalid line (tta(S&apos;druid-graphite.druid/broker.xxxx.groupBy.query/node/ttfb&apos;) received from client xx.xxx.xx.xx:38901, ignoring</div></pre></td></tr></table></figure></p>
<h3 id="Event-Converter具体说明"><a href="#Event-Converter具体说明" class="headerlink" title="Event Converter具体说明"></a>Event Converter具体说明</h3><p>Event Converter用户可配置的：</p>
<ul>
<li>namespacePrefix：前缀</li>
<li>ignoreHostname：是否忽略hostname</li>
<li>ignoreServiceName：是否忽略servicename</li>
<li>mapPath：</li>
</ul>
<p>经过上述配置之后，graphite目录结构为：<br>druid-graphite/serviceName/host/xxxx/xxxx</p>
<h2 id="Grafana展示"><a href="#Grafana展示" class="headerlink" title="Grafana展示"></a>Grafana展示</h2><p>Grafana提供了一种强大的优雅的方式来创建，展示，分享dashboards，支持Graphite数据源。</p>
<p>以broker节点的监控为例，以下的$node为节点变量，broker有两个节点，$node会有两个值。</p>
<h3 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h3><blockquote>
<p>transformNull(druid-graphite.druid.broker.$node.jvm.mem.*, 0)<br><img src="http://note.youdao.com/yws/public/resource/32442f2d923ee4564e15f34e1a33fdd5/BB7AB009DB67446A86208F20DD363274" alt="image"></p>
</blockquote>
<p>图中两条线为其中一个broker的内存情况，黄色的线为mem.used，淡蓝色的线为mem.max</p>
<h3 id="查询时间"><a href="#查询时间" class="headerlink" title="查询时间"></a>查询时间</h3><blockquote>
<p>druid-graphite.druid.broker.$node.$datasource.{groupBy,topN,timeseries}.query.time<br><img src="http://note.youdao.com/yws/public/resource/32442f2d923ee4564e15f34e1a33fdd5/F0B9253194224C37A1B7BEB1E539897F" alt="image"></p>
</blockquote>
<h3 id="查询时间占比"><a href="#查询时间占比" class="headerlink" title="查询时间占比"></a>查询时间占比</h3><blockquote>
<p>druid-graphite.druid.broker.$node.$datasource.$queryType.query.time<br><img src="http://note.youdao.com/yws/public/resource/32442f2d923ee4564e15f34e1a33fdd5/8797DFE746454B20B05EF88EB7FD0DB9" alt="image"></p>
</blockquote>
<h2 id="Seyren报警"><a href="#Seyren报警" class="headerlink" title="Seyren报警"></a>Seyren报警</h2><p>报警使用的基于Graphite数据的开源项目<a href="https://github.com/scobal/seyren" target="_blank" rel="external">seyren</a>，提供邮件和短信等手段的报警。</p>
<h3 id="举例"><a href="#举例" class="headerlink" title="举例"></a>举例</h3><p>监控broker是否活着，可以监控内存使用情况。当broker挂了的话，内存使用会将为0，会进行报警</p>
<p><img src="http://note.youdao.com/yws/public/resource/32442f2d923ee4564e15f34e1a33fdd5/11B8023A6DF845AEAB52ED73ACB66BD1" alt="image">  </p>
<p>配置短信和邮件报警<br><img src="http://note.youdao.com/yws/public/resource/32442f2d923ee4564e15f34e1a33fdd5/01E28C039FF94FF694C5451EBCD7B8D3" alt="image"></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://blog.leanote.com/post/du00/Druid%E7%9A%84Graphite%E7%9B%91%E6%8E%A7%E9%85%8D%E7%BD%AE" target="_blank" rel="external">博客:Druid的Graphite监控配置</a><br><a href="http://druid.io/docs/latest/development/extensions-contrib/graphite.html" target="_blank" rel="external">官方文档:Graphite Emitter</a></p>
</the></excerpt>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Java程序监控---Metrics]]></title>
      <url>https://fangyeqing.github.io/2016/12/14/Java%E7%A8%8B%E5%BA%8F%E7%9B%91%E6%8E%A7---Metrics/</url>
      <content type="html"><![CDATA[<excerpt in="" index="" |="" 首页摘要="">   

<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>Metrics是一个给JAVA服务的各项指标提供度量工具的包，在JAVA代码中嵌入Metrics代码，可以方便的对业务代码的各个指标进行监控</p>
<p>目前最为流行的 metrics 库是来自 Coda Hale 的 dropwizard/metrics，该库被广泛地应用于各个知名的开源项目中。例如 Hadoop，Kafka，Spark，JStorm 中。</p>
<a id="more"></a>  
<the rest="" of="" contents="" |="" 余下全文="">   

<p>有一些优点：</p>
<ul>
<li>提供了对Ehcache、Apache HttpClient、JDBI、Jersey、Jetty、Log4J、Logback、JVM等的集成</li>
<li>支持多种Metric指标：Gauges、Counters、Meters、Histograms和Timers</li>
<li>支持多种Reporter发布指标<ul>
<li>JMX、Console，CSV文件和SLF4J loggers</li>
<li>Ganglia、Graphite，用于图形化展示</li>
</ul>
</li>
</ul>
<h2 id="MetricRegistry"><a href="#MetricRegistry" class="headerlink" title="MetricRegistry"></a>MetricRegistry</h2><p>MetricRegistry类是Metrics的核心，它是存放应用中所有metrics的容器。也是我们使用 Metrics 库的起点。其中maven依赖添加在文末。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">static final MetricRegistry metrics = new MetricRegistry();</div></pre></td></tr></table></figure></p>
<h2 id="Reporter"><a href="#Reporter" class="headerlink" title="Reporter"></a>Reporter</h2><p>指标获取之后需要上传到各种地方，就需要用到Reporter。</p>
<h3 id="控制台"><a href="#控制台" class="headerlink" title="控制台"></a>控制台</h3><p>监控指标直接打印在控制台<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">pravite static void startReportConsole() &#123;</div><div class="line">    ConsoleReporter reporter = ConsoleReporter.forRegistry(metrics)</div><div class="line">            .convertRatesTo(TimeUnit.SECONDS)</div><div class="line">            .convertDurationsTo(TimeUnit.MILLISECONDS)</div><div class="line">            .build();</div><div class="line">    reporter.start(1, TimeUnit.SECONDS);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="JMX"><a href="#JMX" class="headerlink" title="JMX"></a>JMX</h3><p>将监控指标上报到JMX中，后续可以通过其他的开源工具上传到Graphite等供图形化展示。从Jconsole中MBean中能看到。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">pravite static void startReportJmx()&#123;</div><div class="line">    JmxReporter reporterJmx = JmxReporter.forRegistry(metrics).build();</div><div class="line">    reporterJmx.start();</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="Graphite"><a href="#Graphite" class="headerlink" title="Graphite"></a>Graphite</h3><p>将监控指标上传到Graphite，从Graphite-web中能看到上传的监控指标。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">pravite static void startReportGraphite()&#123;</div><div class="line">    Graphite graphite = new Graphite(new InetSocketAddress(&quot;graphite.xxx.com&quot;, 2003));</div><div class="line">    GraphiteReporter reporter = GraphiteReporter.forRegistry(metrics)</div><div class="line">            .prefixedWith(&quot;test.metrics&quot;)</div><div class="line">            .convertRatesTo(TimeUnit.SECONDS)</div><div class="line">            .convertDurationsTo(TimeUnit.MILLISECONDS)</div><div class="line">            .filter(MetricFilter.ALL)</div><div class="line">            .build(graphite);</div><div class="line">    reporter.start(1, TimeUnit.MINUTES);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="封装各种Reporter"><a href="#封装各种Reporter" class="headerlink" title="封装各种Reporter"></a>封装各种Reporter</h3><p>调用方式MetricCommon.getMetricAndStartReport();<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">public class MetricCommon &#123;</div><div class="line">    private static final MetricRegistry metricRegistry = new MetricRegistry();</div><div class="line"></div><div class="line">    public static MetricRegistry getMetricAndStartReport()&#123;</div><div class="line">        startReportConsole();</div><div class="line">        startReportJmx();</div><div class="line">        startReportGraphite();</div><div class="line">        return metricRegistry;</div><div class="line">    &#125;</div><div class="line">    pravite static void startReportConsole() &#123;...&#125;</div><div class="line">    pravite static void startReportJmx()&#123;...&#125;</div><div class="line">    pravite static void startReportGraphite()&#123;...&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="Metics指标"><a href="#Metics指标" class="headerlink" title="Metics指标"></a>Metics指标</h2><p>Metrics 有如下监控指标：</p>
<ul>
<li>Gauges：记录一个瞬时值。例如一个待处理队列的长度。</li>
<li>Histograms：统计单个数据的分布情况，最大值、最小值、平均值、中位数，百分比（75%、90%、95%、98%、99%和99.9%）</li>
<li>Meters：统计调用的频率（TPS），总的请求数，平均每秒的请求数，以及最近的1、5、15分钟的平均TPS</li>
<li>Timers：当我们既要统计TPS又要统计耗时分布情况，Timer基于Histograms和Meters来实现</li>
<li>Counter：计数器，自带inc()和dec()方法计数，初始为0。</li>
<li>Health Checks：用于对Application、其子模块或者关联模块的运行是否正常做检测</li>
</ul>
<h3 id="Gauges"><a href="#Gauges" class="headerlink" title="Gauges"></a>Gauges</h3><p>最简单的度量指标，只有一个简单的返回值，例如，我们想衡量一个待处理队列中任务的个数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line">public class GaugeTest &#123;</div><div class="line">    private static final MetricRegistry registry = MetricCommon.getMetricAndStartReport();</div><div class="line">    private static final Random random = new Random();</div><div class="line"></div><div class="line">    @Test</div><div class="line">    public void testOneGuage() throws InterruptedException &#123;</div><div class="line">        Queue queue= new LinkedList&lt;String&gt;();</div><div class="line">        registry.register(MetricRegistry.name(GaugeTest.class, &quot;testGauges-queue-size&quot;, &quot;size&quot;),</div><div class="line">                (Gauge&lt;Integer&gt;) () -&gt; queue.size());</div><div class="line">        while(true)&#123;</div><div class="line">            Thread.sleep(1000);</div><div class="line">            queue.add(&quot;Job-xxx&quot;);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    @Test</div><div class="line">    public void testMultiGuage() throws InterruptedException &#123;</div><div class="line">        Map&lt;Integer, Integer&gt; map = new ConcurrentHashMap&lt;&gt;();</div><div class="line">        while(true)&#123;</div><div class="line">            int i = random.nextInt(100);</div><div class="line">            int j = i % 10;</div><div class="line"></div><div class="line">            if(!map.containsKey(j))&#123;</div><div class="line">                map.put(j,i);</div><div class="line">                registry.register(MetricRegistry.name(GaugeTest.class, &quot;testGauges-number&quot;, String.valueOf(j)),</div><div class="line">                        (Gauge&lt;Integer&gt;) () -&gt; map.get(j));</div><div class="line">            &#125;else&#123;</div><div class="line">                map.put(j,i);</div><div class="line">            &#125;</div><div class="line">            Thread.sleep(1000);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>第一个测试用例，是用一个guage记录队列的长度<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">-- Gauges ----------------------------------------------------------------------</div><div class="line">GaugeTest.testGauges-queue-size.size</div><div class="line">             value = 4</div></pre></td></tr></table></figure></p>
<p>第二个测试用例，每次产生一个100以内的随机数，将这些数以个位数的数字分组，guage记录每一组现在是什么数。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">-- Gauges ----------------------------------------------------------------------</div><div class="line">GaugeTest.testGauges-number.0</div><div class="line">             value = 60</div><div class="line">GaugeTest.testGauges-number.1</div><div class="line">             value = 1</div><div class="line">GaugeTest.testGauges-number.2</div><div class="line">             value = 82</div><div class="line">GaugeTest.testGauges-number.3</div><div class="line">             value = 23</div><div class="line">GaugeTest.testGauges-number.4</div><div class="line">             value = 74</div><div class="line">GaugeTest.testGauges-number.5</div><div class="line">             value = 25</div><div class="line">GaugeTest.testGauges-number.7</div><div class="line">             value = 17</div><div class="line">GaugeTest.testGauges-number.8</div><div class="line">             value = 78</div><div class="line">GaugeTest.testGauges-number.9</div><div class="line">             value = 69</div></pre></td></tr></table></figure></p>
<h3 id="Histogram"><a href="#Histogram" class="headerlink" title="Histogram"></a>Histogram</h3><p>Histogram统计数据的分布情况。比如最小值，最大值，中间值，还有中位数，75百分位, 90百分位, 95百分位, 98百分位, 99百分位, 和 99.9百分位的值(percentiles)。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">public class HistogramTest &#123;</div><div class="line">    private static final MetricRegistry registry = MetricCommon.getMetricAndStartReport();</div><div class="line">    public static Random random = new Random();</div><div class="line"></div><div class="line">    @Test</div><div class="line">    public void test() throws InterruptedException &#123;</div><div class="line">        Histogram histogram = new Histogram(new ExponentiallyDecayingReservoir());</div><div class="line">        registry.register(MetricRegistry.name(HistogramTest.class, &quot;request&quot;, &quot;histogram&quot;), histogram);</div><div class="line"></div><div class="line">        while(true)&#123;</div><div class="line">            Thread.sleep(1000);</div><div class="line">            histogram.update(random.nextInt(100000));</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>运行很长时间之后，相当于随机值取极限，会趋向于统计值，75%肯定是要&lt;=75000,99.9%肯定是要&lt;=999000。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">-- Histograms ------------------------------------------------------------------</div><div class="line">HistogramTest.request.histogram</div><div class="line">             count = 1336</div><div class="line">               min = 97</div><div class="line">               max = 99930</div><div class="line">              mean = 49816.49</div><div class="line">            stddev = 29435.27</div><div class="line">            median = 49368.00</div><div class="line">              75% &lt;= 75803.00</div><div class="line">              95% &lt;= 95340.00</div><div class="line">              98% &lt;= 98096.00</div><div class="line">              99% &lt;= 98724.00</div><div class="line">            99.9% &lt;= 99930.00</div></pre></td></tr></table></figure></p>
<h3 id="Meters"><a href="#Meters" class="headerlink" title="Meters"></a>Meters</h3><p>Meter度量一系列事件发生的速率(rate)，例如TPS。Meters会统计最近1分钟，5分钟，15分钟，还有全部时间的速率。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">public class MetersTest &#123;</div><div class="line">    MetricRegistry registry = MetricCommon.getMetricAndStartAllReport(&quot;nc110x.corp.youdao.com&quot;,&quot;test.metrics&quot;);</div><div class="line">    public static Random random = new Random();</div><div class="line"></div><div class="line">    @Test</div><div class="line">    public void testOne() throws InterruptedException &#123;</div><div class="line">        Meter meterTps = registry.meter(MetricRegistry.name(MetersTest.class,&quot;request&quot;,&quot;tps&quot;));</div><div class="line">        while(true)&#123;</div><div class="line">            meterTps.mark();</div><div class="line">            Thread.sleep(random.nextInt(1000));</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    @Test</div><div class="line">    public void testMulti() throws InterruptedException &#123;</div><div class="line">        while(true)&#123;</div><div class="line">            int i = random.nextInt(100);</div><div class="line">            int j = i % 10;</div><div class="line">            Meter meterTps = registry.meter(MetricRegistry.name(MetersTest.class,&quot;request&quot;,&quot;tps&quot;,String.valueOf(j)));</div><div class="line">            meterTps.mark();</div><div class="line">            Thread.sleep(10);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这里，多个注册多个meter与注册多个guage、Histograms用法会有不同，meter方法是getOrAdd<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">public Meter meter(String name) &#123;</div><div class="line">        return (Meter)this.getOrAdd(name, MetricRegistry.MetricBuilder.METERS);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>一个meter的测试用例，运行结果如下。可以看到随着次数的增多，各种rate无限趋近于2次。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">-- Meters ----------------------------------------------------------------------</div><div class="line">MetersTest.request.tps</div><div class="line">             count = 452</div><div class="line">         mean rate = 1.99 events/second</div><div class="line">     1-minute rate = 2.03 events/second</div><div class="line">     5-minute rate = 2.00 events/second</div><div class="line">    15-minute rate = 2.00 events/second</div></pre></td></tr></table></figure></p>
<p>多个meter的测试用例，运行结果取了数字个位数为6/7/8的三个如下。最后都会无限趋近于10。sleep时间为10ms，每秒有100份，平均到尾数不同的，每组就有10份。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">MetersTest.request.tps.6</div><div class="line">             count = 905</div><div class="line">         mean rate = 9.74 events/second</div><div class="line">     1-minute rate = 9.76 events/second</div><div class="line">     5-minute rate = 9.94 events/second</div><div class="line">    15-minute rate = 9.98 events/second</div><div class="line">MetersTest.request.tps.7</div><div class="line">             count = 935</div><div class="line">         mean rate = 10.07 events/second</div><div class="line">     1-minute rate = 10.62 events/second</div><div class="line">     5-minute rate = 11.82 events/second</div><div class="line">    15-minute rate = 12.19 events/second</div><div class="line">MetersTest.request.tps.8</div><div class="line">             count = 937</div><div class="line">         mean rate = 10.09 events/second</div><div class="line">     1-minute rate = 10.09 events/second</div><div class="line">     5-minute rate = 10.31 events/second</div><div class="line">    15-minute rate = 10.37 events/second</div></pre></td></tr></table></figure></p>
<h3 id="Timer"><a href="#Timer" class="headerlink" title="Timer"></a>Timer</h3><p>Timer其实是 Histogram 和 Meter 的结合， histogram 某部分代码/调用的耗时， meter统计TPS。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">public class TimerTest &#123;</div><div class="line">    public static Random random = new Random();</div><div class="line">    private static final MetricRegistry registry = MetricCommon.getMetricAndStartAllReport(&quot;nc110x.corp.youdao.com&quot;,&quot;test.metrics&quot;);</div><div class="line">    private static final Map&lt;Integer,Timer&gt; timerMap = new ConcurrentHashMap&lt;&gt;();</div><div class="line"></div><div class="line">    @Test</div><div class="line">    public void testOneTimer() throws InterruptedException &#123;</div><div class="line">        Timer timer = registry.timer(MetricRegistry.name(TestTimer.class,&quot;get-latency&quot;));</div><div class="line">        Timer.Context ctx;</div><div class="line"></div><div class="line">        while(true)&#123;</div><div class="line">            ctx = timer.time();</div><div class="line">            Thread.sleep(random.nextInt(1000));</div><div class="line">            ctx.stop();</div><div class="line">        &#125;</div><div class="line"></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    @Test</div><div class="line">    public void testMultiTimer() throws InterruptedException &#123;</div><div class="line">        while(true)&#123;</div><div class="line">            int i = random.nextInt(100);</div><div class="line">            int j = i % 10;</div><div class="line"></div><div class="line">            Timer timer = registry.timer(MetricRegistry.name(TestTimer.class,&quot;get-latency&quot;,String.valueOf(j)));</div><div class="line">            Timer.Context ctx;</div><div class="line"></div><div class="line">            ctx = timer.time();</div><div class="line">            Thread.sleep(random.nextInt(1000));</div><div class="line">            ctx.stop();</div><div class="line"></div><div class="line">            Thread.sleep(1000);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>测试用例1是单个timer，结果如下。最后的时间都趋近于统计值。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">-- Timers ----------------------------------------------------------------------</div><div class="line">com.testmetrics.TestTimer.get-latency</div><div class="line">             count = 657</div><div class="line">         mean rate = 2.05 calls/second</div><div class="line">     1-minute rate = 1.98 calls/second</div><div class="line">     5-minute rate = 2.02 calls/second</div><div class="line">    15-minute rate = 2.01 calls/second</div><div class="line">               min = 4.98 milliseconds</div><div class="line">               max = 998.93 milliseconds</div><div class="line">              mean = 496.79 milliseconds</div><div class="line">            stddev = 297.46 milliseconds</div><div class="line">            median = 501.02 milliseconds</div><div class="line">              75% &lt;= 765.09 milliseconds</div><div class="line">              95% &lt;= 952.03 milliseconds</div><div class="line">              98% &lt;= 974.12 milliseconds</div><div class="line">              99% &lt;= 989.02 milliseconds</div><div class="line">            99.9% &lt;= 998.93 milliseconds</div></pre></td></tr></table></figure></p>
<h3 id="Counters"><a href="#Counters" class="headerlink" title="Counters"></a>Counters</h3><p>Counter 就是计数器，Counter 只是用 Gauge 封装了 AtomicLong 。我们可以使用如下的方法，使得获得队列大小更加高效。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">public class CounterTest &#123;</div><div class="line">    private static final MetricRegistry registry = MetricCommon.getMetricAndStartReport();</div><div class="line">    public static Queue&lt;String&gt; q = new LinkedBlockingQueue&lt;String&gt;();</div><div class="line">    public static Counter pendingJobs;</div><div class="line">    public static Random random = new Random();</div><div class="line"></div><div class="line">    public static void addJob(String job) &#123;</div><div class="line">        pendingJobs.inc();</div><div class="line">        q.offer(job);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    public static String takeJob() &#123;</div><div class="line">        pendingJobs.dec();</div><div class="line">        return q.poll();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    @Test</div><div class="line">    public void test() throws InterruptedException &#123;</div><div class="line">        pendingJobs = registry.counter(MetricRegistry.name(Queue.class,&quot;pending-jobs&quot;,&quot;size&quot;));</div><div class="line"></div><div class="line">        int num = 1;</div><div class="line">        while(true)&#123;</div><div class="line">            Thread.sleep(200);</div><div class="line">            if (random.nextDouble() &gt; 0.7)&#123;</div><div class="line">                String job = takeJob();</div><div class="line">                System.out.println(&quot;take job : &quot;+job);</div><div class="line">            &#125;else&#123;</div><div class="line">                String job = &quot;Job-&quot;+num;</div><div class="line">                addJob(job);</div><div class="line">                System.out.println(&quot;add job : &quot;+job);</div><div class="line">            &#125;</div><div class="line">            num++;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>job会越来越多，因为每次取走只取一个job，但是加入job是加入num个，num会一直增加，而概率是7:3。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">-- Counters --------------------------------------------------------------------</div><div class="line">java.util.Queue.pending-jobs.size</div><div class="line">             count = 36</div></pre></td></tr></table></figure></p>
<h3 id="HeathChecks"><a href="#HeathChecks" class="headerlink" title="HeathChecks"></a>HeathChecks</h3><p>Metrics提供了一个独立的模块：Health Checks，用于对Application、其子模块或者关联模块的运行是否正常做检测。该模块是独立metrics-core模块的，使用时则导入metrics-healthchecks包。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">public class HeathChecksTest extends HealthCheck &#123;</div><div class="line">    @Override</div><div class="line">    protected Result check() throws Exception &#123;</div><div class="line">        Random random = new Random();</div><div class="line">        if(random.nextInt(10)!=9)&#123;</div><div class="line">            return Result.healthy();</div><div class="line">        &#125;else&#123;</div><div class="line">            return Result.unhealthy(&quot;oh,unhealthy&quot;);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    @Test</div><div class="line">    public void test() throws InterruptedException &#123;</div><div class="line">        HealthCheckRegistry registry = new HealthCheckRegistry();</div><div class="line">        registry.register(&quot;check1&quot;,new HeathChecksTest());</div><div class="line">        registry.register(&quot;check2&quot;, new HeathChecksTest());</div><div class="line">        while (true) &#123;</div><div class="line">            for (Map.Entry&lt;String, Result&gt; entry : registry.runHealthChecks().entrySet()) &#123;</div><div class="line">                if (entry.getValue().isHealthy()) &#123;</div><div class="line">                    System.out.println(entry.getKey() + &quot;: OK, message:&quot;+entry.getValue());</div><div class="line">                &#125; else &#123;</div><div class="line">                    System.err.println(entry.getKey() + &quot;: FAIL, error message: &quot; + entry.getValue());</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">            Thread.sleep(1000);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>注册两个HeathChecks，重写其check()方法为取随机数，只要不是9就为healthy，输出结果如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">check1: OK, message:Result&#123;isHealthy=true&#125;</div><div class="line">check2: FAIL, error message: Result&#123;isHealthy=false, message=oh,unhealthy&#125;</div><div class="line">check1: OK, message:Result&#123;isHealthy=true&#125;</div><div class="line">check2: OK, message:Result&#123;isHealthy=true&#125;</div><div class="line">check1: OK, message:Result&#123;isHealthy=true&#125;</div><div class="line">check2: OK, message:Result&#123;isHealthy=true&#125;</div><div class="line">check1: OK, message:Result&#123;isHealthy=true&#125;</div><div class="line">check2: OK, message:Result&#123;isHealthy=true&#125;</div><div class="line">check1: OK, message:Result&#123;isHealthy=true&#125;</div></pre></td></tr></table></figure></p>
<h2 id="maven依赖"><a href="#maven依赖" class="headerlink" title="maven依赖"></a>maven依赖</h2><ul>
<li>metrics-core：必须添加</li>
<li>metrics-healthchecks：用到healthchecks时添加</li>
<li>metrics-graphite：用到graphite时添加</li>
<li>org.slf4j：不添加看不到metrics-graphite包出错的log<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">&lt;properties&gt;</div><div class="line">    &lt;metrics.version&gt;3.1.0&lt;/metrics.version&gt;</div><div class="line">    &lt;sl4j.version&gt;1.7.22&lt;/sl4j.version&gt;</div><div class="line">&lt;/properties&gt;</div><div class="line"></div><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;io.dropwizard.metrics&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;metrics-core&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;$&#123;metrics.version&#125;&lt;/version&gt;</div><div class="line">&lt;/dependency&gt;</div><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;io.dropwizard.metrics&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;metrics-healthchecks&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;$&#123;metrics.version&#125;&lt;/version&gt;</div><div class="line">&lt;/dependency&gt;</div><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;io.dropwizard.metrics&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;metrics-graphite&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;$&#123;metrics.version&#125;&lt;/version&gt;</div><div class="line">&lt;/dependency&gt;</div><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;$&#123;sl4j.version&#125;&lt;/version&gt;</div><div class="line">&lt;/dependency&gt;</div><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;slf4j-simple&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;$&#123;sl4j.version&#125;&lt;/version&gt;</div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://metrics.dropwizard.io/3.1.0/getting-started/" target="_blank" rel="external">http://metrics.dropwizard.io/3.1.0/getting-started/</a><br><a href="http://www.cnblogs.com/nexiyi/p/metrics_sample_1.html" target="_blank" rel="external">http://www.cnblogs.com/nexiyi/p/metrics_sample_1.html</a><br><a href="http://wuchong.me/blog/2015/08/01/getting-started-with-metrics/" target="_blank" rel="external">http://wuchong.me/blog/2015/08/01/getting-started-with-metrics/</a></p>
</the></excerpt>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Camus介绍]]></title>
      <url>https://fangyeqing.github.io/2016/12/01/Camus%E4%BB%8B%E7%BB%8D/</url>
      <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要="">   </excerpt></p>
<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>Linkedin/Camus是一个MapReduce作业，从Kafka拉取指定topic到HDFS，供批量/离线数据处理、分析。</p>
<p>其中，Camus sweeper组件提供去重功能,可以对Kafka中由于“at least once”机制而存在重复数据的topic进行去重。</p>
<p>目前<a href="https://github.com/linkedin/camus" target="_blank" rel="external">Camus</a>已经停止更新了，新项目为<a href="https://github.com/linkedin/gobblin" target="_blank" rel="external">gobblin</a>。</p>
<h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><p>Camus有以下几个特点：</p>
<ul>
<li>自动发现topic</li>
<li>Avro schema管理</li>
<li>按时间分区  </li>
</ul>
<a id="more"></a>  
<p><the rest="" of="" contents="" |="" 余下全文="">   </the></p>
<h3 id="Camus-job"><a href="#Camus-job" class="headerlink" title="Camus job"></a>Camus job</h3><p><img src="http://note.youdao.com/yws/public/resource/027eae2659928c104735afa6fe77369a/xmlnote/DDAAF70F0B1D4D329E7BDA5E49FC37D2/24715" alt="image">  </p>
<p>每个camus job分为三个阶段：  </p>
<ul>
<li>Setup Stage：从Kafka和Zookeeper获取可用的topics，partitions，offset等元信息（Metadata） </li>
<li>Hadoop Job Stage：开启多个ETL map task执行topic的数据获取，并写到HDFS。每个task的流程如下：<ul>
<li>Pulling the data：每个task根据Setup Stage获取到的元数据，消费Kafka的数据，在Schema注册服务查找Avro模式来反序列化。每个task都生成4个文件：Avro data files，Count statistics files，Updated offset files，Error files</li>
<li>Committing the data：当一个task完成时，其拉取的数据都被提交到基于时间戳的output目录。</li>
<li>Producing Audit Counts：执行成功的tasks会向HDFS写audit counts</li>
<li>Storing the offset：每个partition都有offset，这些offset信息存储在HDFS中</li>
</ul>
</li>
<li>Cleanup Stage：hadoop job完成后，收集HDFS中的audit counts并进行聚合，然后提交聚合结果到kafka</li>
</ul>
<h2 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h2><p>camus关键在于实现两个类，Decoder和Writer，使其满足我们的系统业务，并且稍加配置就可以嵌入到自己的系统中。</p>
<h3 id="MessageDecoder"><a href="#MessageDecoder" class="headerlink" title="MessageDecoder"></a>MessageDecoder</h3><p>MessageDecoder对kafka消息进行解码。</p>
<p>Camus自带了KafkaAvroMessageDecoder，JsonStringMessageDecoder等。也可以通过继承MessageDecoder实现符合自己业务的Decoder。通过camus.message.decoder.class配置。</p>
<h3 id="RecordWriterProvider"><a href="#RecordWriterProvider" class="headerlink" title="RecordWriterProvider"></a>RecordWriterProvider</h3><p>RecordWriterProvider在数据写到HDFS之前进行编码。</p>
<p>Camus自带AvroRecordWriterProvider，StringRecordWriterProvider等。也可以通过实现RecordWriterProvider实现自己的写入方法。并通过<br>etl.record.writer.provider.class来配置</p>
<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><table>
<thead>
<tr>
<th>配置项</th>
<th>解释</th>
<th>是否必须</th>
<th>默认值</th>
</tr>
</thead>
<tbody>
<tr>
<td>Schema配置</td>
<td></td>
</tr>
<tr>
<td><code>schema.registry.url</code></td>
<td>schema registry地址</td>
<td>是</td>
</tr>
<tr>
<td><code>max.schemas.per.subject</code></td>
<td>subject下最大schema数量</td>
<td>否</td>
<td>1000</td>
</tr>
<tr>
<td>Kafka配置</td>
<td></td>
</tr>
<tr>
<td><code>kafka.brokers</code></td>
<td>kafka broker地址List</td>
<td>是</td>
</tr>
<tr>
<td><code>kafka.max.pull.hrs</code></td>
<td>从每个分区拉取数据的最长历史小时数（相对于第一条未消费的消息的时间戳），-1表示没限制</td>
<td>否</td>
<td>-1</td>
</tr>
<tr>
<td><code>kafka.max.historical.days</code></td>
<td>Events的时间戳超过将被丢弃，-1表示没限制</td>
<td>否</td>
<td>-1</td>
</tr>
<tr>
<td><code>kafka.max.pull.minutes.per.task</code></td>
<td>MapReduce任务拉取消息的最大时间。超时就会停止，下一个camus job会继续从停止的offset消费</td>
<td>否</td>
<td>-1 </td>
</tr>
<tr>
<td><code>kafka.blacklist.topics</code></td>
<td>黑名单里的topic不会被消费</td>
<td>否</td>
<td>null</td>
</tr>
<tr>
<td><code>kafka.whitelist.topics</code></td>
<td>白名单里的topic会被消费</td>
<td>否</td>
<td>null</td>
</tr>
<tr>
<td><code>etl.output.record.delimiter</code></td>
<td>消息分隔符</td>
<td>否</td>
<td>“\n”</td>
</tr>
<tr>
<td>Camus Job配置</td>
<td></td>
</tr>
<tr>
<td><code>camus.job.name</code></td>
<td>camus job名</td>
<td>否</td>
<td>Camus Job</td>
</tr>
<tr>
<td><code>camus.message.decoder.class</code></td>
<td>解码器</td>
<td>否</td>
<td>AvroMessageDecoder</td>
</tr>
<tr>
<td><code>etl.record.writer.provider.class</code></td>
<td>编码器</td>
<td>否</td>
<td>AvroRecordWriterProvider</td>
</tr>
<tr>
<td><code>etl.partitioner.class</code></td>
<td>Camus输出分区，默认按小时</td>
<td>否</td>
<td>DefaultPartitioner</td>
</tr>
<tr>
<td><code>camus.work.allocator.class</code></td>
<td>Class for creating input splits from ETL requests</td>
<td>否</td>
<td>BaseAllocator</td>
</tr>
<tr>
<td><code>etl.destination.path</code></td>
<td>文件最终输出的文件夹，Top-level output directory, sub-directories will be dynamically created for each topic pulled.</td>
<td>是</td>
</tr>
<tr>
<td><code>etl.execution.base.path</code></td>
<td>Camus运行信息临时存放的HDFS目录，offsets, error logs and count files等</td>
<td>是</td>
</tr>
<tr>
<td><code>etl.execution.history.path</code></td>
<td>已完成的Job的运行信息存放的HDFS目录，通常是 <code>etl.execution.base.path</code>的子目录</td>
<td>是</td>
</tr>
<tr>
<td><code>hdfs.default.classpath.dir</code></td>
<td>All files in this directory will be added to the distributed cache and placed on the classpath for Hadoop tasks.</td>
<td>否</td>
<td>null</td>
</tr>
<tr>
<td><code>mapred.map.tasks</code></td>
<td>最大hadoop任务数, 每个任务可以拉取多个topic partitions</td>
<td>否</td>
<td>30</td>
</tr>
</tbody>
</table>
<h4 id="配置讲解"><a href="#配置讲解" class="headerlink" title="配置讲解"></a>配置讲解</h4><p><img src="http://note.youdao.com/yws/public/resource/027eae2659928c104735afa6fe77369a/xmlnote/4134B32520014148A88F9AC1EB2B9663/24930" alt="image"><br>设ts是在<code>runTime-kafka.max.historical</code>之内的还未消费的第一条消息的时间戳。图中当前运行时间runTime为2015年12月5日0点，ts为2015年12月2日0点到5日0点之间还未消费的第一条消息的时间戳，即绿色区域的起点。</p>
<p>如果消息的时间戳在<code>ts,ts + kafka.max.pull.hrs</code>之间）,将被camus任务消费，并且假设在<code>kafka.max.pull.minutes.per.task</code>内任务很快完成。显然图中绿色区域的都会被消费。</p>
<h4 id="配置场景应用"><a href="#配置场景应用" class="headerlink" title="配置场景应用"></a>配置场景应用</h4><p><code>kafka.max.historical.days</code>:可以用于忽略过老的消息<br><code>kafka.max.pull.hrs</code>:将此值设置得比camus job的执行频率小，可以防止重复任务  </p>
<h3 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">mvn clean package</div><div class="line"></div><div class="line">hadoop jar camus-example-&lt;version&gt;-SNAPSHOT.jar com.linkedin.camus.etl.kafka.CamusJob  </div><div class="line"> -D &lt;property=value&gt;   use value for given property  </div><div class="line"> -P &lt;arg&gt;              external properties filename  </div><div class="line"> -p &lt;arg&gt;              properties filename from the classpath</div></pre></td></tr></table></figure>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://docs.confluent.io/1.0/camus/docs/intro.html" target="_blank" rel="external">http://docs.confluent.io/1.0/camus/docs/intro.html</a><br><a href="https://github.com/confluentinc/camus" target="_blank" rel="external">https://github.com/confluentinc/camus</a><br><a href="http://getindata.com/blog/post/time-related-configuration-settings-and-assumptions-in-camus/" target="_blank" rel="external">http://getindata.com/blog/post/time-related-configuration-settings-and-assumptions-in-camus/</a><br><a href="http://blog.csdn.net/amghost/article/details/44258817" target="_blank" rel="external">http://blog.csdn.net/amghost/article/details/44258817</a><br><a href="http://blog.csdn.net/amghost/article/details/44258841" target="_blank" rel="external">http://blog.csdn.net/amghost/article/details/44258841</a>  </p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Samza 3---Samza API]]></title>
      <url>https://fangyeqing.github.io/2016/11/17/Samza_3---Samza_API/</url>
      <content type="html"><![CDATA[<excerpt in="" index="" |="" 首页摘要="">   

<p>Samza任务类必须实现StreamTask,可选 InitableTask, ClosableTask,WindowableTask<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">public class xxxxTask implements StreamTask, InitableTask, ClosableTask,WindowableTask &#123;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<a id="more"></a>  
<p><the rest="" of="" contents="" |="" 余下全文="">   </the></p>
<h2 id="StreamTask"><a href="#StreamTask" class="headerlink" title="StreamTask"></a>StreamTask</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">public interface StreamTask &#123;</div><div class="line">    void process(IncomingMessageEnvelope var1, //接收到的消息封装</div><div class="line">                MessageCollector var2,//用来发送其他消息</div><div class="line">                TaskCoordinator var3) </div><div class="line">    throws Exception;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="IncomingMessageEnvelop"><a href="#IncomingMessageEnvelop" class="headerlink" title="IncomingMessageEnvelop"></a>IncomingMessageEnvelop</h3><p>代表接收到的消息的封装,表示StreamTask收到一个分区的一个特定的输入流。包括：</p>
<ul>
<li>message</li>
<li>key</li>
<li>消息来源（system+stream+partition）<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">public class IncomingMessageEnvelope &#123;</div><div class="line">  /** A deserialized message. */</div><div class="line">  Object getMessage() &#123; ... &#125;</div><div class="line"></div><div class="line">  /** A deserialized key. */</div><div class="line">  Object getKey() &#123; ... &#125;</div><div class="line"></div><div class="line">  /** The stream and partition that this message came from. */</div><div class="line">  SystemStreamPartition getSystemStreamPartition() &#123; ... &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="SystemStreamPartition"><a href="#SystemStreamPartition" class="headerlink" title="SystemStreamPartition"></a>SystemStreamPartition</h4><p>消息来源包括：</p>
<ul>
<li>消息来源system名</li>
<li>消息来源stream/topic/queue名</li>
<li>消息流的分区<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">/** A triple of system name, stream name and partition. */</div><div class="line">public class SystemStreamPartition extends SystemStream &#123;</div><div class="line"></div><div class="line">  /** The name of the system which provides this stream. It is</div><div class="line">      defined in the Samza job&apos;s configuration. */</div><div class="line">  public String getSystem() &#123; ... &#125;</div><div class="line"></div><div class="line">  /** The name of the stream/topic/queue within the system. */</div><div class="line">  public String getStream() &#123; ... &#125;</div><div class="line"></div><div class="line">  /** The partition within the stream. */</div><div class="line">  public Partition getPartition() &#123; ... &#125;</div><div class="line">  </div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="MessageCollector"><a href="#MessageCollector" class="headerlink" title="MessageCollector"></a>MessageCollector</h3><p> 为了发送一个消息， 你会创建一个OutgoingMessageEnvelop对象并且把它传递给消息收集器。它至少会确定你想要发送的消息、系统和数据流名字再发送出去。你也可以确定分区的key和另一些参数。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">public interface MessageCollector &#123;</div><div class="line">  void send(OutgoingMessageEnvelope envelope);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>注意：<br>请只在process()方法里使用MessageCollector对象。如果你保持住一个MessageCollector实例并且之后再次使用它，你的消息可能会错误地发送出去。</p>
<h4 id="OutgoingMessageEnvelope"><a href="#OutgoingMessageEnvelope" class="headerlink" title="OutgoingMessageEnvelope"></a>OutgoingMessageEnvelope</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">public class OutgoingMessageEnvelope &#123;</div><div class="line">    private final SystemStream systemStream;</div><div class="line">    private final String keySerializerName;</div><div class="line">    private final String messageSerializerName;</div><div class="line">    private final Object partitionKey;</div><div class="line">    private final Object key;</div><div class="line">    private final Object message;</div><div class="line">    </div><div class="line">    public OutgoingMessageEnvelope(SystemStream systemStream, String keySerializerName, String messageSerializerName, Object partitionKey, Object key, Object message) &#123; ... &#125;</div><div class="line">    </div><div class="line">     public OutgoingMessageEnvelope(SystemStream systemStream, Object partitionKey, Object key, Object message) &#123; ... &#125;</div><div class="line"></div><div class="line">    public OutgoingMessageEnvelope(SystemStream systemStream, Object key, Object message) &#123; ... &#125;</div><div class="line">    </div><div class="line">    public OutgoingMessageEnvelope(SystemStream systemStream, Object message) &#123; ... &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="InitableTask"><a href="#InitableTask" class="headerlink" title="InitableTask"></a>InitableTask</h2><p>用来处理初始化工作，init 函数会首先被调用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">public interface InitableTask &#123;</div><div class="line">    void init(Config var1, TaskContext var2) throws Exception;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="ClosableTask"><a href="#ClosableTask" class="headerlink" title="ClosableTask"></a>ClosableTask</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">public interface ClosableTask &#123;</div><div class="line">    void close() throws Exception;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="WindowableTask"><a href="#WindowableTask" class="headerlink" title="WindowableTask"></a>WindowableTask</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">public interface WindowableTask &#123;</div><div class="line">    void window(MessageCollector var1, </div><div class="line">                TaskCoordinator var2) throws Exception;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h2><p>有一个简单的任务，它把每个输入的消息拆成单词，并且发送每一个单词作为一个消息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"> public class SplitStringIntoWords implements StreamTask, InitableTask, ClosableTask &#123;</div><div class="line"></div><div class="line">    private String outputSystem;</div><div class="line">    </div><div class="line">    //官网教程中直接使用固定的SystemStream,稍加改造</div><div class="line">    //private final SystemStream output_stream = new SystemStream(&quot;kafka&quot;, &quot;words&quot;);</div><div class="line">    </div><div class="line">    @Override</div><div class="line">    public void close() throws Exception &#123;</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    @Override</div><div class="line">    public void init(Config config, TaskContext context) throws Exception &#123;//初始化时从配置文件读output system</div><div class="line">        outputSystem = config.get(&quot;task.output.system&quot;);</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    public void process(IncomingMessageEnvelope envelope,</div><div class="line">                      MessageCollector collector,</div><div class="line">                      TaskCoordinator coordinator) &#123;</div><div class="line">        String topic = envelope.getSystemStreamPartition().getSystemStream().getStream();</div><div class="line">        </div><div class="line">        topic=topic+&quot;_split&quot;;//获取输入消息的topic，加上后缀</div><div class="line">        </div><div class="line">        SystemStream output_stream=new SystemStream(outputSystem, topic);//构造新的发送消息的System+Stream</div><div class="line">        </div><div class="line">        String message = (String) envelope.getMessage();//接收到的消息</div><div class="line">        </div><div class="line">        for (String word : message.split(&quot; &quot;)) &#123;</div><div class="line">          //单词作为key，1作为value，后续任务可以将1相加计数</div><div class="line">          collector.send(new OutgoingMessageEnvelope(output_stream, word, 1));</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h2><p><a href="https://samza.apache.org/learn/documentation/0.10/" target="_blank" rel="external">https://samza.apache.org/learn/documentation/0.10/</a><br><a href="https://github.com/feuyeux/hello-samza/blob/master/doc/0.hello_samza.md" target="_blank" rel="external">https://github.com/feuyeux/hello-samza/blob/master/doc/0.hello_samza.md</a><br><a href="http://wdxtub.com/vault/cc-21.html" target="_blank" rel="external">http://wdxtub.com/vault/cc-21.html</a><br><a href="http://www.infoq.com/cn/articles/linkedin-samza" target="_blank" rel="external">http://www.infoq.com/cn/articles/linkedin-samza</a><br><a href="http://blog.csdn.net/colorant/article/details/12082145" target="_blank" rel="external">http://blog.csdn.net/colorant/article/details/12082145</a><br><a href="https://wyyhzc.gitbooks.io/hadoop2x/content/samzacontainer.html" target="_blank" rel="external">https://wyyhzc.gitbooks.io/hadoop2x/content/samzacontainer.html</a></p>
</excerpt>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Samza 2---介绍]]></title>
      <url>https://fangyeqing.github.io/2016/11/17/Samza_2---%E4%BB%8B%E7%BB%8D/</url>
      <content type="html"><![CDATA[<excerpt in="" index="" |="" 首页摘要="">   

<p>samza是一个分布式的流式数据处理框架（streaming processing），它是基于Kafka消息队列来实现类实时的流式数据处理的。下面将从为什么需要Samza、Samza一些基本概念、Samza架构、Samza的核心部件（SamzaContainer、Stream、Serialization、Checkpointing、State Management、Windowing、Metrix、JMX）几个部分来介绍。</p>
<h2 id="为什么需要samza"><a href="#为什么需要samza" class="headerlink" title="为什么需要samza"></a>为什么需要samza</h2><p>kafka作为一个分布式的消息队列系统，已经实现了流式处理框架底层的许多核心基础架构，把消息串联流动起来就是Streaming了。kafka相关内容可以参考另一篇博客<a href="https://fangyeqing.github.io/2016/10/28/kafka---%E4%BB%8B%E7%BB%8D/">kafka介绍</a>。</p>
<p>但是要构建一个可用的流式数据处理框架，还是有许多事情要做。例如生产者和消费者进程的管理，作业调度和容错处理，辅助工具和监控管理手段，更友好方便的用户接口等等，本质上说，Samza是在消息队列系统上的更高层的抽象，是一种应用流式处理框架在消息队列系统上的一种应用模式的实现。  </p>
<a id="more"></a>  
<p><the rest="" of="" contents="" |="" 余下全文="">  </the></p>
<h3 id="需要解决的问题"><a href="#需要解决的问题" class="headerlink" title="需要解决的问题"></a>需要解决的问题</h3><p>比如分区：如何划分流？如何划分处理器？如何管理状态，其中状态本质上是指在处理器中维护的介于消息之间的东西，或者如果每次有消息到达的时候，计数器就会加1，那么它也可以是像总数这样的东西。如何重新处理？</p>
<p>至于失败语义，我们会得到至少一次，或者至多一次，或者恰好一次消息，也有不确定性。如果流处理器与另一个系统交互，无论它是个数据库，还是依赖于时间或者消息的顺序，如何处理那些真正决定最终输出结果的数据？</p>
<h3 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h3><p>Samza的一个job的基本处理流程是一个用户任务从一个或多个输入流中读取数据，再输出到一个或多个输出流中，具体映射到kafka上就是从一个或多个topic读入数据，再写出到另一个或多个topic中去。多个job串联起来就完成了流式的数据处理流程。</p>
<p>这种模式其实有点像MapReduce的过程，stream输入部分由kafka的partition决定了分区和task数目，类似于一个Map过程，输出时由用户task指定topic和分区（或者框架自动由Key决定分区），这相当于一次shuffle的过程，下一个job读取新的stream时，可以认为是一个reduce，也可以认为是下一个map过程的开始。</p>
<p>不同之处在于job之间的串联无需等待上一个job的结束，类实时的消息分发机制决定了整个串联的job是连续不间断的，亦即流式的。</p>
<h3 id="应用场景举例"><a href="#应用场景举例" class="headerlink" title="应用场景举例"></a>应用场景举例</h3><ul>
<li>流处理方面<ul>
<li>处理topic：最常见的对kafka中的topic进行消费，然后对消息进行处理，生成新的topic发送到kafka。</li>
<li>镜像topic：对kafka中的数据流直接进行消费，然后不经过处理，直接在另一个kafka集群上生成一个镜像的kafka topic。</li>
<li>关联topic：利用samza的状态管理，可以将kafka中的两个topic进行关联。例如，广告的点击topic和转化topic可以通过samza的状态管理中的key-value存储，然后merge起来。</li>
</ul>
</li>
<li>有状态的分布式事件驱动服务<ul>
<li>有状态的事件驱动服务的状态管理，利用远程数据库或者系统内部维护状态。利用远程数据库会有I/O或者CPU瓶颈，系统内部维护状态在分布式的情况下容错处理实现也比较麻烦。而Samza集成本地的key-value数据库RocksDB，state的change会生成changelog stream放在kafka上，容错性好。</li>
</ul>
</li>
</ul>
<h3 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h3><p>Samza是一个流式计算框架，它有以下特性：</p>
<ul>
<li>简单的API：和绝大多数低层次消息系统API不同，相比MapReduce，Samza提供了一个非常简单的“基于回调（callback-based）”的消息处理API</li>
<li>管理状态：Samza管理快照和流处理器的状态恢复。当处理器重启，Samza恢复其状态一致的快照。Samza的建立是为了处理大量的状态</li>
<li>容错性：当集群中有一台机器宕机了，基于Yarn管理的Samza会立即将你的任务导向另一台机器；</li>
<li>持久性：Samza通过Kafka保证消息按顺序写入对应分区，并且不会丢失消息；</li>
<li>扩展性：Samza在每一层都做了分区和分布。Kafka提供了顺序的、分区、可复制的、容错的流。YARN则为Samza的运行提供了一个分布式环境</li>
<li>可插拔：虽然Samza在Kafka和YARN的外部工作，但是Samza提供了可以让你在其它消息系统和执行环境里运行的可插拔的API</li>
<li>处理器隔离：运行在YARN上的Samza同样支持Hadoop安全模型以及通过linux CGroups进行资源隔离</li>
</ul>
<p>Samza区别于其他框架的几个方面：</p>
<ul>
<li>Samza支持局部状态的容错。状态自己作为一个流被构造。如果因为机器宕机本地状态丢失，那么状态流会回放重新存储它</li>
<li>流是有序、分区的、可回放的并且是容错的</li>
<li>YARN用来处理隔离、安全和容错</li>
<li>任务之间是解耦的：如果有一个任务慢了并且造成了消息的积压，系统其它部分不会受到影响；</li>
</ul>
<h2 id="一些基本概念"><a href="#一些基本概念" class="headerlink" title="一些基本概念"></a>一些基本概念</h2><h3 id="流（Streams）"><a href="#流（Streams）" class="headerlink" title="流（Streams）"></a>流（Streams）</h3><p>Samza处理流。流是由一定数量的类型或类别相似的不可变消息组成。  </p>
<ul>
<li>kafka里，流是一个topic（话题） </li>
<li>数据库里，我们可以通过消费从一个表里更新操作读取一个流  </li>
<li>hadoop里，我们可能跟踪在hdfs上的一个目录下的文件</li>
</ul>
<h3 id="作业（job）"><a href="#作业（job）" class="headerlink" title="作业（job）"></a>作业（job）</h3><p>Samza的jobs 是将输入流进行逻辑处理，然后转化成输出流的程序。</p>
<p>为了扩展流处理器的吞吐量，stream拆分成Partitions</p>
<blockquote>
<p>Streams–&gt;Partitions</p>
</blockquote>
<p>job拆分更小的并行单元任务Tasks</p>
<blockquote>
<p>job–&gt;tasks</p>
</blockquote>
<h3 id="分区（Partitions）"><a href="#分区（Partitions）" class="headerlink" title="分区（Partitions）"></a>分区（Partitions）</h3><p>每个流都被分割成一个或多个分区，并且在流里的每一个分区都总是一个有序的消息序列。每个消息在这个序列里有一个被叫做offset（中文称它为偏移量），它在每一个分区里都是唯一的。这个偏移量可以是一个连续的整数、字节偏移量或者字符串，这取决于底层的系统实现了。</p>
<p>当有一个消息加入到流中，它只会追加到流的分区中的一个。这个消息通过写入者带着一个被选择的key分配到它对应的分区中。举个例子，如果用户id被用作key，那么所有和用户id相关的消息都应该追加到这个分区中。<br><img src="https://samza.apache.org/img/0.10/learn/documentation/introduction/stream.png" alt="image"></p>
<h3 id="任务（task）"><a href="#任务（task）" class="headerlink" title="任务（task）"></a>任务（task）</h3><p>一个Job通过把他分割成多个任务Task进行扩展。每个任务Task消费来自一个Partitions的数据。</p>
<p>按照消息的偏移，一个任务按序处理来自它的输入分区的消息。分区之间没有定义顺序，这就允许每一个任务独立执行。YARN调度器负责分发任务给一台机器，所以作为一个整体的工作Job可以分配到多个机器并行执行。</p>
<p>在一个Job中任务Task的数量是由输入分区决定的（也就是说任务数目不能超过分区数目，否则就会存在没有输入的任务）。可是，你能改变分配给Job的计算资源（比如内存、cpu核数等）去满足job的需要，可以参考下面关于container的介绍。</p>
<p>另外一个值得注意的是分配给task的分区的任务绝不会改变：如果有一个任务在一台失效的机器上，这个task会被在其它地方重启，仍然会消费同一个流的分区。</p>
<p><img src="https://samza.apache.org/img/0.10/learn/documentation/introduction/job_detail.png" alt="image"></p>
<h3 id="Dataflow-Graphs"><a href="#Dataflow-Graphs" class="headerlink" title="Dataflow Graphs"></a>Dataflow Graphs</h3><p>我们能组合多个Jobs去创建一个数据流图（DAG 有向无环图），其中节点表示包含数据的流，而边则是进行数据传输。这个组合纯粹是通过Jobs作为输入和输出的流来完成。这些Jobs也是解耦的：他们不需要基于相同的代码库，并且添加、删除或者重启一个下游任务不会影响上游的任务。<br><img src="https://samza.apache.org/img/0.10/learn/documentation/introduction/dag.png" alt="image"></p>
<h3 id="其他概念"><a href="#其他概念" class="headerlink" title="其他概念"></a>其他概念</h3><ul>
<li>Containers——分区Partitions和任务Tasks都是并行的逻辑单元。Containers是物理的并行单元，并且一个容器本质上是一个Unix进程（或者Linux cgroup）。每个容器跑着一个或多个Tasks。Tasks的数量是从输入的分区数自动确定和固定下来的，但是容器的数量（CPU、内存资源）是在运行时用户设定的并且能在任何时刻改变。</li>
<li>TaskRunner——TaskRunner是Samza的流处理容器。它负责启动、执行以及关闭一个或多个StreamTask实例。</li>
<li>“检查点（Checkpointing）”——检查点通常用于故障恢复，实现“at least once”语义。如果一个taskrunner由于某种原因宕掉了（比如，硬件故障），当重新启动时，它应该使用最后离开时的消息——这是通过检查点实现的。</li>
<li>状态管理（State Management）——需要在不同的消息处理之间传递的数据称之为状态——它可以是保存一个总数那样简单的东西，也可以是复杂得多的东西。Samza允许任务维持一种持久可变且可查询的状态，而且，它与每个任务在物理上处于同一位置。状态需要具备高可用性：如果出现任务失败的情况，它可以在任务故障转移到另一台机器时还原。</li>
<li>周期任务（Windowing）——有一些需要周期执行的任务</li>
<li>监控相关（Metrix&amp;&amp;JMX）——当在生产中运行stream process过程,用Metrix（度量）来跟踪job的运行，Metrix有kafka流或者JMX的方式。</li>
</ul>
<p>在Samza架构之后，会具体介绍这些概念。</p>
<h2 id="Samza-架构"><a href="#Samza-架构" class="headerlink" title="Samza 架构"></a>Samza 架构</h2><p>Samza是由以下三层构成：  </p>
<ul>
<li>数据流层（A streaming layer）：分布式消息中间件Kafka  </li>
<li>执行层（An execution layer）：Hadoop资源调度管理系统YARN  </li>
<li>处理层（A progressing layer）：Samza API   </li>
</ul>
<p><img src="https://samza.apache.org/img/0.10/learn/documentation/introduction/samza-ecosystem.png" alt="image"></p>
<h3 id="kafka"><a href="#kafka" class="headerlink" title="kafka"></a>kafka</h3><p>kafka相关内容可以参考另一篇博客<a href="https://fangyeqing.github.io/2016/10/28/kafka---%E4%BB%8B%E7%BB%8D/">kafka介绍</a>。</p>
<p>Kafka是一个分布式发布/订阅消息队列系统，它支持<strong>at-least once</strong>通信保障（即系统保证没有信息丢失，但是在某些故障情况下，消费者可能收到超过一条同样的信息）和<strong>高度可用的分区</strong>特性（即使一台机器宕机了，分区依然是可用的）。</p>
<p>每一条数据流被称为一个topic。每一个话题都在多台被称作broker的机器上进行分区和复制。当一个生产者发送一条消息给一个话题，它会提供一个key，这个key被用来决定这条消息应该被发送到哪一个分区。生产者发送信息而Kafka的broker则接收和存储它们。Kafka的消费者能通过在一个话题的所有分区上订阅消息来读取消息。</p>
<p>Kafka有一些有趣的特点：</p>
<ul>
<li>同一个key的所有消息都被划分到同一个分区，这就意味着如果你想要读到一个特定用户的所有消息，你只要从包含这个用户id的分区读取即可，而不是整个topic（假设把用户id用作key）</li>
<li>一个topic的分区是按顺序到达的一序列消息，所以你可以通过单调递增偏移量offset来引用任何消息（就好比放一个索引到一个数组里）；这也意味着broker不需要跟踪被一个特定的消费者读取的消息，为什么呢？因为消费者保存了消息的偏移量offset能够跟踪到它。然后我们知道的是带着一个比当前偏移量小的消息是已经被处理过的，而每一个带着更大偏移量的消息还没有被处理过。</li>
</ul>
<h3 id="YARN"><a href="#YARN" class="headerlink" title="YARN"></a>YARN</h3><p>YARN有三个组成部分：资源管理器（ResourceManager）、节点管理器（NodeManager）和应用管理器（ApplicationMaster）。</p>
<ul>
<li>NodeManager：在一个YARN网格里，每一台机器上都跑着NodeManager，它负责在所在的机器上启动进程。</li>
<li>ResourceManager与所有的NodeMananger交互告诉它们跑什么应用，反过来NodeManager也会告诉ResourceManager它们希望什么时间在集群里跑这些东东。</li>
<li>ApplicationMaster让特定应用的代码跑在YARN集群上，它负责管理应用的负载、容器（通常是UNIX进程），并且当其中一个容器失败时发出通知。</li>
</ul>
<p>Samza提供了一个YARN ApplicationMaster和一个开箱即用的YARN Job运行器。如图所示（不同的颜色表示不同的机器）</p>
<p><img src="https://samza.apache.org/img/0.10/learn/documentation/introduction/samza-yarn-kafka-integration.png" alt="image"></p>
<p>Samza的客户端告诉YARN的RM（ResourceManager，以下简称RM）运行一个新的Job，RM会告诉YARN的一个NodeManager（简称NM）为Samza的ApplicationMaster（AM）在集群里分配空间。一旦NM分配了空间，就会启动这个Samza的AM。AM开始后，它会向RM请求运行SamzaContainers所需的YARN containers。RM和NMs一起为containers分配空间。一旦空间被分配，NMs就会开启Samza containers。  </p>
<p>YARN启动并且监控一个或者多个SamzaContainers，并且你的处理逻辑代码（使用StreamTask API）在这些容器里运行。这些Samza 流任务的输入和输出都来自Kafka的Brokers（通常他们都是作为YARN NMs位于同台机器）</p>
<p>通过对topic的分区，将数据流处理拆解到任务中以及在多台机器上并行执行任务，使得Samza具有很高的消息吞吐量。通过结合YARN和Kafka，Samza实现了高容错：如果一个进程或者机器失败，它会自动在另一台机器上重启它并且继续从消息终端的地方开始处理，这些都是自动化的。</p>
<h2 id="SamzaContainer"><a href="#SamzaContainer" class="headerlink" title="SamzaContainer"></a>SamzaContainer</h2><p>SamzaContainer负责管理一个或多个StreamTask实例的启动，执行和关闭。每个SamzaContainer通常在独立的Java虚拟机上运行。一个Samza job可以由几个SamzaContainers组成，并可以在在不同的机器上运行。</p>
<p>当SamzaContainer启动时，它按照顺序执行以下操作：  </p>
<ul>
<li>获取每个输入流的分区的最后一个checkpoint记录的偏移量，并从此位置开始处理消息  </li>
<li>作为消费者，对于每一个输入流分区创建一个“reader”线程</li>
<li>启动度量监控器（metrics reporters），监控度量指标</li>
<li>启动定时器检查站（checkpoint timer），每隔一段时间，保存任务的输入流中的偏移量</li>
<li>如果定义了任务的windows方法，将启动一个窗口定时器（window timer），触发任务的windows方法</li>
<li>为每个kafka输入流的分区实例化和初始化StreamTask（即调用InitableTask的init方法）</li>
<li>启动事件循环（event loop），从reader线程读取消息，传递到StreamTask</li>
</ul>
<h3 id="Event-Loop"><a href="#Event-Loop" class="headerlink" title="Event Loop"></a>Event Loop</h3><p>事件循环是container的一个单线程，负责读写消息,传递指标（metrix）、checkpoint周期执行和window周期执行。事件循环的工作原理如下:</p>
<ul>
<li>从传入消息队列获取消息;</li>
<li>通过调用process()给适当的任务实例传递信息;</li>
<li>如果任务实例实现WindowableTask并且窗口周期时间到了,在该任务实例上调用window();</li>
<li>从process()和window()调用适当的SystemProducers输出消息;</li>
<li>时间间隔到了，写checkpoint</li>
</ul>
<h3 id="任务与分区-Tasks-and-Partitions"><a href="#任务与分区-Tasks-and-Partitions" class="headerlink" title="任务与分区(Tasks and Partitions)"></a>任务与分区(Tasks and Partitions)</h3><p>通过前面的介绍可以得知，samza job划分为task，samza stream划分为partition。单个task消费并处理stream中单个partition的消息。</p>
<p>因此，samza job的input stream有多少个partition，就会创建多少个samza task 的实例。</p>
<p><img src="http://samza.apache.org/img/0.8/learn/documentation/container/tasks-and-partitions.svg" alt="image"></p>
<p>samza stream的partition数量，取决于消费的系统。</p>
<p>例如，如果的数据流是通过kafka系统来实现的，那么数据流的partition数量是kafka的topic的分区数。是你创建kafka队列的时候的cmd决定的。如果cmd中没有指定，那么默认是通过 kafka的服务器端配置中的num.partitions这个阐述。</p>
<p>如果samza job多于一个input stream，那么，对应到Samza job 的task实例，将是所有input stream中partition的最大值。例如：如果一个Samza job从PageViewEvent（12 partition）和ServiceMetricEvent（14 partition），那么，将会产生14个task实例（从0到13）。task实例12和13将只用来读取和ServiceMetricEvent事件，因为PageViewEvent没有对应的partition。</p>
<h3 id="容器和资源分配"><a href="#容器和资源分配" class="headerlink" title="容器和资源分配"></a>容器和资源分配</h3><p>task实例的数量由input stream的partition数决定。</p>
<p>SamzaContainer数，是否什么决定的呢?如果使用yarn，容器的数量是由分配给你的CPU和内存资源决定的。</p>
<p>每一个SamzaContainer被设计成只是用一个CPU，因此他用了单线程事件循环的模式。因此，你在开发程序的时候，不要再SamzaContainer创建自己的多线程。如果你需要进行并行，你需要配置一下你的job利用多SamzaContainer。</p>
<h3 id="多个输入流"><a href="#多个输入流" class="headerlink" title="多个输入流 　　 　　"></a>多个输入流 　　 　　</h3><p>如果你的工作有多个输入流,Samza提供了一个简单但强大的机制来加入数据从不同的来源:每个任务实例接收消息从一个分区的每个输入流。例如,假设您有两个输入流,A和B,每四个分区。Samza创建了四个任务实例流程,分配分区如下:<br>Task instance|Consumes stream partitions<br>—|—<br>0|stream A partition 0, stream B partition 0<br>1|stream A partition 1, stream B partition 1<br>2|stream A partition 2, stream B partition 2<br>3|stream A partition 3, stream B partition 3</p>
<p>因此,如果想要两个在不同的流中的事件被同样的任务实例处理,需要确保它们被发送到相同的分区号，即使用相同的key发送消息。</p>
<h2 id="Stream"><a href="#Stream" class="headerlink" title="Stream"></a>Stream</h2><p>SamzaContainer 是通过 SystemConsumer 与 SystemProducer 接口进行消息得读取与写入。你可以通过这两个接口实现对任何消息系统得整合。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">public interface SystemConsumer &#123;</div><div class="line">  void start();</div><div class="line">  void stop();</div><div class="line">  void register(SystemStreamPartition systemStreamPartition, String lastReadOffset);</div><div class="line"></div><div class="line">  List&lt;IncomingMessageEnvelope&gt; poll(</div><div class="line">      Map&lt;SystemStreamPartition, Integer&gt; systemStreamPartitions,</div><div class="line">      long timeout)</div><div class="line">    throws InterruptedException;</div><div class="line">&#125;</div><div class="line"></div><div class="line">public interface SystemProducer &#123;</div><div class="line">  void start();</div><div class="line">  void stop();</div><div class="line">  void register(String source);</div><div class="line"></div><div class="line">  void send(String source, OutgoingMessageEnvelope envelope);</div><div class="line">  void flush(String source);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>特点：</p>
<ul>
<li><p>插件式：开箱即用，Samza实现了对kafka的支持（KafkaSystemConsumer和KafkaSystemProducer）。然而，任何消息总线系统都可以被整合，只要它能提供由Samza所需的接口。</p>
</li>
<li><p>消息类型多样：SystemConsumers和SystemProducers可以读取和写入任何数据类型的消息。<br>  Samza没有规定任何具体的数据模型或序列化格式，具体形式可以由开发人员实现。如果他们只支持byte数组也没有关系——Samza有一个独立的串行化层,将之转化为应用程序代码可以使用对象。</p>
</li>
</ul>
<h3 id="流处理"><a href="#流处理" class="headerlink" title="流处理"></a>流处理</h3><p>如果job从多个输入数据流处处理消息，并且所有输入流消息可用，缺省情况下将在一个循环赛的方式逐个处理。</p>
<p>例如，如果一个job需要处理AdImpressionEvent和AdClickEvent的消息，任务实例的process（）方法被调用，来处理AdImpressionEvent消息，再处理AdClickEvent消息，然后从AdImpressionEvent处理另一个消息，…，并继续在这两者之间交替处理。</p>
<p>如果流处理系统处理中如果一个输入流没有消息，那么流处理系统将跳过这个输入流进行处理另外一个输入流。同时，还会继续检查空输入流是否有新的消息进来。</p>
<h3 id="MessageChooser"><a href="#MessageChooser" class="headerlink" title="MessageChooser"></a>MessageChooser</h3><p>当Samza容器对不同的流分区传入的消息进行处理的时候，它是如何决定要首先处理拿一个？该行为是由一个MessageChooser决定。默认选择器是RoundRobinChooser，但你可以自己实现自定义选择器覆盖它。</p>
<p>实现自己的MessageChooser，你需要实现MessageChooserFactory接口，并在配置文件中设置“task.chooser.class”，并配置您实现的完全类名：</p>
<p>task.chooser.class=com.example.samza.YourMessageChooserFactory</p>
<h3 id="优先输入流"><a href="#优先输入流" class="headerlink" title="优先输入流"></a>优先输入流</h3><p>在一定得时间窗口内，可以让一个输入流得处理比另一个输入流得处理有更高得优先级别，我们可以通过设置输入流得优先级别。例如：samza得job需要处理2个输入流，其中一个输入流由实时系统提供消息，另外一个由批处理系统提供处理消息。在这个案例中，我们将给实时输入流提供更高得优先级。可以使实时输入数据流系统不会产生突然变慢得情况。</p>
<p>例如，我们可以再配置文件中设置如下：</p>
<p>systems.kafka.streams.my-real-time-stream.samza.priority=2<br>systems.kafka.streams.my-batch-stream.samza.priority=1</p>
<h3 id="引导顺序"><a href="#引导顺序" class="headerlink" title="引导顺序"></a>引导顺序</h3><p>略</p>
<h3 id="批处理"><a href="#批处理" class="headerlink" title="批处理"></a>批处理</h3><p>在某些情况下，可以提高每次从多个分区消费多个消息，从而提高消息得处理能力。 Samza支持这种操作模式，被称为批处理。</p>
<p>例如，如果你想读的100条信息从每个流分区行，你可以使用这个配置参数：</p>
<p>task.consumer.batch.size=100</p>
<h2 id="Serialization"><a href="#Serialization" class="headerlink" title="Serialization"></a>Serialization</h2><p>任何消息最终都需要被序列化成字节（通过网络发送或写到本地磁盘），包括读取或写入的流数据或者持久化状态信息存储。序列化和反序列化可能发生在各种地方：</p>
<ol>
<li>在客户端lib库中：例如，从kafka进行生产或者消费支持可插入的序列化。</li>
<li>在任务的执行中：你的process程序将原始字节作为inputs与outputs，并进行任何解析和序列化。</li>
<li>在两者之间: Samza 提供了一层专门进行序列化与反序列化，叫做SERDE层。 </li>
</ol>
<p>你可以使用任何方式做这块工作;samza不会强加任何特定的数据模型或序列化模式。然而，<strong>最合理的做法，通常是使用Samza的SERDE层</strong>。</p>
<h3 id="Serde层类型"><a href="#Serde层类型" class="headerlink" title="Serde层类型"></a>Serde层类型</h3><p>每个serde通过一个工厂类定义。可以通过实现SerdeFactory接口创建自己的序列化器。以下是Samza自带的serde类型的列表：</p>
<table>
<thead>
<tr>
<th>Serde Name</th>
<th>Data Handled</th>
</tr>
</thead>
<tbody>
<tr>
<td>string</td>
<td>UTF-8 strings</td>
</tr>
<tr>
<td>integer</td>
<td>binary-encoded integers</td>
</tr>
<tr>
<td>serializable</td>
<td>Serializable Object Type</td>
</tr>
<tr>
<td>long</td>
<td>long data type</td>
</tr>
<tr>
<td>json</td>
<td>JSON formatted data</td>
</tr>
<tr>
<td>byte</td>
<td>Plain Bytes (effectively no-op) - Useful for Binary Messages</td>
</tr>
<tr>
<td>bytebuffer</td>
<td>Byte Buffer</td>
</tr>
</tbody>
</table>
<p>例如：在配置文件中，定义名为“string”的serde。将用于名为“kafka”的system中对输入流中的key反序列化,并序列化输出流中的key<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">serializers.registry.byte.class=org.apache.samza.serializers.ByteSerdeFactory</div><div class="line">serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory</div><div class="line"></div><div class="line">systems.kafka.samza.msg.serde=byte</div><div class="line">systems.kafka.samza.key.serde=string</div></pre></td></tr></table></figure></p>
<h2 id="Checkpointing"><a href="#Checkpointing" class="headerlink" title="Checkpointing"></a>Checkpointing</h2><p>Samza提供对流的容错性处理：Samza保证信息不会丢失，即使你的job崩溃，或者是一台机器down掉了，再或是网络故障，还是其他什么地方出了问题。为了提供这种保障，Samza期望的输入流系统，要能以满足以下要求：</p>
<ul>
<li>该流可以分成一个或多个分区。每个分区是独立的，分区的副本在多台机器复制（即使一台机器出现故障，流仍然可用）。</li>
<li>每个分区包含在一个固定的顺序的序列消息。每个消息都有一个偏移量，这表明其在该序列的位置。每个分区内消息总是按顺序消费</li>
<li>一个Samza作业可以从消息序列的任何位置开始处理消息。</li>
</ul>
<p>kafka满足上面的要求。samza也可以整合其他的message broker系统。</p>
<p>我们描述一下SamzaContainer的处理场景，每个task实例将会消费一个输入流的一个分区，每个task都会保存每个分区当前处理得offset值。每一次处理一个消息，offset将往前移动一位。</p>
<p>如果SamzaContainer失败，需要重新启动能够恢复到处理失败的地方，为了能够做到这一点，需要SamzaContainer能够保存每个task实例当前处理的offset位置。</p>
<p><img src="https://samza.apache.org/img/0.11/learn/documentation/container/checkpointing.svg" alt="image"></p>
<p>Checkpoint源码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">public interface CheckpointManager &#123;</div><div class="line">  void start();</div><div class="line">  void register(Partition partition);</div><div class="line">  void writeCheckpoint(Partition partition, Checkpoint checkpoint);</div><div class="line">  Checkpoint readLastCheckpoint(Partition partition);</div><div class="line">  void stop();</div><div class="line">&#125;</div><div class="line"></div><div class="line">public class Checkpoint &#123;</div><div class="line">    private final Map&lt;SystemStreamPartition, String&gt; offsets;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="at-least-once处理"><a href="#at-least-once处理" class="headerlink" title="at-least-once处理"></a>at-least-once处理</h3><p>通过event loop，container定期为每一个任务实例checkpoint——即：记录每个partition的当前offset。</p>
<p>container启动时,它寻找最近的checkpoint,开始从该checkpoint记录的partion的offset处消费消息。如果前面的container 意外失败,checkpoint记录的offset不会移动，最近的checkpoint会落后当前topic的offset(即这个job下次再执行时，可能重复process了一些消息，但是不会错过任何消息)</p>
<p>有些场景下，“at-least-once”这种策略满足不了要求。exact once在后续版本会开发。目前只能通过减少写checkpoint的时间间隔来减少这种影响,可能要以性能开销为代价。配置如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">task.commit.ms</div></pre></td></tr></table></figure></p>
<p>如果实时性要求不高，准确性要求比较高，必须实现exact once。利用Camus或者Gobbin将kafka topic落地到HDFS，然后做去重即可。其中Camus可以参考我的另一篇博客<a href="https://fangyeqing.github.io/2016/12/01/Camus%E4%BB%8B%E7%BB%8D/">Camus介绍</a>。</p>
<h3 id="配置checkpoint"><a href="#配置checkpoint" class="headerlink" title="配置checkpoint"></a>配置checkpoint</h3><p>提供两种：FileSystemCheckpointManager and KafkaCheckpointManager  </p>
<p>分别将checkpoint存在本地文件中和kafka中<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"># The name of your job determines the name under which checkpoints will be stored</div><div class="line">job.name=example-job</div><div class="line"></div><div class="line"># Define a system called &quot;kafka&quot; for consuming and producing to a Kafka cluster</div><div class="line">systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory</div><div class="line"></div><div class="line"># Declare that we want our job&apos;s checkpoints to be written to Kafka</div><div class="line">task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory</div><div class="line">task.checkpoint.system=kafka</div><div class="line"></div><div class="line"># By default, a checkpoint is written every 60 seconds. You can change this if you like.</div><div class="line">task.commit.ms=60000</div></pre></td></tr></table></figure></p>
<p>samza会向kafka中写入单独的一个topic–<strong>__samza<em>checkpoint</em><job-name>_<job-id></job-id></job-name></strong><br>上述配置的叫：__samza_checkpoint_example-job_1</p>
<h2 id="State-Management"><a href="#State-Management" class="headerlink" title="State Management"></a>State Management</h2><h3 id="状态管理的分类"><a href="#状态管理的分类" class="headerlink" title="状态管理的分类"></a>状态管理的分类</h3><table>
<thead>
<tr>
<th>分类</th>
<th>是否保留state</th>
<th>场景</th>
<th>类比sql</th>
</tr>
</thead>
<tbody>
<tr>
<td>stateless</td>
<td>不需要</td>
<td>一次处理一条消息、基于某些条件过滤消息</td>
<td>select … where…</td>
</tr>
<tr>
<td>stateful</td>
<td>需要</td>
<td>Windowed aggregation(ranking, trend detection, count)、Join (Stream-table, Stream-stream)</td>
<td>aggregation和join</td>
</tr>
</tbody>
</table>
<p>那么，问题来了, 如果保证临时state不丢失?</p>
<h3 id="老的管理任务状态的方法"><a href="#老的管理任务状态的方法" class="headerlink" title="老的管理任务状态的方法"></a>老的管理任务状态的方法</h3><h4 id="In-memory-state-with-checkpointing"><a href="#In-memory-state-with-checkpointing" class="headerlink" title="In-memory state with checkpointing"></a>In-memory state with checkpointing</h4><p>周期性的把task在内存中的数据做checkpoint. S4的状态管理就是这样做的。<br>缺点是当作为state的数据量很大时，每次都完全dump所有数据不切实际，如果用diff又太复杂。</p>
<h4 id="Using-an-external-store"><a href="#Using-an-external-store" class="headerlink" title="Using an external store"></a>Using an external store</h4><p>把状态写进一个外部的数据库或者key-value store中。</p>
<p>这样数据是不会丢了, 但是明显效率会有问题<br>而且会产生对其他系统的依赖性<br>还会影响正确性, 比如当task失败了, 之前的state需要作废,   如何让外部存储上的数据回滚  </p>
<h3 id="Samza管理任务的方法——Local-state-in-Samza"><a href="#Samza管理任务的方法——Local-state-in-Samza" class="headerlink" title="Samza管理任务的方法——Local state in Samza"></a>Samza管理任务的方法——Local state in Samza</h3><p>samza相当于结合上述两处的优点。   </p>
<ul>
<li>local：存整个state，但是存在硬盘上。samza采用Key-value数据库存储：RocksDB。每个Task对应一个RocksDB，隔离性高，本地存储吞吐高。       </li>
<li>external：state的change会生成changelog stream放在kafka上。<br>这样当有task failover的时候, 可以从kafka上读出change log, 并replay出local state</li>
</ul>
<p><img src="http://samza.apache.org/img/0.10/learn/documentation/container/stateful_job.png" alt="image"></p>
<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"># Use the key-value store implementation for a store called &quot;my-store&quot;</div><div class="line">stores.my-store.factory=org.apache.samza.storage.kv.RocksDbKeyValueStorageEngineFactory</div><div class="line"></div><div class="line"># Use the Kafka topic &quot;my-store-changelog&quot; as the changelog stream for this store.</div><div class="line"># This enables automatic recovery of the store after a failure. If you don&apos;t</div><div class="line"># configure this, no changelog stream will be generated.</div><div class="line">stores.my-store.changelog=kafka.my-store-changelog</div><div class="line"></div><div class="line"># Encode keys and values in the store as UTF-8 strings.</div><div class="line">serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory</div><div class="line">stores.my-store.key.serde=string</div><div class="line">stores.my-store.msg.serde=string</div></pre></td></tr></table></figure>
<h3 id="举例"><a href="#举例" class="headerlink" title="举例"></a>举例</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">public class MyStatefulTask implements StreamTask, InitableTask &#123;</div><div class="line">  private KeyValueStore&lt;String, String&gt; store;</div><div class="line"></div><div class="line">  public void init(Config config, TaskContext context) &#123;</div><div class="line">    this.store = (KeyValueStore&lt;String, String&gt;) context.getStore(&quot;my-store&quot;);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  public void process(IncomingMessageEnvelope envelope,</div><div class="line">                      MessageCollector collector,</div><div class="line">                      TaskCoordinator coordinator) &#123;</div><div class="line">    store.put((String) envelope.getKey(), (String) envelope.getMessage());</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="Windowing"><a href="#Windowing" class="headerlink" title="Windowing"></a>Windowing</h2><p>有些流处理job需要周期执行。  </p>
<h3 id="配置-1"><a href="#配置-1" class="headerlink" title="配置"></a>配置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># Call the window() method every 60 seconds</div><div class="line">task.window.ms=60000</div></pre></td></tr></table></figure>
<h3 id="举例-1"><a href="#举例-1" class="headerlink" title="举例"></a>举例</h3><p>假设你想报告每分钟pv。每当你看到pv事件，需要增加一个计数。每到一分钟,你当前的计数器值发送到输出流，计数器重置为零。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">public class EventCounterTask implements StreamTask, WindowableTask &#123;</div><div class="line"></div><div class="line">  public static final SystemStream OUTPUT_STREAM =</div><div class="line">    new SystemStream(&quot;kafka&quot;, &quot;events-per-minute&quot;);</div><div class="line"></div><div class="line">  private int eventsSeen = 0;</div><div class="line"></div><div class="line">  public void process(IncomingMessageEnvelope envelope,</div><div class="line">                      MessageCollector collector,</div><div class="line">                      TaskCoordinator coordinator) &#123;</div><div class="line">    eventsSeen++;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  public void window(MessageCollector collector,</div><div class="line">                     TaskCoordinator coordinator) &#123;</div><div class="line">    collector.send(new OutgoingMessageEnvelope(OUTPUT_STREAM, eventsSeen));</div><div class="line">    eventsSeen = 0;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><ol>
<li><p>与process一样，不要在windows()之外使用MessageCollector。</p>
</li>
<li><p>Samza使用单线程执行,所以window()调用不能和一个process()同时发生调用。</p>
<ul>
<li>优势：不需要担心线程安全的代码(没有需要同步)</li>
<li>缺点:如果process()方法需要很长时间返回，window()调用可能推迟。</li>
</ul>
</li>
</ol>
<h2 id="Metrix"><a href="#Metrix" class="headerlink" title="Metrix"></a>Metrix</h2><p>当在生产中运行stream process过程,有合理的metrix（度量）来跟踪job的运行是很重要的。Samza提供封装好的metrix库。Samza本身生成消息吞吐量等标准指标,也可以自定义指标。</p>
<h3 id="metrix上报方式"><a href="#metrix上报方式" class="headerlink" title="metrix上报方式"></a>metrix上报方式</h3><ul>
<li>JmxReporterFactory方式（jvm）：<br>每个容器的指标作为JMX mbean，即通过jmx可以监控，见下节。</li>
<li>MetricsSnapshotReporterFactory方式（kafka）：<br>reporter每分钟将指标作为消息发送到kafka输出流。输出流用metrics.reporter.*.stream配置<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"># Define a metrics reporter called &quot;snapshot&quot;, which publishes metrics every 60 seconds.</div><div class="line">metrics.reporters=snapshot</div><div class="line">metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory</div><div class="line"></div><div class="line"># Tell the snapshot reporter to publish to a topic called &quot;metrics&quot;in the &quot;kafka&quot; system.</div><div class="line">metrics.reporter.snapshot.stream=kafka.metrics</div><div class="line"></div><div class="line"># Encode metrics data as JSON.</div><div class="line">serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory</div><div class="line">systems.kafka.streams.metrics.samza.msg.serde=metrics</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="默认metrix内容"><a href="#默认metrix内容" class="headerlink" title="默认metrix内容"></a>默认metrix内容</h3><p>这个配置,job每隔60秒自动发送几个json编码的消息到kafka的“metrics”话题。像这样的消息:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">  &quot;header&quot;: &#123;</div><div class="line">    &quot;container-name&quot;: &quot;samza-container-0&quot;,</div><div class="line">    &quot;host&quot;: &quot;samza-grid-1234.example.com&quot;,</div><div class="line">    &quot;job-id&quot;: &quot;1&quot;,</div><div class="line">    &quot;job-name&quot;: &quot;my-samza-job&quot;,</div><div class="line">    &quot;reset-time&quot;: 1401729000347,</div><div class="line">    &quot;samza-version&quot;: &quot;0.0.1&quot;,</div><div class="line">    &quot;source&quot;: &quot;Partition-2&quot;,</div><div class="line">    &quot;time&quot;: 1401729420566,</div><div class="line">    &quot;version&quot;: &quot;0.0.1&quot;</div><div class="line">  &#125;,</div><div class="line">  &quot;metrics&quot;: &#123;</div><div class="line">    &quot;org.apache.samza.container.TaskInstanceMetrics&quot;: &#123;</div><div class="line">      &quot;commit-calls&quot;: 7,</div><div class="line">      &quot;commit-skipped&quot;: 77948,</div><div class="line">      &quot;kafka-input-topic-offset&quot;: &quot;1606&quot;,</div><div class="line">      &quot;messages-sent&quot;: 985,</div><div class="line">      &quot;process-calls&quot;: 1093,</div><div class="line">      &quot;send-calls&quot;: 985,</div><div class="line">      &quot;send-skipped&quot;: 76970,</div><div class="line">      &quot;window-calls&quot;: 0,</div><div class="line">      &quot;window-skipped&quot;: 77955</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>每个任务实例有一个单独的消息。</p>
<ul>
<li>header包括：job名称、job的ID、task分区。</li>
<li>metrics包括：已处理和发送消息的数量、当前输入流的分区的offset、其他细节。还有上述没有展示出来的：JVM信息(堆大小、垃圾收集信息、线程等),kafka的生产者和消费者的内部指标等</li>
</ul>
<h3 id="自定义metrix内容"><a href="#自定义metrix内容" class="headerlink" title="自定义metrix内容"></a>自定义metrix内容</h3><p>你可以通过MetricsRegistry注册您的自定义指标。需要实现InitableTask流任务,从TaskContext注册表得到指标。  </p>
<p><strong>自定义metrix种类</strong>:  </p>
<ul>
<li>counters（计数器）：当想要跟踪事物发生的频率</li>
<li>仪表(guages)：当想要报告事物的level,比如一个缓冲区的大小</li>
<li>定时器(timer)：当你想要知道代码块花多少时间</li>
</ul>
<p>counter源码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">public class Counter implements Metric &#123;</div><div class="line">    private final String name;</div><div class="line">    private final AtomicLong count;</div><div class="line"></div><div class="line">    public Counter(String name) &#123;</div><div class="line">        this.name = name;</div><div class="line">        this.count = new AtomicLong(0L);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    public long inc() &#123;</div><div class="line">        return this.inc(1L);</div><div class="line">    &#125;</div><div class="line">    .....</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这个简单的例子显示了如何计算你的任务处理的消息数量:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">public class MyJavaStreamTask implements StreamTask, InitableTask &#123;</div><div class="line">  private Counter messageCount;</div><div class="line"></div><div class="line">  public void init(Config config, TaskContext context) &#123;</div><div class="line">    this.messageCount = context</div><div class="line">      .getMetricsRegistry()</div><div class="line">      .newCounter(getClass().getName(), &quot;message-count&quot;);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  public void process(IncomingMessageEnvelope envelope,</div><div class="line">                      MessageCollector collector,</div><div class="line">                      TaskCoordinator coordinator) &#123;</div><div class="line">    messageCount.inc();</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="JMX"><a href="#JMX" class="headerlink" title="JMX"></a>JMX</h2><p>Samza容器和YARN ApplicationMaster默认支持JMX。可以使用JMX管理JVM;例如,可以使用包含在JDK中的jconsole连接到它。</p>
<p>可以告诉Samza发布其内部指标,你和任何自定义指标定义,作为JMX mbean。需要设置以下属性:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"># Define a Samza metrics reporter called &quot;jmx&quot;, which publishes to JMX</div><div class="line">metrics.reporter.jmx.class=org.apache.samza.metrics.reporter.JmxReporterFactory</div><div class="line"></div><div class="line"># Use it (if you have multiple reporters defined, separate them with commas)</div><div class="line">metrics.reporters=jmx</div></pre></td></tr></table></figure></p>
<p>JMX需要配置为使用一个特定的端口,但是在分布式环境中,没有办法提前知道哪些端口可用的机器运行您的容器。因此Samza JMX端口随机选择。如果你需要连接到它,你可以通过容器的日志找到port,报告JMX服务器详细信息如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">2014-06-02 21:50:17 JmxServer [INFO] According to InetAddress.getLocalHost.getHostName we are samza-grid-1234.example.com</div><div class="line">2014-06-02 21:50:17 JmxServer [INFO] Started JmxServer registry port=50214 server port=50215 url=service:jmx:rmi://localhost:50215/jndi/rmi://localhost:50214/jmxrmi</div><div class="line">2014-06-02 21:50:17 JmxServer [INFO] If you are tunneling, you might want to try JmxServer registry port=50214 server port=50215 url=service:jmx:rmi://samza-grid-1234.example.com:50215/jndi/rmi://samza-grid-1234.example.com:50214/jmxrmi</div></pre></td></tr></table></figure></p>
<h2 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h2><p><a href="https://samza.apache.org/learn/documentation/0.10/" target="_blank" rel="external">https://samza.apache.org/learn/documentation/0.10/</a><br><a href="https://github.com/feuyeux/hello-samza/blob/master/doc/0.hello_samza.md" target="_blank" rel="external">https://github.com/feuyeux/hello-samza/blob/master/doc/0.hello_samza.md</a><br><a href="http://wdxtub.com/vault/cc-21.html" target="_blank" rel="external">http://wdxtub.com/vault/cc-21.html</a><br><a href="http://www.infoq.com/cn/articles/linkedin-samza" target="_blank" rel="external">http://www.infoq.com/cn/articles/linkedin-samza</a><br><a href="http://blog.csdn.net/colorant/article/details/12082145" target="_blank" rel="external">http://blog.csdn.net/colorant/article/details/12082145</a><br><a href="https://wyyhzc.gitbooks.io/hadoop2x/content/samzacontainer.html" target="_blank" rel="external">https://wyyhzc.gitbooks.io/hadoop2x/content/samzacontainer.html</a></p>
</excerpt>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Samza1---Hello Samza]]></title>
      <url>https://fangyeqing.github.io/2016/11/17/Samza_1---Hello_Samza/</url>
      <content type="html"><![CDATA[<excerpt in="" index="" |="" 首页摘要="">   

<p><a href="http://samza.apache.org/startup/hello-samza/0.10/" target="_blank" rel="external">hello-samza</a>是官方给的例子，包括一整套运行环境，包括zookeeper、kafka、yarn、samza。虽然例子看起来很容易，但是跑起来感觉全是坑，毕竟用的公司的集群，没有root权限，然后例子给的都是国外的地址，访问速度很慢或者根本被墙了。想say hello不容易！<br><a id="more"></a>   </p>
<the rest="" of="" contents="" |="" 余下全文=""> 

<p>安装和配置Apache-Samza，需要jdk1.7+、maven2的环境</p>
<h2 id="下载源码"><a href="#下载源码" class="headerlink" title="下载源码"></a>下载源码</h2><p>官方给的<a href="https://git.apache.org/samza-hello-samza.git可能连接不上，换了一个" target="_blank" rel="external">https://git.apache.org/samza-hello-samza.git可能连接不上，换了一个</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">git clone https://github.com/apache/samza-hello-samza.git hello-samza</div><div class="line">cd hello-samza/</div></pre></td></tr></table></figure></p>
<h2 id="运行grid"><a href="#运行grid" class="headerlink" title="运行grid"></a>运行grid</h2><p>下载、安装相关系统<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bin/grid bootstrap</div></pre></td></tr></table></figure></p>
<p>虽然只有一句话，但是会执行如下，会下载并安装samza，zookeeper，yarn，kafka<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">stop all           #停止yarn|kafka|zookeeper</div><div class="line">install all        #安装</div><div class="line">start all          #启动</div></pre></td></tr></table></figure></p>
<p>可能出现很多问题</p>
<h4 id="出现问题："><a href="#出现问题：" class="headerlink" title="出现问题："></a>出现问题：</h4><ol>
<li>公司开发机，没有root权限，会有错误：  <blockquote>
<p>Caused by: java.io.IOException: No locks available</p>
</blockquote>
</li>
</ol>
<p>gradle的默认本地仓库是home下的 如~/.gradle<br>需要修改gradle和samza目录，在用户的home目录下建立软连接：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ln -s /disk1/fangyq/gradle ~/.gradle</div><div class="line">ln -s /disk1/fangyq/samza ~/.samza</div></pre></td></tr></table></figure></p>
<ol>
<li>改完继续执行bin/grid bootstrap,会出现超时，</li>
</ol>
<blockquote>
<p>fatal: unable to connect to git.apache.org:<br>git.apache.org[0: 54.84.58.65]: errno=Connection timed out</p>
</blockquote>
<p>修改bin/grid文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">git clone git://git.apache.org/samza.git                 #原地址</div><div class="line">git clone https://github.com/apache/samza.git            #现地址</div></pre></td></tr></table></figure></p>
<p>继续执行bin/grid bootstrap，下载、安装持续了很久。<br>再给我一次机会，肯定会改下载地址，下面自带的地址太慢了，hadoop的用了一个多小时。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">DOWNLOAD_KAFKA=http://www.us.apache.org/dist/kafka/0.8.2.1/kafka_2.10-0.8.2.1.tgz</div><div class="line">DOWNLOAD_YARN=https://archive.apache.org/dist/hadoop/common/hadoop-2.6.1/hadoop-2.6.1.tar.gz</div><div class="line">DOWNLOAD_ZOOKEEPER=http://archive.apache.org/dist/zookeeper/zookeeper-3.4.3/zookeeper-3.4.3.tar.gz</div></pre></td></tr></table></figure></p>
<p>安装完后，在deploy目录下有kafka，yarn，zookeeper的系统。<br>在自己建立软连接的目录下有samza。</p>
<p>查看是否安装成功：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">jps</div><div class="line"></div><div class="line">50500 NodeManager</div><div class="line">43877 Kafka</div><div class="line">56215 Jps</div><div class="line">50439 ResourceManager</div><div class="line">43721 QuorumPeerMain</div></pre></td></tr></table></figure></p>
<p>还可以通过浏览器访问来查看YARN UI：<br><a href="http://localhost:8088" target="_blank" rel="external">http://localhost:8088</a>   </p>
<h2 id="利用maven打包并解压"><a href="#利用maven打包并解压" class="headerlink" title="利用maven打包并解压"></a>利用maven打包并解压</h2><p>打包，要等很久。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mvn clean package</div></pre></td></tr></table></figure></p>
<h4 id="出现问题：-1"><a href="#出现问题：-1" class="headerlink" title="出现问题："></a>出现问题：</h4><blockquote>
<p>Too many files with unapproved license samza</p>
</blockquote>
<p>修改之后继续打包：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mvn -Drat.ignoreErrors=true  clean package</div></pre></td></tr></table></figure></p>
<p>解压：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mkdir -p deploy/samza</div><div class="line">tar -xvf target/hello-samza-0.10.1-dist.tar.gz -C deploy/samza</div></pre></td></tr></table></figure></p>
<h2 id="运行samza-job："><a href="#运行samza-job：" class="headerlink" title="运行samza job："></a>运行samza job：</h2><h3 id="数据获取job"><a href="#数据获取job" class="headerlink" title="数据获取job"></a>数据获取job</h3><p>该job是从在线的wikimedia实时消费数据，作为kafka的wikipedia-raw这个topic的producer。  </p>
<p>先看下将要运行的示例的input<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">less deploy/samza/config/wikipedia-feed.properties</div></pre></td></tr></table></figure></p>
<p>测试一下是否能连接上<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">telnet irc.wikimedia.org 6667</div></pre></td></tr></table></figure></p>
<ul>
<li><p>如果有响应</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">deploy/samza/bin/run-job.sh --config-factory=org.apache.samza.config.factories.PropertiesConfigFactory --config-path=file://$PWD/deploy/samza/config/wikipedia-feed.properties</div></pre></td></tr></table></figure>
</li>
<li><p>如果没有响应。只能使用本地的数据，作为kafka的producer：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">bin/produce-wikipedia-raw-data.sh</div><div class="line"></div><div class="line">#或者可以修改kafka-broker地址和zookeeper地址</div><div class="line">bin/produce-wikipedia-raw-data.sh -b yourKafkaBrokerAddress -z yourZookeeperAddress</div></pre></td></tr></table></figure>
</li>
</ul>
<p>测试是否成功，开一个消费者实时消费wikipedia-raw<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">deploy/kafka/bin/kafka-console-consumer.sh  --zookeeper localhost:2181 --topic wikipedia-raw</div></pre></td></tr></table></figure></p>
<p>将会有实时的消息输出<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&#123;&quot;raw&quot;:&quot;[[Paul Henreid]]  http://en.wikipedia.org/w/index.php?diff=606587718&amp;oldid=603654278 * .48.142.193 * (-1) original name Wasel, not Wassel - see ref &amp; ext link&quot;,&quot;time&quot;:1398926962623,&quot;source&quot;:&quot;rc-pmtpa&quot;,&quot;channel&quot;:&quot;#en.wikipedia&quot;&#125;</div></pre></td></tr></table></figure></p>
<h3 id="数据统计job"><a href="#数据统计job" class="headerlink" title="数据统计job"></a>数据统计job</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">deploy/samza/bin/run-job.sh --config-factory=org.apache.samza.config.factories.PropertiesConfigFactory --config-path=file://$PWD/deploy/samza/config/wikipedia-parser.properties</div><div class="line"></div><div class="line">deploy/samza/bin/run-job.sh --config-factory=org.apache.samza.config.factories.PropertiesConfigFactory --config-path=file://$PWD/deploy/samza/config/wikipedia-stats.properties</div></pre></td></tr></table></figure>
<p>前面的wikipedia-parser负责解析wikipedia-raw中消息，从而抽取edit的大小,修改者等信息</p>
<blockquote>
<p>wikipedia-raw–&gt;wikipedia-edits</p>
</blockquote>
<p>后面的wikipedia-stats负责统计来自wikipedia-edits中的消息，计算消息的个数。而后通过一个10秒钟长的滑动时间窗口将统计个数发送到kafka的wikipedia-statstopic中</p>
<blockquote>
<p>wikipedia-edits–&gt;wikipedia-statstopic  </p>
</blockquote>
<p>可以查看结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">deploy/kafka/bin/kafka-console-consumer.sh  --zookeeper localhost:2181 --topic wikipedia-edits</div><div class="line"></div><div class="line">deploy/kafka/bin/kafka-console-consumer.sh  --zookeeper localhost:2181 --topic wikipedia-stats</div></pre></td></tr></table></figure></p>
<p>最后的输出结果类似：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&#123;&quot;is-minor&quot;:948,&quot;unique-titles&quot;:763,&quot;is-talk&quot;:90,&quot;is-bot-edit&quot;:513,&quot;bytes-added&quot;:350253,&quot;edits&quot;:2790,&quot;is-new&quot;:135,&quot;edits-all-time&quot;:3720,&quot;is-unpatrolled&quot;:78&#125;</div><div class="line">&#123;&quot;is-minor&quot;:632,&quot;unique-titles&quot;:763,&quot;is-talk&quot;:60,&quot;is-bot-edit&quot;:342,&quot;bytes-added&quot;:233502,&quot;edits&quot;:1860,&quot;is-new&quot;:90,&quot;edits-all-time&quot;:5580,&quot;is-unpatrolled&quot;:52&#125;</div></pre></td></tr></table></figure></p>
<h2 id="关闭samza"><a href="#关闭samza" class="headerlink" title="关闭samza"></a>关闭samza</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bin/grid stop all</div></pre></td></tr></table></figure>
<h2 id="开启samza"><a href="#开启samza" class="headerlink" title="开启samza"></a>开启samza</h2><p>如果不是首次，则通过之前的bootstrap已经下载了相应的东西，只需要start<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bin/grid start all</div></pre></td></tr></table></figure></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://blog.jassassin.com/2015/04/30/samza/hello-samza/" target="_blank" rel="external">http://blog.jassassin.com/2015/04/30/samza/hello-samza/</a><br><a href="http://samza.apache.org/startup/hello-samza/0.10/" target="_blank" rel="external">http://samza.apache.org/startup/hello-samza/0.10/</a></p>
</the></excerpt>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Java程序员学python3.0--面向对象篇]]></title>
      <url>https://fangyeqing.github.io/2016/11/06/Java%E7%A8%8B%E5%BA%8F%E5%91%98%E5%AD%A6python3.0--%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%AF%87/</url>
      <content type="html"><![CDATA[<excerpt in="" index="" |="" 首页摘要="">  

<p>参考廖雪峰大神的<a href="http://www.liaoxuefeng.com/" target="_blank" rel="external">python3.0教程</a>，适用于有一定基础的Java程序员，会对比着Java来学习python。代码在PyCharm中运行通过，地址为<a href="https://github.com/fangyeqing/hello-python/tree/master" target="_blank" rel="external">github</a>。本篇主要介绍python面向对象编程相关的知识，在上一篇介绍了python的一些基础知识，包括安装运行、基础语法、函数、高级特性、函数式编程、模块等。</p>
<h2 id="面向对象编程"><a href="#面向对象编程" class="headerlink" title="面向对象编程"></a>面向对象编程</h2><h3 id="类和对象"><a href="#类和对象" class="headerlink" title="类和对象"></a>类和对象</h3><ul>
<li>定义类语法：class ClassName(superClass/object),其中括号里为父类，没有的话写object</li>
<li>类中定义的函数第一个参数永远是实例变量self，调用时，不用传递该参数。</li>
<li>允许对实例动态增加变量和方法，类的不同实例拥有的变量和方法可能不同</li>
<li>允许对类动态添加方法，添加后对象都能访问</li>
<li>类动态添加属性限制<strong>slots</strong>：定义一个特殊的<strong>slots</strong>变量，来限制该class实例能动态添加的属性。仅对当前类实例起作用，子类不起作用</li>
</ul>
<a id="more"></a>  
<p><the rest="" of="" contents="" |="" 余下全文=""><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">from types import MethodType</div><div class="line"></div><div class="line">class Student(object):</div><div class="line">    def __init__(self, name, score):</div><div class="line">        self.name = name</div><div class="line">        self.score = score</div><div class="line"></div><div class="line">    def print_score(self):</div><div class="line">        print(&apos;%s: %s&apos; % (self.name, self.score))</div><div class="line"># 对象动态添加属性</div><div class="line">bart = Student(&apos;Bart Simpson&apos;, 59)</div><div class="line">bart.age = 8</div><div class="line">bart.print_score()</div><div class="line">print(bart.age)</div><div class="line"># 对象动态添加方法</div><div class="line">def set_age(self, age):</div><div class="line">    self.age = age</div><div class="line">lisa = Student(&apos;Lisa Simpson&apos;, 87)</div><div class="line">lisa.set_age = MethodType(set_age, lisa)</div><div class="line">lisa.set_age(8)</div><div class="line">print(lisa.age)</div><div class="line"># 给类动态添加方法</div><div class="line">def set_score(self, score):</div><div class="line">    self.score = score</div><div class="line">Student.set_score = set_score</div><div class="line">lisa.set_score(10)</div><div class="line">bart.set_score(10)</div><div class="line">print(lisa.score)</div></pre></td></tr></table></figure></the></p>
<h3 id="访问限制"><a href="#访问限制" class="headerlink" title="访问限制"></a>访问限制</h3><p>私有变量(private):两个下划线开头<strong>xxx，跟java一样可以有set和get方法。区别于两个下划线开头和结尾的特殊变量</strong>xxx__<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">class Student(object):</div><div class="line">    def __init__(self, name, score):</div><div class="line">        self.__name = name</div><div class="line">        self.__score = score</div><div class="line">    def print_score(self):</div><div class="line">        print(&apos;%s: %s&apos; % (self.__name, self.__score))</div><div class="line">bart = Student(&apos;Bart Simpson&apos;, 98)</div><div class="line">bart.print_score()</div></pre></td></tr></table></figure></p>
<h3 id="继承和多态"><a href="#继承和多态" class="headerlink" title="继承和多态"></a>继承和多态</h3><ul>
<li>与java相同点：继承父类的所有功能，支持方法覆盖</li>
<li>与java不同点：<ul>
<li>Python动态语言–Java静态语言。下例：只需要保证传入的对象有一个run()方法就可以了，不需要是Animal类</li>
<li>Python支持多重继承，可以同时继承多个类。而Java的继承extends只能去继承一个类<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"># 父类-动物</div><div class="line">class Animal(object):</div><div class="line">    def run(self):</div><div class="line">        print(&apos;Animal is running...&apos;)</div><div class="line"># 父类-尖叫</div><div class="line">class MixlnBark(object):</div><div class="line">    def bark(self):</div><div class="line">        print(&quot;Barking....&quot;);</div><div class="line"># 方法：依赖于run方法</div><div class="line">def run_twice(animal):</div><div class="line">    animal.run()</div><div class="line">    animal.run()</div><div class="line"># 多重继承示例</div><div class="line">class Dog(Animal,MixlnBark):</div><div class="line">    def run(self):</div><div class="line">        print(&quot;Dog is Running&quot;);</div><div class="line">dog = Dog();</div><div class="line">dog.run()</div><div class="line">dog.bark()</div><div class="line"># 动态语言示例</div><div class="line">class Timer(object):</div><div class="line">    def run(self):</div><div class="line">        print(&apos;Start...&apos;)</div><div class="line">run_twice(Dog())</div><div class="line">run_twice(Timer())</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h3 id="获取对象信息"><a href="#获取对象信息" class="headerlink" title="获取对象信息"></a>获取对象信息</h3><ul>
<li>type(对象)：获取类型</li>
<li>isinstance(判断的实例,类型1,类型2…)：判断实例是否是这几种类型</li>
<li>dir(对象):获取对象所有属性和方法。配合以下方法，直接操作一个对象的状态，通常先通过has判断对象有没有该方法，有的话执行：<ul>
<li>hasattr(对象,’属性名/方法名’)</li>
<li>getattr(对象,’属性名/方法名’)</li>
<li>setattr(对象,’属性名/方法名’,set值)<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">import types</div><div class="line"># type</div><div class="line">print(type(abs)==types.BuiltinFunctionType)</div><div class="line"># isinstance</div><div class="line">print(isinstance(&apos;a&apos;, str))</div><div class="line">print(isinstance([1, 2, 3], (list, tuple)))</div><div class="line"># dir</div><div class="line">print(dir(&apos;abc&apos;))</div><div class="line">print(hasattr(&apos;abc&apos;, &apos;__init__&apos;))</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h3 id="类属性和实例属性"><a href="#类属性和实例属性" class="headerlink" title="类属性和实例属性"></a>类属性和实例属性</h3><p>类属性就类似于java中的类的静态属性，static<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"># 学生</div><div class="line">class Student(object):</div><div class="line">    # 用于记录已经注册学生数</div><div class="line">    student_number = 0</div><div class="line"></div><div class="line">    def __init__(self, name):</div><div class="line">        self.name = name</div><div class="line"># 注册一个学生:注册必填项名字，选填项利用关键字参数传递。注册完成，学生数+1</div><div class="line">def register(name, **kw):</div><div class="line">    a = Student(name)</div><div class="line">    for k, v in kw.items():</div><div class="line">        setattr(a, k, v)</div><div class="line">    Student.student_number += 1</div><div class="line">    return a</div><div class="line">bob = register(&apos;Bob&apos;, score=90)</div><div class="line">ah = register(&apos;Ah&apos;, age=8)</div><div class="line"></div><div class="line">print(getattr(bob, &apos;score&apos;))</div><div class="line">print(getattr(ah, &apos;age&apos;))</div><div class="line">print(Student.student_number)</div></pre></td></tr></table></figure></p>
<h2 id="面向对象高级编程"><a href="#面向对象高级编程" class="headerlink" title="面向对象高级编程"></a>面向对象高级编程</h2><h3 id="检查参数与-property"><a href="#检查参数与-property" class="headerlink" title="检查参数与@property"></a>检查参数与@property</h3><h3 id="定制类"><a href="#定制类" class="headerlink" title="定制类"></a>定制类</h3><p><strong>xxx</strong>前后两个下划线的函数帮助定制类，重写这些方法之后，可以实现一些功能。</p>
<ul>
<li><strong>str</strong>:类似于java的toString()</li>
<li><strong>getattr</strong>:获取属性,可以用于防止没有此属性,也可以用于链式调用</li>
<li><p><strong>call</strong>:相当于直接运行一个对象，不需要方法，这个方法相当于默认方法。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line">class Student(object):</div><div class="line">    def __init__(self, name):</div><div class="line">        self.name = name</div><div class="line"></div><div class="line">    def __str__(self):</div><div class="line">        return &apos;Student object (name: %s)&apos; % self.name</div><div class="line"></div><div class="line">    def __getattr__(self, attr):</div><div class="line">        if attr == &apos;score&apos;:</div><div class="line">            return 99</div><div class="line">        elif attr == &apos;age&apos;:</div><div class="line">            return lambda: 25</div><div class="line">        else:</div><div class="line">            raise AttributeError(&apos;\&apos;Student\&apos; object has no attribute \&apos;%s\&apos;&apos; % attr)</div><div class="line"></div><div class="line">    def __call__(self):</div><div class="line">        print(&apos;My name is %s.&apos; % self.name)</div><div class="line">stu = Student(&apos;Michael&apos;)</div><div class="line">print(stu)</div><div class="line">print(stu.score)</div><div class="line">print(stu.age)</div><div class="line"># print(stu.phone)</div><div class="line">print(stu())</div><div class="line">callable(stu)</div><div class="line"></div><div class="line"># __getattr__应用:链式调用</div><div class="line">class Chain(object):</div><div class="line">    def __init__(self, path=&apos;&apos;):</div><div class="line">        self._path = path</div><div class="line">    def __getattr__(self, path):</div><div class="line">        return Chain(&apos;%s/%s&apos; % (self._path, path))</div><div class="line">    def __str__(self):</div><div class="line">        return self._path</div><div class="line">print(Chain().status.user.timeline.list)</div></pre></td></tr></table></figure>
</li>
<li><p><strong>iter</strong><br>如果一个类想被用于for … in循环，类似list或tuple那样，就必须实现一个<strong>iter</strong>()方法，该方法返回一个迭代对象，然后，Python的for循环就会不断调用该迭代对象的<strong>next</strong>()方法拿到循环的下一个值，直到遇到StopIteration错误时退出循环</p>
</li>
<li><strong>getitem</strong><br>要表现得像list那样按照下标取出元素，需要实现<strong>getitem</strong>()方法<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"># __iter__和__next__:将斐波那契数列改成可以for循环的形式</div><div class="line"># __getitem__:使其实现取元素的功能</div><div class="line">class Fib(object):</div><div class="line">    def __init__(self):</div><div class="line">        self.a, self.b = 0, 1 # 初始化两个计数器a，b</div><div class="line"></div><div class="line">    def __iter__(self):</div><div class="line">        return self # 实例本身就是迭代对象，故返回自己</div><div class="line"></div><div class="line">    def __next__(self):</div><div class="line">        self.a, self.b = self.b, self.a + self.b # 计算下一个值</div><div class="line">        if self.a &gt; 100: # 退出循环的条件</div><div class="line">            raise StopIteration();</div><div class="line">        return self.a # 返回下一个值</div><div class="line"></div><div class="line">    def __getitem__(self, n):</div><div class="line">        if isinstance(n, int):  # n是索引</div><div class="line">            a, b = 1, 1</div><div class="line">            for x in range(n):</div><div class="line">                a, b = b, a + b</div><div class="line">            return a</div><div class="line">        if isinstance(n, slice):  # n是切片</div><div class="line">            start = n.start</div><div class="line">            stop = n.stop</div><div class="line">            if start is None:</div><div class="line">                start = 0</div><div class="line">            a, b = 1, 1</div><div class="line">            L = []</div><div class="line">            for x in range(stop):</div><div class="line">                if x &gt;= start:</div><div class="line">                    L.append(a)</div><div class="line">                a, b = b, a + b</div><div class="line">            return L</div><div class="line">for n in Fib():</div><div class="line">    print(n)</div><div class="line">f = Fib()</div><div class="line">print(f[3])</div><div class="line">print(f[:5])</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="枚举类"><a href="#枚举类" class="headerlink" title="枚举类"></a>枚举类</h3><p>Enum可以把一组相关常量定义在一个class中，且class不可变<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">@unique</div><div class="line">class Weekday(Enum):</div><div class="line">    Sun = 0 # Sun的value被设定为0</div><div class="line">    Mon = 1</div><div class="line">    Tue = 2</div><div class="line">    Wed = 3</div><div class="line">    Thu = 4</div><div class="line">    Fri = 5</div><div class="line">    Sat = 6</div><div class="line">day1 = Weekday.Mon</div><div class="line">print(Weekday.Tue)</div><div class="line">print(Weekday[&apos;Tue&apos;])</div><div class="line">print(Weekday.Tue.value)</div><div class="line">print(day1 == Weekday.Tue)</div><div class="line">print(Weekday(1))</div><div class="line">print(day1 == Weekday(1))</div></pre></td></tr></table></figure></p>
<h3 id="元类"><a href="#元类" class="headerlink" title="元类"></a>元类</h3><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000" target="_blank" rel="external">http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000</a><br><a href="http://blog.csdn.net/pipisorry/article/details/39909057" target="_blank" rel="external">http://blog.csdn.net/pipisorry/article/details/39909057</a>  </p>
</excerpt>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Java程序员学python3.0--入门篇]]></title>
      <url>https://fangyeqing.github.io/2016/11/05/Java%E7%A8%8B%E5%BA%8F%E5%91%98%E5%AD%A6python3.0--%E5%85%A5%E9%97%A8%E7%AF%87/</url>
      <content type="html"><![CDATA[<excerpt in="" index="" |="" 首页摘要="">   

<p>参考廖雪峰大神的<a href="http://www.liaoxuefeng.com/" target="_blank" rel="external">python3.0教程</a>，适用于有一定基础的Java程序员，会对比着Java来学习python。代码在PyCharm中运行通过，地址为<a href="https://github.com/fangyeqing/hello-python/tree/master" target="_blank" rel="external">github</a>。本篇主要介绍python的一些基础知识，包括安装运行（PyCharm设置）、基础语法、函数、高级特性、函数式编程、模块等。在下一篇会介绍python面向对象相关的知识。</p>
<h2 id="python简介"><a href="#python简介" class="headerlink" title="python简介"></a>python简介</h2><p>Python的哲学就是简单优雅，尽量写容易看明白的代码，尽量写少的代码</p>
<a id="more"></a>  
<the rest="" of="" contents="" |="" 余下全文=""> 

<h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><ul>
<li>首选是网络应用，包括网站、后台服务等等；</li>
<li>其次是许多日常需要的小工具，包括系统管理员需要的脚本任务等等；</li>
<li>另外就是把其他语言开发的程序再包装起来，方便使用。</li>
</ul>
<h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul>
<li>简洁优雅。</li>
<li>非常完善的基础代码库，覆盖了网络、文件、GUI、数据库、文本等大量内容</li>
<li>大量的第三方库</li>
</ul>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul>
<li>运行速度慢：Python是解释型语言，代码在执行时会一行一行地翻译成机器码。但是大量的应用程序不需要这么快的运行速度，因为用户根本感觉不出来</li>
<li>代码不能加密：如果要发布你的Python程序，实际上就是发布源代码</li>
</ul>
<h2 id="安装Python"><a href="#安装Python" class="headerlink" title="安装Python"></a>安装Python</h2><h3 id="linux下安装"><a href="#linux下安装" class="headerlink" title="linux下安装"></a>linux下安装</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">wget https://www.python.org/ftp/python/3.5.2/Python-3.5.2.tgz --no-check-certificate</div><div class="line">tar -zxvf Python-3.5.2.tgz</div><div class="line">cd Python-3.5.2/</div><div class="line">./configure --prefix=/global/exec/fangyeqing/python-3.5.2/</div><div class="line">make&amp;&amp;make install</div></pre></td></tr></table></figure>
<p>从安装日志中可以看到python3自带pip，easyinstall，setup-tools<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Installing collected packages: setuptools, pip</div><div class="line">Successfully installed pip-8.1.1 setuptools-20.10.1</div></pre></td></tr></table></figure></p>
<h4 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h4><p>环境变量添加，将刚才configure设置的地址添加到环境变量中：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vi ~/.bash_profile</div></pre></td></tr></table></figure></p>
<p>内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">#python</div><div class="line">export PATH=/global/exec/fangyeqing/python-3.5.2/bin:$PATH</div></pre></td></tr></table></figure></p>
<p>source之后测试是否安装成功:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">source ~/.bash_profile</div><div class="line">python3</div></pre></td></tr></table></figure></p>
<h3 id="windows下安装"><a href="#windows下安装" class="headerlink" title="windows下安装"></a>windows下安装</h3><p>python-3.5.2<a href="https://www.python.org/ftp/python/3.5.2/python-3.5.2.exe" target="_blank" rel="external">官方下载地址</a></p>
<p>安装过程中,务必勾上，就不用自己添加到环境变量了</p>
<ul>
<li>[x] Add Python 3.5 to PATH</li>
</ul>
<p>安装完后测试是否成功<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python</div></pre></td></tr></table></figure></p>
<h3 id="解释器"><a href="#解释器" class="headerlink" title="解释器"></a>解释器</h3><p>当我们编写Python代码时，我们得到的是一个包含Python代码的以.py为扩展名的文本文件。要运行代码，就需要Python解释器去执行.py文件。安装python之后自带了CPython，就用这个 就可以了。</p>
<h3 id="编译器"><a href="#编译器" class="headerlink" title="编译器"></a>编译器</h3><p>Windows下安装PyCharm，官方下载地址为<a href="https://download.jetbrains.com/python/pycharm-professional-2016.2.3.exe" target="_blank" rel="external">pycharm-professional-2016.2.3</a>，第一次打开的时候，选择激活方式为code，填入下方激活码（激活码来自互联网，仅供学习交流之用）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">43B4A73YYJ-eyJsaWNlbnNlSWQiOiI0M0I0QTczWVlKIiwibGljZW5zZWVOYW1lIjoibGFuIHl1IiwiYXNzaWduZWVOYW1lIjoiIiwiYXNzaWduZWVFbWFpbCI6IiIsImxpY2Vuc2VSZXN0cmljdGlvbiI6IkZvciBlZHVjYXRpb25hbCB1c2Ugb25seSIsImNoZWNrQ29uY3VycmVudFVzZSI6ZmFsc2UsInByb2R1Y3RzIjpbeyJjb2RlIjoiSUkiLCJwYWlkVXBUbyI6IjIwMTctMDItMjUifSx7ImNvZGUiOiJBQyIsInBhaWRVcFRvIjoiMjAxNy0wMi0yNSJ9LHsiY29kZSI6IkRQTiIsInBhaWRVcFRvIjoiMjAxNy0wMi0yNSJ9LHsiY29kZSI6IlBTIiwicGFpZFVwVG8iOiIyMDE3LTAyLTI1In0seyJjb2RlIjoiRE0iLCJwYWlkVXBUbyI6IjIwMTctMDItMjUifSx7ImNvZGUiOiJDTCIsInBhaWRVcFRvIjoiMjAxNy0wMi0yNSJ9LHsiY29kZSI6IlJTMCIsInBhaWRVcFRvIjoiMjAxNy0wMi0yNSJ9LHsiY29kZSI6IlJDIiwicGFpZFVwVG8iOiIyMDE3LTAyLTI1In0seyJjb2RlIjoiUEMiLCJwYWlkVXBUbyI6IjIwMTctMDItMjUifSx7ImNvZGUiOiJSTSIsInBhaWRVcFRvIjoiMjAxNy0wMi0yNSJ9LHsiY29kZSI6IldTIiwicGFpZFVwVG8iOiIyMDE3LTAyLTI1In0seyJjb2RlIjoiREIiLCJwYWlkVXBUbyI6IjIwMTctMDItMjUifSx7ImNvZGUiOiJEQyIsInBhaWRVcFRvIjoiMjAxNy0wMi0yNSJ9XSwiaGFzaCI6IjMzOTgyOTkvMCIsImdyYWNlUGVyaW9kRGF5cyI6MCwiYXV0b1Byb2xvbmdhdGVkIjpmYWxzZSwiaXNBdXRvUHJvbG9uZ2F0ZWQiOmZhbHNlfQ==-keaxIkRgXPKE4BR/ZTs7s7UkP92LBxRe57HvWamu1EHVXTcV1B4f/KNQIrpOpN6dgpjig5eMVMPmo7yMPl+bmwQ8pTZaCGFuLqCHD1ngo6ywHKIQy0nR249sAUVaCl2wGJwaO4JeOh1opUx8chzSBVRZBMz0/MGyygi7duYAff9JQqfH3p/BhDTNM8eKl6z5tnneZ8ZG5bG1XvqFTqWk4FhGsEWdK7B+He44hPjBxKQl2gmZAodb6g9YxfTHhVRKQY5hQ7KPXNvh3ikerHkoaL5apgsVBZJOTDE2KdYTnGLmqxghFx6L0ofqKI6hMr48ergMyflDk6wLNGWJvYHLWw==-MIIEPjCCAiagAwIBAgIBBTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTE1MTEwMjA4MjE0OFoXDTE4MTEwMTA4MjE0OFowETEPMA0GA1UEAwwGcHJvZDN5MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAxcQkq+zdxlR2mmRYBPzGbUNdMN6OaXiXzxIWtMEkrJMO/5oUfQJbLLuMSMK0QHFmaI37WShyxZcfRCidwXjot4zmNBKnlyHodDij/78TmVqFl8nOeD5+07B8VEaIu7c3E1N+e1doC6wht4I4+IEmtsPAdoaj5WCQVQbrI8KeT8M9VcBIWX7fD0fhexfg3ZRt0xqwMcXGNp3DdJHiO0rCdU+Itv7EmtnSVq9jBG1usMSFvMowR25mju2JcPFp1+I4ZI+FqgR8gyG8oiNDyNEoAbsR3lOpI7grUYSvkB/xVy/VoklPCK2h0f0GJxFjnye8NT1PAywoyl7RmiAVRE/EKwIDAQABo4GZMIGWMAkGA1UdEwQCMAAwHQYDVR0OBBYEFGEpG9oZGcfLMGNBkY7SgHiMGgTcMEgGA1UdIwRBMD+AFKOetkhnQhI2Qb1t4Lm0oFKLl/GzoRykGjAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBggkA0myxg7KDeeEwEwYDVR0lBAwwCgYIKwYBBQUHAwEwCwYDVR0PBAQDAgWgMA0GCSqGSIb3DQEBCwUAA4ICAQC9WZuYgQedSuOc5TOUSrRigMw4/+wuC5EtZBfvdl4HT/8vzMW/oUlIP4YCvA0XKyBaCJ2iX+ZCDKoPfiYXiaSiH+HxAPV6J79vvouxKrWg2XV6ShFtPLP+0gPdGq3x9R3+kJbmAm8w+FOdlWqAfJrLvpzMGNeDU14YGXiZ9bVzmIQbwrBA+c/F4tlK/DV07dsNExihqFoibnqDiVNTGombaU2dDup2gwKdL81ua8EIcGNExHe82kjF4zwfadHk3bQVvbfdAwxcDy4xBjs3L4raPLU3yenSzr/OEur1+jfOxnQSmEcMXKXgrAQ9U55gwjcOFKrgOxEdek/Sk1VfOjvS+nuM4eyEruFMfaZHzoQiuw4IqgGc45ohFH0UUyjYcuFxxDSU9lMCv8qdHKm+wnPRb0l9l5vXsCBDuhAGYD6ss+Ga+aDY6f/qXZuUCEUOH3QUNbbCUlviSz6+GiRnt1kA9N2Qachl+2yBfaqUqr8h7Z2gsx5LcIf5kYNsqJ0GavXTVyWh7PYiKX4bs354ZQLUwwa/cG++2+wNWP+HtBhVxMRNTdVhSm38AknZlD+PTAsWGu9GyLmhti2EnVwGybSD2Dxmhxk3IPCkhKAK+pl0eWYGZWG3tJ9mZ7SowcXLWDFAk0lRJnKGFMTggrWjV8GYpw5bq23VmIqqDLgkNzuoog==</div></pre></td></tr></table></figure></p>
<h4 id="pycharm配置"><a href="#pycharm配置" class="headerlink" title="pycharm配置"></a>pycharm配置</h4><p>配置的文件在github项目中，直接导入也可以，下载<a href="https://github.com/fangyeqing/hello-python/blob/master/pyCharm_setting/pyCharm-settings.jar" target="_blank" rel="external">地址</a>。不怕麻烦可以按下面一步步设置：</p>
<ol>
<li><p>界面窗口设置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Appearance&amp;&amp;Behavior -&gt; Appearance -&gt; show tool windows bars</div></pre></td></tr></table></figure>
</li>
<li><p>编辑器设置：file -&gt; Setting -&gt;Editor</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">#设置Python自动引入包</div><div class="line">general &gt; autoimport -&gt; python :show popup    </div><div class="line">#“代码自动完成”时间延时设置</div><div class="line">Code Completion   -&gt; Auto code completion in (ms):0  -&gt; Autopopup in (ms):500</div><div class="line">#显示“行号”与“空白字符”</div><div class="line">Appearance  -&gt; 勾选“Show line numbers”、“Show whitespaces”、“Show method separators”</div><div class="line">设置编辑器“颜色与字体”主题</div><div class="line"> Colors &amp; Fonts -&gt; Scheme name -&gt; 选择黑色背景的主题“Darcula”-&gt;Sava as先保存一份-&gt;Size -&gt; 设置为“14”</div><div class="line">#python文件默认编码</div><div class="line">File Encodings&gt; IDE Encoding: UTF-8;Project Encoding: UTF-8;</div></pre></td></tr></table></figure>
</li>
<li><p>python文件模板设置：file and code template&gt;python scripts</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">#!/usr/bin/env python</div><div class="line"># -*- coding: utf-8 -*-</div><div class="line">&quot;&quot;&quot;</div><div class="line">__title__ = &apos;$Package_name&apos;</div><div class="line">__author__ = &apos;$USER&apos;</div><div class="line">__time__ = &apos;$DATE&apos;</div><div class="line"># code is far away from bugs with the god animal protecting</div><div class="line">    I love animals. They taste delicious.</div><div class="line">              ┏┓      ┏┓</div><div class="line">            ┏┛┻━━━┛┻┓</div><div class="line">            ┃      ☃      ┃</div><div class="line">            ┃  ┳┛  ┗┳  ┃</div><div class="line">            ┃      ┻      ┃</div><div class="line">            ┗━┓      ┏━┛</div><div class="line">                ┃      ┗━━━┓</div><div class="line">                ┃  神兽保佑    ┣┓</div><div class="line">                ┃　永无BUG！   ┏┛</div><div class="line">                ┗┓┓┏━┳┓┏┛</div><div class="line">                  ┃┫┫  ┃┫┫</div><div class="line">                  ┗┻┛  ┗┻┛</div><div class="line">&quot;&quot;&quot;</div></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="hello-world"><a href="#hello-world" class="headerlink" title="hello world"></a>hello world</h2><h3 id="PyCharm"><a href="#PyCharm" class="headerlink" title="PyCharm"></a>PyCharm</h3><p>如果前面已经安装好PyCharm，就跟IntelliJ Idea一样，新建项目，新建py文件，直接运行就可以了。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">print(&apos;hello python&apos;)</div><div class="line">print(100+200+300)</div></pre></td></tr></table></figure></p>
<p>后面的示例程序都是在PyCharm中直接运行即可。</p>
<p>当然也可以通过交互式命令行、文本形式、py脚本形式（linux）运行。</p>
<h3 id="交互式命令行"><a href="#交互式命令行" class="headerlink" title="交互式命令行"></a>交互式命令行</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">python3               #进入交互式命令行模式，windows下为python</div><div class="line">100+200+300</div><div class="line">exit()                #退出，Ctrl+D也可以</div></pre></td></tr></table></figure>
<h3 id="文本形式"><a href="#文本形式" class="headerlink" title="文本形式"></a>文本形式</h3><p>编辑文本hello-world.py,内容为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">print(100+200+300)</div></pre></td></tr></table></figure></p>
<p>执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python3 hello-world.py</div></pre></td></tr></table></figure></p>
<h3 id="脚本形式"><a href="#脚本形式" class="headerlink" title="脚本形式"></a>脚本形式</h3><p>linux下如果想直接运行py脚本，在开头加上：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">#!/usr/bin/env python3</div><div class="line">print(100+200+300)</div></pre></td></tr></table></figure></p>
<p>执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hello-world.py</div></pre></td></tr></table></figure></p>
<h2 id="Python基础"><a href="#Python基础" class="headerlink" title="Python基础"></a>Python基础</h2><ul>
<li>#开头的语句是注释 </li>
<li>语句以冒号:结尾时，缩进的语句视为代码块</li>
<li>4个空格的缩进</li>
<li>大小写敏感<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"># print absolute value of an integer:</div><div class="line">a = 100</div><div class="line">if a &gt;= 0:</div><div class="line">    print(a)</div><div class="line">else:</div><div class="line">    print(-a)</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="数据类型和变量"><a href="#数据类型和变量" class="headerlink" title="数据类型和变量"></a>数据类型和变量</h3><h4 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h4><p>数据类型跟Java类似，基本类型主要有以下几种：</p>
<ul>
<li>整数</li>
<li>浮点数</li>
<li>字符串：单引号或者双引号，转义字符“\”</li>
<li>布尔值：True、False</li>
<li>空值：None<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"># 整数</div><div class="line">print(1)</div><div class="line">print(-8080)</div><div class="line">print(0xff00)</div><div class="line"># 浮点数</div><div class="line">print(1.23)</div><div class="line">print(12.3e8)</div><div class="line"># 字符串</div><div class="line">print(&apos;I\&apos;m \&quot;OK\&quot;!&apos;)</div><div class="line"># 布尔值</div><div class="line">print(True)</div><div class="line">print(2 &gt; 3)</div><div class="line"># 空值</div><div class="line">print(None)</div></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h4><p>动态类型，“=”赋值任意类型<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">a = &apos;ABC&apos;</div><div class="line">b = a</div><div class="line">a = &apos;XYZ&apos;</div><div class="line">print(b)</div></pre></td></tr></table></figure></p>
<ul>
<li>执行a = ‘ABC’，解释器创建了字符串’ABC’和变量a，并把a指向’ABC’：</li>
<li>执行b = a，解释器创建了变量b，并把b指向a指向的字符串’ABC’：</li>
<li>执行a = ‘XYZ’，解释器创建了字符串’XYZ’，并把a的指向改为’XYZ’，但b并没有更改：</li>
<li>所以，最后打印变量b的结果自然是’ABC’了。</li>
</ul>
<h4 id="常量"><a href="#常量" class="headerlink" title="常量"></a>常量</h4><p>用全部大写的变量名表示常量。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">PI = 3.14159265359</div><div class="line">print(PI)</div></pre></td></tr></table></figure></p>
<h3 id="字符串和编码"><a href="#字符串和编码" class="headerlink" title="字符串和编码"></a>字符串和编码</h3><h4 id="计算机编码类型"><a href="#计算机编码类型" class="headerlink" title="计算机编码类型"></a>计算机编码类型</h4><ul>
<li>ASCII编码：1 byte，只支持英文</li>
<li>Unicode编码：2 byte，支持中文、英文</li>
<li>UTF-8编码：可变长度1-6byte，英文字母1个字节，汉字通常3个字节，很生僻的字符被编码成4-6个字节。</li>
</ul>
<table>
<thead>
<tr>
<th>字符</th>
<th>ASCII</th>
<th>Unicode</th>
<th>UTF-8</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>01000001</td>
<td>00000000</td>
<td>01000001</td>
<td>01000001</td>
</tr>
<tr>
<td>中</td>
<td>x</td>
<td>01001110</td>
<td>00101101</td>
<td>11100100</td>
<td>10111000</td>
<td>10101101</td>
</tr>
</tbody>
</table>
<ul>
<li>在计算机内存中，统一使用2个字节的Unicode编码，当需要保存到硬盘或者需要传输的时候，就转换为可变长度的UTF-8编码。</li>
<li>用记事本编辑的时候，从文件读取的UTF-8字符被转换为Unicode字符到内存里，编辑完成后，保存的时候再把Unicode转换为UTF-8保存到文件。</li>
<li>浏览网页的时候，服务器会把动态生成的Unicode内容转换为UTF-8再传输到浏览器.很多网页的源码上会有类似<meta charset="UTF-8">的信息，表示该网页正是用的UTF-8编码</li>
</ul>
<h4 id="python编解码"><a href="#python编解码" class="headerlink" title="python编解码"></a>python编解码</h4><h5 id="bytes类型"><a href="#bytes类型" class="headerlink" title="bytes类型"></a>bytes类型</h5><p>bytes类型的数据用带b前缀的单引号或双引号表示。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">x = b&apos;ABC&apos;</div></pre></td></tr></table></figure></p>
<p>纯英文可以用ascii编码成bytes，中文只能用UTF-8编码成bytes，所以最好统一用UTF-8<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">print(&apos;中文&apos;.encode(&apos;utf-8&apos;))</div><div class="line">print(b&apos;\xe4\xb8\xad\xe6\x96\x87&apos;.decode(&apos;utf-8&apos;))</div></pre></td></tr></table></figure></p>
<h5 id="源码的中文处理"><a href="#源码的中文处理" class="headerlink" title="源码的中文处理"></a>源码的中文处理</h5><p>当你的源代码中包含中文的时候，就需要务必指定保存为UTF-8编码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">#!/usr/bin/env python3</div><div class="line"># -*- coding: utf-8 -*-</div></pre></td></tr></table></figure></p>
<h5 id="格式化输出"><a href="#格式化输出" class="headerlink" title="格式化输出"></a>格式化输出</h5><p>与C语言类似，用占位符表示：%d、%f、%s、%x。其中，%%来转义表示一个%。</p>
<p>例如：小明的成绩从去年的72分提升到了今年的85分，请计算小明成绩提升的百分点，并用字符串格式化显示出’xx.x%’，只保留小数点后1位<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">#!/usr/bin/env python3</div><div class="line"># -*- coding: utf-8 -*-</div><div class="line">s1 = 72</div><div class="line">s2 = 85</div><div class="line">s3 = (s1-s2)/s1*100</div><div class="line">print(&apos;%.2f%%&apos; % s3)</div></pre></td></tr></table></figure></p>
<h3 id="python集合类型"><a href="#python集合类型" class="headerlink" title="python集合类型"></a>python集合类型</h3><table>
<thead>
<tr>
<th>python集合类型</th>
<th>创建方式</th>
<th>对应Java类型</th>
</tr>
</thead>
<tbody>
<tr>
<td> list</td>
<td>[]</td>
<td>List</td>
</tr>
<tr>
<td> tuple</td>
<td>()</td>
<td>List</td>
</tr>
<tr>
<td> map</td>
<td>{}</td>
<td>Map</td>
</tr>
<tr>
<td> set</td>
<td>set()</td>
<td>set</td>
</tr>
</tbody>
</table>
<h4 id="list"><a href="#list" class="headerlink" title="list:[]"></a>list:[]</h4><p>list是一种有序的集合，可以随时添加和删除其中的元素。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">classmates = [&apos;Michael&apos;, &apos;Bob&apos;, &apos;Tracy&apos;]    #list初始化</div><div class="line">print(classmates)</div><div class="line">print(len(classmates))                        #list长度len()</div><div class="line">print(classmates[0])                             #取序号处元素</div><div class="line">print(classmates[-1])                      #反向取序号处元素</div><div class="line"></div><div class="line">classmates.append(&apos;Adam&apos;)       #末尾插入</div><div class="line">classmates.insert(1, &apos;Jack&apos;)    #序号处插入</div><div class="line">classmates.pop()                #删除末尾</div><div class="line">classmates.pop(1)               #删除序号处</div><div class="line">classmates[1] = &apos;Sarah&apos;         #序号处替换</div><div class="line">print(classmates)</div></pre></td></tr></table></figure></p>
<p>list里面的元素的数据类型也可以不同，比如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">L = [&apos;Apple&apos;, 123, True]</div></pre></td></tr></table></figure></p>
<p>list元素也可以是另一个list，比如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">s = [&apos;python&apos;, &apos;java&apos;, [&apos;asp&apos;, &apos;php&apos;], &apos;scheme&apos;]</div><div class="line">print(s[2])</div></pre></td></tr></table></figure></p>
<p>如果一个list中一个元素也没有，就是一个空的list，它的长度为0：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">L = []</div><div class="line">print(len(L))</div></pre></td></tr></table></figure></p>
<h4 id="tuple"><a href="#tuple" class="headerlink" title="tuple:()"></a>tuple:()</h4><p>相当于不可变的list，没有append、insert方法，小括号表示。只有1个元素的tuple时，也会加一个逗号，以免你误解成数学计算意义上的括号<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">classmates = (&apos;Michael&apos;, &apos;Bob&apos;, &apos;Tracy&apos;)</div><div class="line">print(classmates)</div><div class="line">t = (1,)</div><div class="line">print(t)</div></pre></td></tr></table></figure></p>
<p>与java的final类似,虽然是不可变的，但是tuple中的list是可变的<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">t = (&apos;a&apos;, &apos;b&apos;, [&apos;A&apos;, &apos;B&apos;])</div><div class="line">t[2][0] = &apos;X&apos;</div><div class="line">t[2][1] = &apos;Y&apos;</div><div class="line">print(t)</div></pre></td></tr></table></figure></p>
<h4 id="dict"><a href="#dict" class="headerlink" title="dict:{}"></a>dict:{}</h4><p>类似于java的map，dict的key必须是不可变对象<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">d = &#123;&apos;Michael&apos;: 95, &apos;Bob&apos;: 75, &apos;Tracy&apos;: 85&#125;     #初始化</div><div class="line">print(d[&apos;Michael&apos;])                             #取key为xxx的值，key不存在会报错</div><div class="line">d[&apos;Adam&apos;] = 67                                  #给key给xxx的赋值</div><div class="line">print(&apos;Thomas&apos; in d)                            #判断key是否存在</div><div class="line">print(d.get(&apos;Thomas&apos;))                          #取key为xxx的值，不存在返回空</div><div class="line">print(d.get(&apos;Thomas&apos;, -1))                      #取key为xxx的值，不存在返回-1</div><div class="line">print(d.pop(&apos;Bob&apos;))                             #删除key为xxx</div></pre></td></tr></table></figure></p>
<h4 id="set"><a href="#set" class="headerlink" title="set"></a>set</h4><p>set和dict的唯一区别仅在于没有存储对应的value。创建set必须以list作为输入集合：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">s = set([1, 2, 3])</div><div class="line">print(s)</div></pre></td></tr></table></figure></p>
<p>set可以看成数学意义上的无序和无重复元素的集合，因此，两个set可以做数学意义上的交集、并集等操作：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">s1 = set([1, 2, 3])</div><div class="line">s2 = set([2, 3, 4])</div><div class="line">print(s1 &amp; s2)</div><div class="line">print(s1 | s2)</div></pre></td></tr></table></figure></p>
<h3 id="不变与可变"><a href="#不变与可变" class="headerlink" title="不变与可变"></a>不变与可变</h3><p>list是可变对象<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">classmates = [&apos;Michael&apos;, &apos;Bob&apos;, &apos;Tracy&apos;]</div><div class="line">classmates.sort()</div><div class="line">print(classmates)</div></pre></td></tr></table></figure></p>
<p>str是不变对象<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">a = &apos;abc&apos;</div><div class="line">b = a.replace(&apos;a&apos;, &apos;A&apos;)</div><div class="line">print(a)</div><div class="line">print(b)</div></pre></td></tr></table></figure></p>
<p>对于不变对象来说，调用对象自身的任意方法，也不会改变该对象自身的内容。相反，这些方法会创建新的对象并返回，这样，就保证了不可变对象本身永远是不可变的。</p>
<p>其实说这么多，就是类似于java中的final类型，不能改变对象的地址，但是可以改变内容。</p>
<h3 id="条件判断"><a href="#条件判断" class="headerlink" title="条件判断"></a>条件判断</h3><p>注意冒号和缩进，else if必须写成elif<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">age = input(&apos;birth:&apos;)           </div><div class="line">age = int(age)                  #相当于java的Integer.parse(String)</div><div class="line">if age &gt;= 18:</div><div class="line">    print(&apos;adult&apos;)</div><div class="line">elif age &gt;= 6:</div><div class="line">    print(&apos;teenager&apos;)</div><div class="line">else:</div><div class="line">    print(&apos;kid&apos;)</div></pre></td></tr></table></figure></p>
<h3 id="循环"><a href="#循环" class="headerlink" title="循环"></a>循环</h3><h4 id="for"><a href="#for" class="headerlink" title="for"></a>for</h4><p>跟java类似<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">names = [&apos;Michael&apos;, &apos;Bob&apos;, &apos;Tracy&apos;]</div><div class="line">for name in names:</div><div class="line">    print(name)</div></pre></td></tr></table></figure></p>
<p>range(i1,i2,n)表示从i1到i2的数组，步进为n，range(i)表示range(0,i)，n省略为1，list(range())表示转化成list<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">print(list(range(1, 5)))</div></pre></td></tr></table></figure></p>
<h4 id="while循环"><a href="#while循环" class="headerlink" title="while循环"></a>while循环</h4><p>跟java类似<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">sum = 0</div><div class="line">n = 99</div><div class="line">while n &gt; 0:</div><div class="line">    sum = sum + n</div><div class="line">    n = n - 2</div><div class="line">print(sum)</div></pre></td></tr></table></figure></p>
<h4 id="break和continue"><a href="#break和continue" class="headerlink" title="break和continue"></a>break和continue</h4><p>跟java一样，break语句可以在循环过程中直接退出循环，而continue语句可以提前结束本轮循环<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">for x in range(20):</div><div class="line">    if x == 10:</div><div class="line">        break</div><div class="line">    if x % 2 == 0:</div><div class="line">        continue</div><div class="line">    print(x)</div></pre></td></tr></table></figure></p>
<h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><h3 id="内置函数"><a href="#内置函数" class="headerlink" title="内置函数"></a>内置函数</h3><p>绝对值、求最大值<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">print(abs(-100))</div><div class="line">print(max(1, 2, 3, 199))</div></pre></td></tr></table></figure></p>
<p>数据类型转换函数：<br>int、float、str、bool<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">print(int(&apos;123&apos;))</div><div class="line">print(int(12.34))</div><div class="line">print(float(&apos;12.34&apos;))</div><div class="line">print(str(1.23))</div><div class="line">print(str(100))</div><div class="line">print(bool(1))</div><div class="line">print(bool(&apos;&apos;))</div></pre></td></tr></table></figure></p>
<h3 id="定义函数"><a href="#定义函数" class="headerlink" title="定义函数"></a>定义函数</h3><p>定义函数，以def开头。没有return语句，返回结果为None<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">def my_abs(x):</div><div class="line">    if not isinstance(x, (int, float)):     #参数检查</div><div class="line">        raise TypeError(&apos;bad operand type&apos;)</div><div class="line">    if x &gt;= 0:</div><div class="line">        return x</div><div class="line">    else:</div><div class="line">        return -x</div><div class="line"></div><div class="line">print(my_abs(-10))</div></pre></td></tr></table></figure></p>
<p>在其他py文件中调用，则需要引入from _2_def.py import my_abs。当然，在PyCharm中只需要Alt+Enter引入。</p>
<h4 id="空函数"><a href="#空函数" class="headerlink" title="空函数"></a>空函数</h4><p>空函数：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">def nop():</div><div class="line">    pass</div></pre></td></tr></table></figure></p>
<p>pass还可以用在其他语句里<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">if age &gt;= 18:</div><div class="line">    pass</div></pre></td></tr></table></figure></p>
<h4 id="返回多个值"><a href="#返回多个值" class="headerlink" title="返回多个值"></a>返回多个值</h4><p>游戏中经常需要从一个点移动到另一个点，给出坐标、位移和角度，就可以计算出新的新的坐标。Python函数返回的仍然是单一值，以tuple形式而已。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">import math</div><div class="line"></div><div class="line">def move(x, y, step, angle=0):</div><div class="line">    nx = x + step * math.cos(angle)</div><div class="line">    ny = y - step * math.sin(angle)</div><div class="line">    return nx, ny</div><div class="line"></div><div class="line">a, b = move(100, 100, 60, math.pi / 6)</div><div class="line">print(a, b)</div><div class="line">r = move(100, 100, 60, math.pi / 6)</div><div class="line">print(r)</div></pre></td></tr></table></figure></p>
<h5 id="练习"><a href="#练习" class="headerlink" title="练习"></a>练习</h5><p>请定义一个函数quadratic(a, b, c)，接收3个参数，返回一元二次方程：ax2 + bx + c = 0的两个解。详解见：_3_function/quadratic.py</p>
<h3 id="递归函数"><a href="#递归函数" class="headerlink" title="递归函数"></a>递归函数</h3><p>跟java类似，也要小心栈溢出的问题<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">def fact(n):</div><div class="line">    if n == 1:</div><div class="line">        return 1</div><div class="line">    return n * fact(n - 1)</div><div class="line">print(fact(5))</div><div class="line">print(fact(10))</div><div class="line"># print(fact(1000))</div></pre></td></tr></table></figure></p>
<h3 id="函数参数"><a href="#函数参数" class="headerlink" title="函数参数"></a>函数参数</h3><h4 id="必选参数"><a href="#必选参数" class="headerlink" title="必选参数"></a>必选参数</h4><p>必须传入的参数</p>
<h4 id="默认参数"><a href="#默认参数" class="headerlink" title="默认参数"></a>默认参数</h4><ul>
<li>必选参数在前，默认参数在后</li>
<li>当函数有多个参数时，把变化大的参数放前面，变化小的参数放后面。变化小的参数就可以作为默认参数</li>
<li>默认参数必须指向不变对象<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">def power(x, n=2):</div><div class="line">    s = 1</div><div class="line">    while n &gt; 0:</div><div class="line">        n -= 1</div><div class="line">        s = s * x</div><div class="line">    return s</div><div class="line">print(power(5))</div><div class="line">print(power(5, 3))</div></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="可变参数"><a href="#可变参数" class="headerlink" title="可变参数"></a>可变参数</h4><p>在入参数前面加了一个*号，表示可变参数在函数调用时自动组装为一个tuple<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">def calc(*numbers):</div><div class="line">    sum = 0</div><div class="line">    for n in numbers:</div><div class="line">        sum = sum + n * n</div><div class="line">    return sum</div><div class="line">print(calc(1, 2, 3))</div></pre></td></tr></table></figure></p>
<h4 id="关键字参数"><a href="#关键字参数" class="headerlink" title="关键字参数"></a>关键字参数</h4><p>在入参数前面加了一个**号,在函数内部自动组装为一个dict<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">def person(name, age, **kw):</div><div class="line">    print(&apos;name:&apos;, name, &apos;age:&apos;, age, &apos;other:&apos;, kw)</div><div class="line">person(&apos;Michael&apos;, 30)</div><div class="line">person(&apos;Bob&apos;, 35, city=&apos;Beijing&apos;)</div><div class="line">person(&apos;Adam&apos;, 45, gender=&apos;M&apos;, job=&apos;Engineer&apos;)</div><div class="line">extra = &#123;&apos;city&apos;: &apos;Beijing&apos;, &apos;job&apos;: &apos;Engineer&apos;&#125;</div><div class="line">person(&apos;Jack&apos;, 24, **extra)</div></pre></td></tr></table></figure></p>
<h4 id="命名关键字"><a href="#命名关键字" class="headerlink" title="命名关键字"></a>命名关键字</h4><p>如果要限制关键字参数的名字，就可以用命名关键字参数。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">def person(name, age, *, city, job):</div><div class="line">    print(name, age, city, job)</div><div class="line">person(&apos;Jack&apos;, 24, city=&apos;Beijing&apos;, job=&apos;Engineer&apos;)</div></pre></td></tr></table></figure></p>
<p>已经有了一个可变参数，命名关键字参数就不再需要一个特殊分隔符*了：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">def person(name, age, *args, city, job):</div><div class="line">    print(name, age, args, city, job)</div><div class="line">person(&apos;Jack&apos;, 24, 3, 1, city=&apos;Beijing&apos;, job=&apos;Engineer&apos;)</div></pre></td></tr></table></figure></p>
<h4 id="参数组合"><a href="#参数组合" class="headerlink" title="参数组合"></a>参数组合</h4><p>参数定义的顺序必须是：必选参数、默认参数、可变参数、命名关键字参数和关键字参数。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">def f1(a, b, c=0, *args, **kw):</div><div class="line">    print(&apos;a =&apos;, a, &apos;b =&apos;, b, &apos;c =&apos;, c, &apos;args =&apos;, args, &apos;kw =&apos;, kw)</div><div class="line">f1(1, 2)</div><div class="line">f1(1, 2, c=3)</div><div class="line">f1(1, 2, 3, &apos;a&apos;, &apos;b&apos;)</div><div class="line">f1(1, 2, 3, &apos;a&apos;, &apos;b&apos;, x=99)</div><div class="line">args = (1, 2, 3, 4)</div><div class="line">kw = &#123;&apos;d&apos;: 99, &apos;x&apos;: &apos;#&apos;&#125;</div><div class="line">f1(*args, **kw)</div><div class="line"></div><div class="line">def f2(a, b, c=0, *, d, **kw):</div><div class="line">    print(&apos;a =&apos;, a, &apos;b =&apos;, b, &apos;c =&apos;, c, &apos;d =&apos;, d, &apos;kw =&apos;, kw)</div><div class="line">f2(1, 2, d=99, ext=None)</div><div class="line">args = (1, 2, 3)</div><div class="line">kw = &#123;&apos;d&apos;: 88, &apos;x&apos;: &apos;#&apos;&#125;</div><div class="line">f2(*args, **kw)</div></pre></td></tr></table></figure></p>
<p>对于任意函数，都可以通过类似func(<em>args, *</em>kw)的形式调用它</p>
<h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><ul>
<li>默认参数一定要用不可变对象，如果是可变对象，程序运行时会有逻辑错误！</li>
<li>要注意定义可变参数和关键字参数的语法：<ul>
<li>*args是可变参数，args接收的是一个tuple；  </li>
<li>**kw是关键字参数，kw接收的是一个dict。</li>
</ul>
</li>
<li>调用函数时如何传入可变参数和关键字参数的语法：<ul>
<li>可变参数既可以直接传入：func(1, 2, 3)，又可以先组装list或tuple，再通过<em>args传入：func(</em>(1, 2, 3))；</li>
<li>关键字参数既可以直接传入：func(a=1, b=2)，又可以先组装dict，再通过<strong>kw传入：func(</strong>{‘a’: 1, ‘b’: 2})。</li>
</ul>
</li>
<li>使用<em>args和*</em>kw是Python的习惯写法，当然也可以用其他参数名，但最好使用习惯用法。</li>
<li>命名的关键字参数是为了限制调用者可以传入的参数名，同时可以提供默认值。</li>
</ul>
<h2 id="高级特性"><a href="#高级特性" class="headerlink" title="高级特性"></a>高级特性</h2><h3 id="切片"><a href="#切片" class="headerlink" title="切片"></a>切片</h3><ul>
<li>L[i1:i2]表示从第i个到第i-2个，间隔为1。i1为负数时，表示从倒数第-i1个开始。</li>
<li>L[i1:]表示到最后一个</li>
<li>L[:i2]表示前i2个</li>
<li>L[i1:i2:n]表示从第i个到第i-2个,间隔为n。</li>
<li>L[:]表示复制L<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">L = [&apos;Michael&apos;, &apos;Sarah&apos;, &apos;Tracy&apos;, &apos;Bob&apos;, &apos;Jack&apos;]</div><div class="line"># 切片</div><div class="line">print(L[0:3])</div><div class="line">print(L[1:3])</div><div class="line">print(L[-1])</div><div class="line">print(L[-3:-1])</div><div class="line"></div><div class="line">L1 = list(range(100))</div><div class="line">print(L1[1:20])</div><div class="line"># 前十个数</div><div class="line">print(L1[:10])</div><div class="line"># 后十个数</div><div class="line">print(L1[-10:])</div><div class="line"># 前十个数，没两个取一个</div><div class="line">print(L1[:10:2])</div><div class="line"># 所有数，每5个取一个</div><div class="line">print(L1[::5])</div><div class="line"># 复制一个list</div><div class="line">print(L1[:])</div><div class="line"></div><div class="line"># tuple切片仍是tuple</div><div class="line">print((0, 1, 2, 3, 4, 5)[:3])</div><div class="line"></div><div class="line"># 切片用于字符串切割</div><div class="line">s = &apos;ABCDEFG&apos;</div><div class="line">s1 = s[:3]</div><div class="line">s2 = s[-4:]</div><div class="line">print(s1, s2,)</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="迭代"><a href="#迭代" class="headerlink" title="迭代"></a>迭代</h3><p>任何可迭代对象都可以作用于for循环，包括我们自定义的数据类型，只要符合迭代条件，就可以使用for循环<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"># dict迭代</div><div class="line">from collections import Iterable</div><div class="line"></div><div class="line">d = &#123;&apos;a&apos;: 1, &apos;b&apos;: 2, &apos;c&apos;: 3&#125;</div><div class="line">for key in d:</div><div class="line">    print(key)</div><div class="line">for value in d.values():</div><div class="line">    print(value)</div><div class="line">for k, v in d.items():</div><div class="line">    print(k, v)</div><div class="line"># 字符串迭代</div><div class="line">for ch in &apos;ABC&apos;:</div><div class="line">    print(ch)</div><div class="line"># 判断是否可以迭代</div><div class="line">print(isinstance(&apos;abc&apos;, Iterable))</div><div class="line">print(isinstance(123, Iterable))</div><div class="line"># 类java下标循环</div><div class="line">for i, value in enumerate([&apos;A&apos;, &apos;B&apos;, &apos;C&apos;]):</div><div class="line">    print(i, value)</div><div class="line"># 两个变量，list元素中为tuple</div><div class="line">for x, y in [(1, 1), (2, 4), (3, 9)]:</div><div class="line">    print(x, y)</div></pre></td></tr></table></figure></p>
<h3 id="列表生成式"><a href="#列表生成式" class="headerlink" title="列表生成式"></a>列表生成式</h3><p>运用列表生成式，可以快速生成list，可以通过一个list推导出另一个list，而代码却十分简洁<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">import os</div><div class="line"># 生成[1x1, 2x2, 3x3, ..., 10x10]</div><div class="line">print([x*x for x in range(1, 11)])</div><div class="line"># 选出仅偶数的平方</div><div class="line">print([x * x for x in range(1, 11) if x % 2 == 0])</div><div class="line"># 两层循环生成全排列</div><div class="line">print([m + n for m in &apos;ABC&apos; for n in &apos;XYZ&apos;])</div><div class="line"># 列出当前目录下的所有文件和目录名</div><div class="line">print([d for d in os.listdir(&apos;.&apos;)])</div><div class="line"># 生成表达式</div><div class="line">d = &#123;&apos;x&apos;: &apos;A&apos;, &apos;y&apos;: &apos;B&apos;, &apos;z&apos;: &apos;C&apos;&#125;</div><div class="line">print([k + &apos;=&apos; + v for k, v in d.items()])</div><div class="line"># list字符串变小写</div><div class="line">L = [&apos;Hello&apos;, &apos;World&apos;, &apos;IBM&apos;, &apos;Apple&apos;]</div><div class="line">print([s.lower() for s in L])</div><div class="line"># test</div><div class="line">L1 = [&apos;Hello&apos;, &apos;World&apos;, 18, &apos;Apple&apos;, None]</div><div class="line">L2 = [s.lower() for s in L1 if isinstance(s, str)]</div><div class="line">print(L2)</div></pre></td></tr></table></figure></p>
<h3 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h3><p>通过列表生成式，我们可以直接创建一个列表。但是，受到内存限制，列表容量肯定是有限的。在循环的过程中不断推算出后续的元素，这样就不必创建完整的list，从而节省大量的空间。在Python中，这种一边循环一边计算的机制，称为生成器：generator。</p>
<ul>
<li>把一个列表生成式的[]改成()，就创建了一个generator</li>
<li>一个函数定义中包含yield关键字，是一个generator函数，generator函数的“调用”实际返回一个generator对象</li>
<li>generator函数在每次next(g)或者for循环调用的时候执行，yield返回结果，再次执行时从上次yield语句处继续执行<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">g = (x * x for x in range(10))</div><div class="line">print(next(g))</div><div class="line">print(next(g))</div><div class="line"></div><div class="line">#斐波拉契数列（Fibonacci），除第一个和第二个数外，任意一个数都可由前两个数相加得到：</div><div class="line"># 1, 1, 2, 3, 5, 8, 13, 21, 34, ...</div><div class="line">def fib(max):</div><div class="line">    n, a, b = 0, 0, 1</div><div class="line">    while n &lt; max:</div><div class="line">        yield b</div><div class="line">        a, b = b, a + b</div><div class="line">        n = n + 1</div><div class="line">    return &apos;done&apos;</div><div class="line">f = fib(6)</div><div class="line">print(f)</div><div class="line">for n in fib(6):</div><div class="line">    print(n)</div><div class="line">    </div><div class="line"># 杨辉三角</div><div class="line">def triangles():</div><div class="line">    L = [1]</div><div class="line">    while True:</div><div class="line">        yield L</div><div class="line">        L.append(0)</div><div class="line">        L = [L[i-1] + L[i]  for i in range(len(L))]</div><div class="line"></div><div class="line">n=0</div><div class="line">for t in triangles():</div><div class="line">    print(t)</div><div class="line">    n += 1</div><div class="line">    if n == 10:</div><div class="line">        break</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="迭代器"><a href="#迭代器" class="headerlink" title="迭代器"></a>迭代器</h3><table>
<thead>
<tr>
<th>对比</th>
<th>Iterable(可迭代对象)</th>
<th>Iterator(迭代器)</th>
</tr>
</thead>
<tbody>
<tr>
<td>特点</td>
<td>可以直接作用于for循环</td>
<td>可作用于next()函数的对象</td>
</tr>
<tr>
<td>举例</td>
<td>集合类型、generator</td>
<td>generator、iter(集合类型)</td>
</tr>
</tbody>
</table>
<p>集合数据类型：如list、tuple、dict、set、str等。<br>generator：包括生成器和带yield的generator function。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"># 可迭代对象：Iterable判断</div><div class="line">print(isinstance([], Iterable))</div><div class="line">print(isinstance(&#123;&#125;, Iterable))</div><div class="line">print(isinstance(&apos;abc&apos;, Iterable))</div><div class="line">print(isinstance((x for x in range(10)), Iterable))</div><div class="line">print(isinstance(100, Iterable))</div><div class="line"># 迭代器：Iterator判断</div><div class="line">print(isinstance((x for x in range(10)), Iterator))</div><div class="line">print(isinstance([], Iterator))</div><div class="line">print(isinstance(&#123;&#125;, Iterator))</div><div class="line">print(isinstance(&apos;abc&apos;, Iterator))</div><div class="line"># iter转化集合类型为Iterator</div><div class="line">print(isinstance(iter([]), Iterator))</div><div class="line">print(isinstance(iter(&apos;abc&apos;), Iterator))</div></pre></td></tr></table></figure></p>
<h2 id="函数式编程"><a href="#函数式编程" class="headerlink" title="函数式编程"></a>函数式编程</h2><h3 id="高阶函数"><a href="#高阶函数" class="headerlink" title="高阶函数"></a>高阶函数</h3><p>把函数作为参数传入，这样的函数称为高阶函数，函数式编程就是指这种高度抽象的编程范式<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"># 变量指向函数</div><div class="line">f = abs</div><div class="line">print(f(-10))</div><div class="line"># 高阶函数</div><div class="line">def add(x, y, f1):</div><div class="line">    return f1(x) + f1(y)</div><div class="line">print(add(-5, 6, abs))</div></pre></td></tr></table></figure></p>
<h4 id="map-reduce"><a href="#map-reduce" class="headerlink" title="map/reduce"></a>map/reduce</h4><ul>
<li>map(函数，Iterator)：将传入的函数依次作用到序列的每个元素(并行计算)，并把结果作为新的Iterator返回<ul>
<li>map(f, [x1, x2, x3, x4]) = [f(x1), f(x2), f(x3), f(x4)]</li>
</ul>
</li>
<li>reduce(函数，Iterator):reduce把结果继续和序列的下一个元素做累积计算(串行计算)<ul>
<li>reduce(f, [x1, x2, x3, x4]) = f(f(f(x1, x2), x3), x4)<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"># 实现int函数：map利用dict将集合str挨个转换为数字，reduce加权累加每位</div><div class="line">def str2int(s):</div><div class="line">    def fn(x, y):</div><div class="line">        return x * 10 + y</div><div class="line">    def char2num(s):</div><div class="line">        L = &#123;&apos;0&apos;: 0, &apos;1&apos;: 1, &apos;2&apos;: 2, &apos;3&apos;: 3, &apos;4&apos;: 4, &apos;5&apos;: 5, &apos;6&apos;: 6, &apos;7&apos;: 7, &apos;8&apos;: 8, &apos;9&apos;: 9&#125;</div><div class="line">        return L[s]</div><div class="line">    return reduce(fn, map(char2num, s))</div><div class="line">print(str2int(&apos;123&apos;))</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h4 id="filter"><a href="#filter" class="headerlink" title="filter"></a>filter</h4><p>filter()用于过滤序列。把传入的函数依次作用于每个元素，然后根据返回值是True还是False决定保留还是丢弃该元素。返回的是一个Iterator<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"># filter:过滤偶数</div><div class="line">def is_odd(n):</div><div class="line">    return n % 2 == 1</div><div class="line">print(list(filter(is_odd, [1, 2, 4, 5, 6, 9, 10, 15])))</div></pre></td></tr></table></figure></p>
<h4 id="sorted"><a href="#sorted" class="headerlink" title="sorted"></a>sorted</h4><p>语法：sorted(L, key=函数, reverse=True/False)</p>
<ul>
<li>L:序列</li>
<li>key：排序规则</li>
<li>reverse：是否逆序<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">L = [36, 5, -12, 9, -21]</div><div class="line">print(sorted(L))</div><div class="line"># sorted：key</div><div class="line">print(sorted(L, key=abs))</div><div class="line">s = [&apos;bob&apos;, &apos;about&apos;, &apos;Zoo&apos;, &apos;Credit&apos;]</div><div class="line">print(sorted(s))</div><div class="line">print(sorted(s, key=str.lower))</div><div class="line"># # sorted：reverse=True逆序</div><div class="line">print(sorted(s, key=str.lower, reverse=True))</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="返回函数"><a href="#返回函数" class="headerlink" title="返回函数"></a>返回函数</h3><ul>
<li>返回的函数并没有立刻执行，而是直到调用了f()才执行</li>
<li>相关参数和变量都保存在返回的函数中，这种称为“闭包（Closure）”</li>
<li>返回函数不要引用任何循环变量，或者后续会发生变化的变量<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">def lazy_sum(*args):</div><div class="line">    def sum():</div><div class="line">        ax = 0</div><div class="line">        for n in args:</div><div class="line">            ax = ax + n</div><div class="line">        return ax</div><div class="line">    return sum</div><div class="line">f = lazy_sum(1, 3, 5, 7, 9)</div><div class="line">print(f)</div><div class="line">print(f())</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="匿名函数"><a href="#匿名函数" class="headerlink" title="匿名函数"></a>匿名函数</h3><ul>
<li>Lambda 函数相当于没有显式声明的函数，定义即用。</li>
<li>只能有一个单独的表达式<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">lambda x, y: x * y</div></pre></td></tr></table></figure>
</li>
</ul>
<p>相当于：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">def f(x, y):</div><div class="line">    return x * y</div></pre></td></tr></table></figure></p>
<h3 id="装饰器"><a href="#装饰器" class="headerlink" title="装饰器"></a>装饰器</h3><p>在代码运行期间动态增加功能的方式，称之为“装饰器”。类似于java的Annotation。下述代码</p>
<ul>
<li>now()相当于执行log(now)</li>
<li>tomorrow()相当于执行log(‘exective’)(now)</li>
<li>@functools.wraps(func)是为了不改变函数的<code>__name__</code>属性<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">import functools</div><div class="line"></div><div class="line">def log(args):</div><div class="line">    if isinstance(args, str):</div><div class="line">        def decorator(func):</div><div class="line">            @functools.wraps(func)</div><div class="line">            def wrapper(*args, **kw):</div><div class="line">                print(&apos;begin %s %s():&apos;%(args,func.__name__))</div><div class="line">                func(*args, **kw)</div><div class="line">                print(&apos;end %s %s():&apos;%(args,func.__name__))</div><div class="line">            return wrapper</div><div class="line">        return decorator</div><div class="line">    else:</div><div class="line">        func = args</div><div class="line">        @functools.wraps(func)</div><div class="line">        def wrapper(*args, **kw):</div><div class="line">            print(&apos;begin call %s():&apos; % func.__name__)</div><div class="line">            func(*args, **kw)</div><div class="line">            print(&apos;end call %s():&apos;%func.__name__)</div><div class="line">        return wrapper</div><div class="line"></div><div class="line">@log</div><div class="line">def now():</div><div class="line">    print(&apos;2015-3-25&apos;)</div><div class="line">now()</div><div class="line"></div><div class="line">@log(&apos;exective&apos;)</div><div class="line">def tomorrow():</div><div class="line">    print(&apos;2017/2/13&apos;)</div><div class="line"></div><div class="line">now()</div><div class="line">tomorrow()</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="偏函数"><a href="#偏函数" class="headerlink" title="偏函数"></a>偏函数</h3><p>当函数的参数个数太多，需要简化时，使用functools.partial可以创建一个新的函数，这个新函数可以固定住原函数的部分参数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">print(int(&apos;101&apos;, base=2))</div><div class="line"># 将str转int的int函数改装成2进制,固定base参数为2</div><div class="line">int2 = functools.partial(int, base=2)</div><div class="line">print(int2(&apos;101&apos;))</div></pre></td></tr></table></figure></p>
<h2 id="模块"><a href="#模块" class="headerlink" title="模块"></a>模块</h2><ul>
<li>在Python中，一个.py文件就称之为一个模块（Module）</li>
<li>按目录来组织模块的方法，称为包（Package）</li>
</ul>
<h3 id="使用模块"><a href="#使用模块" class="headerlink" title="使用模块"></a>使用模块</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">import module_name</div></pre></td></tr></table></figure>
<h3 id="安装第三方模块"><a href="#安装第三方模块" class="headerlink" title="安装第三方模块"></a>安装第三方模块</h3><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><ul>
<li>第三方模块搜索：<a href="pypi.python.org">下载地址</a></li>
<li>pip安装:比如要做图片处理Pillow，<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip install Pillow</div></pre></td></tr></table></figure>
</li>
</ul>
<p>图片压缩<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">from PIL import Image</div><div class="line"></div><div class="line">im = Image.open(&apos;xiaolan.jpg&apos;)</div><div class="line">print(im.format, im.size, im.mode)</div><div class="line">im.thumbnail((400, 400))</div><div class="line">im.save(&apos;xiaolan.png&apos;, &apos;JPEG&apos;)</div></pre></td></tr></table></figure></p>
<h4 id="模块搜索路径"><a href="#模块搜索路径" class="headerlink" title="模块搜索路径"></a>模块搜索路径</h4><p>Python解释器会搜索当前目录、所有已安装的内置模块和第三方模块。搜索路径存放在sys模块的path变量中,查看sys.path<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">import sys</div><div class="line">print(sys.path)</div></pre></td></tr></table></figure></p>
<p>如果我们要添加自己的搜索目录，有两种方法：  </p>
<ol>
<li>一是直接修改sys.path，添加要搜索的目录：<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; import sys</div><div class="line">&gt;&gt;&gt; sys.path.append(&apos;/Users/michael/my_py_scripts&apos;)</div></pre></td></tr></table></figure>
</li>
</ol>
<p>这种方法是在运行时修改，运行结束后失效。</p>
<ol>
<li>第二种方法是设置环境变量PYTHONPATH，该环境变量的内容会被自动添加到模块搜索路径中。</li>
</ol>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000" target="_blank" rel="external">http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000</a><br><a href="http://blog.csdn.net/pipisorry/article/details/39909057" target="_blank" rel="external">http://blog.csdn.net/pipisorry/article/details/39909057</a>  </p>
</the></excerpt>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[druid.io---Coordinator balancer源码解析]]></title>
      <url>https://fangyeqing.github.io/2016/11/01/druid.io---Coordinator_balancer%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/</url>
      <content type="html"><![CDATA[<excerpt in="" index="" |="" 首页摘要="">   

<p>Druid.io每次增加历史节点，经过一段时间的balance，数据总会均衡，下面从代码分析一下原因。Druid版本为0.9.11</p>
<a id="more"></a>  
<the rest="" of="" contents="" |="" 余下全文=""> 

<h2 id="DruidCoordinatorBalancer-java"><a href="#DruidCoordinatorBalancer-java" class="headerlink" title="DruidCoordinatorBalancer.java"></a>DruidCoordinatorBalancer.java</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line">public class DruidCoordinatorBalancer implements DruidCoordinatorHelper</div><div class="line">&#123;</div><div class="line"> @Override</div><div class="line">  public DruidCoordinatorRuntimeParams run(DruidCoordinatorRuntimeParams params)</div><div class="line">  &#123;</div><div class="line">    final BalancerStrategy strategy = params.getBalancerStrategyFactory().createBalancerStrategy(referenceTimestamp);</div><div class="line">    final int maxSegmentsToMove = params.getCoordinatorDynamicConfig().getMaxSegmentsToMove();</div><div class="line"></div><div class="line">    for (Map.Entry&lt;String, MinMaxPriorityQueue&lt;ServerHolder&gt;&gt; entry :</div><div class="line">        params.getDruidCluster().getCluster().entrySet()) &#123;//循环cluster中的所有server</div><div class="line"></div><div class="line">      final List&lt;ServerHolder&gt; serverHolderList = Lists.newArrayList(entry.getValue());</div><div class="line"></div><div class="line">      for (int iter = 0; iter &lt; maxSegmentsToMove; iter++) &#123;//循环maxSegmentsToMove次</div><div class="line">        //选择将要移动的segment</div><div class="line">        final BalancerSegmentHolder segmentToMove = strategy.pickSegmentToMove(serverHolderList);</div><div class="line">        </div><div class="line">        if (segmentToMove != null &amp;&amp; params.getAvailableSegments().contains(segmentToMove.getSegment())) &#123;</div><div class="line">        //选择将要移动到的server</div><div class="line">          final ServerHolder holder = strategy.findNewSegmentHomeBalancer(segmentToMove.getSegment(), serverHolderList);</div><div class="line"></div><div class="line">          if (holder != null) &#123;//执行移动</div><div class="line">            moveSegment(segmentToMove, holder.getServer(), params);</div><div class="line">          &#125;</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">  &#125;</div><div class="line">  //移动单个segment，入参：segment、移动到哪个server，协调节点参数</div><div class="line">  protected void moveSegment(</div><div class="line">      final BalancerSegmentHolder segment,</div><div class="line">      final ImmutableDruidServer toServer,</div><div class="line">      final DruidCoordinatorRuntimeParams params</div><div class="line">    )&#123;&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="选择将要移动的segment—pickSegmentToMove-方法"><a href="#选择将要移动的segment—pickSegmentToMove-方法" class="headerlink" title="选择将要移动的segment—pickSegmentToMove()方法"></a>选择将要移动的segment—pickSegmentToMove()方法</h3><p>所在类：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">public class RandomBalancerStrategy implements BalancerStrategy</div><div class="line">&#123;</div><div class="line">  @Override</div><div class="line">  public BalancerSegmentHolder pickSegmentToMove(List&lt;ServerHolder&gt; serverHolders)</div><div class="line">  &#123;</div><div class="line">    return sampler.getRandomBalancerSegmentHolder(serverHolders);</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h4 id="getRandomBalancerSegmentHolder"><a href="#getRandomBalancerSegmentHolder" class="headerlink" title="getRandomBalancerSegmentHolder"></a>getRandomBalancerSegmentHolder</h4><p>循环遍历serverList中的每一个server中的每一个segment，每个segment都是等概率的1/N，所以当前已有segment越多的server选中segment的概率会越大。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">public class ReservoirSegmentSampler</div><div class="line">&#123;</div><div class="line"></div><div class="line">  public BalancerSegmentHolder getRandomBalancerSegmentHolder(final List&lt;ServerHolder&gt; serverHolders)</div><div class="line">  &#123;</div><div class="line">    final Random rand = new Random();</div><div class="line">    ServerHolder fromServerHolder = null;</div><div class="line">    DataSegment proposalSegment = null;</div><div class="line">    int numSoFar = 0;</div><div class="line">    </div><div class="line">    for (ServerHolder server : serverHolders) &#123;//serverList中循环每一个server</div><div class="line">      for (DataSegment segment : server.getServer().getSegments().values()) &#123;//循环每一个server中的segment</div><div class="line">        int randNum = rand.nextInt(numSoFar + 1);</div><div class="line">        // w.p. 1 / (numSoFar+1), swap out the server and segment</div><div class="line">        if (randNum == numSoFar) &#123;//循环过程中，后面的会覆盖前面的</div><div class="line">          fromServerHolder = server;</div><div class="line">          proposalSegment = segment;</div><div class="line">        &#125;</div><div class="line">        numSoFar++;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    if (fromServerHolder != null) &#123;</div><div class="line">      return new BalancerSegmentHolder(fromServerHolder.getServer(), proposalSegment);</div><div class="line">    &#125; else &#123;</div><div class="line">      return null;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>实现一个等概率的选择：<br>比如说一共有5个数，第2个选中的话，就需要第3、4、5选不中：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">1/2 * 2/3 * 3/4 * 4/5 =1/5</div></pre></td></tr></table></figure></p>
<p>第i个：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">1/(i+1)*(i+1)/(i+2)*……*(n-2)/(n-1)*(n-1)/n=1/n</div></pre></td></tr></table></figure></p>
<h3 id="选择将要移动到的server—findNewSegmentHomeBalancer"><a href="#选择将要移动到的server—findNewSegmentHomeBalancer" class="headerlink" title="选择将要移动到的server—findNewSegmentHomeBalancer()"></a>选择将要移动到的server—findNewSegmentHomeBalancer()</h3><p>所在类：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line">public class CostBalancerStrategy implements BalancerStrategy</div><div class="line">&#123;</div><div class="line">  @Override</div><div class="line">  public ServerHolder findNewSegmentHomeBalancer(</div><div class="line">      DataSegment proposalSegment, List&lt;ServerHolder&gt; serverHolders</div><div class="line">  )</div><div class="line">  &#123;</div><div class="line">    return chooseBestServer(proposalSegment, serverHolders, true).rhs;</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line"> protected Pair&lt;Double, ServerHolder&gt; chooseBestServer(</div><div class="line">      final DataSegment proposalSegment,</div><div class="line">      final Iterable&lt;ServerHolder&gt; serverHolders,</div><div class="line">      final boolean includeCurrentServer</div><div class="line">  )</div><div class="line">  &#123;</div><div class="line">    Pair&lt;Double, ServerHolder&gt; bestServer = Pair.of(Double.POSITIVE_INFINITY, null);</div><div class="line"></div><div class="line">    ListeningExecutorService service = MoreExecutors.listeningDecorator(Executors.newFixedThreadPool(threadCount));</div><div class="line">    List&lt;ListenableFuture&lt;Pair&lt;Double, ServerHolder&gt;&gt;&gt; futures = Lists.newArrayList();</div><div class="line">    //开启一个线程池，将serverList中的每个server计算出computeCost的值</div><div class="line">    for (final ServerHolder server : serverHolders) &#123;</div><div class="line">      futures.add(</div><div class="line">          service.submit(</div><div class="line">              new Callable&lt;Pair&lt;Double, ServerHolder&gt;&gt;()</div><div class="line">              &#123;</div><div class="line">                @Override</div><div class="line">                public Pair&lt;Double, ServerHolder&gt; call() throws Exception</div><div class="line">                &#123;</div><div class="line">                  return Pair.of(computeCost(proposalSegment, server, includeCurrentServer), server);</div><div class="line">                &#125;</div><div class="line">              &#125;</div><div class="line">          )</div><div class="line">      );</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    final ListenableFuture&lt;List&lt;Pair&lt;Double, ServerHolder&gt;&gt;&gt; resultsFuture = Futures.allAsList(futures);</div><div class="line">    </div><div class="line">    try &#123;</div><div class="line">      for (Pair&lt;Double, ServerHolder&gt; server : resultsFuture.get()) &#123;</div><div class="line">        if (server.lhs &lt; bestServer.lhs) &#123;//比较computeCost计算出的值最小的为best</div><div class="line">          bestServer = server;</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    catch (Exception e) &#123;</div><div class="line">      log.makeAlert(e, &quot;Cost Balancer Multithread strategy wasn&apos;t able to complete cost computation.&quot;).emit();</div><div class="line">    &#125;</div><div class="line">    service.shutdown();</div><div class="line">    return bestServer;</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<h4 id="server的cost的计算方法"><a href="#server的cost的计算方法" class="headerlink" title="server的cost的计算方法"></a>server的cost的计算方法</h4><p>当前server已有的and将要加载的每个seg，与将要移动的seg的cost值之和。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">protected double computeCost(</div><div class="line">     final DataSegment proposalSegment, final ServerHolder server, final boolean includeCurrentServer</div><div class="line"> )</div><div class="line"> &#123;</div><div class="line">   final long proposalSegmentSize = proposalSegment.getSize();</div><div class="line"></div><div class="line">   //如果当前server已有该seg</div><div class="line">   if (!includeCurrentServer &amp;&amp; server.isServingSegment(proposalSegment)) &#123;</div><div class="line">     return Double.POSITIVE_INFINITY;</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   //如果当前server正在load该segment或者存储空间不够</div><div class="line">   if (proposalSegmentSize &gt; server.getAvailableSize() || server.isLoadingSegment(proposalSegment)) &#123;</div><div class="line">     return Double.POSITIVE_INFINITY;</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   double cost = 0d;</div><div class="line"></div><div class="line">    //将要balance的seg与当前server的cost和,不包括该seg</div><div class="line">   cost += computeJointSegmentsCost(</div><div class="line">       proposalSegment,</div><div class="line">       Iterables.filter(</div><div class="line">           server.getServer().getSegments().values(),</div><div class="line">           Predicates.not(Predicates.equalTo(proposalSegment))</div><div class="line">       )</div><div class="line">   );</div><div class="line"></div><div class="line">   //将要load的segment与当前server的cost和</div><div class="line">   cost += computeJointSegmentsCost(proposalSegment, server.getPeon().getSegmentsToLoad());</div><div class="line"></div><div class="line">   return cost;</div><div class="line"> &#125;</div></pre></td></tr></table></figure></p>
<h4 id="两个seg的cost的计算方法"><a href="#两个seg的cost的计算方法" class="headerlink" title="两个seg的cost的计算方法"></a>两个seg的cost的计算方法</h4><p>如果要提高查询速度，<strong>同一个查询查询的数据尽量分散在不同的server</strong>。而上述<strong>chooseBestServer中选择最佳server是选择cost最小的</strong>，即将要移动的seg移动到cost小的server。 </p>
<h5 id="druid-0-9-0"><a href="#druid-0-9-0" class="headerlink" title="druid 0.9.0"></a>druid 0.9.0</h5><ul>
<li>recencyPenalty: 离得越近的时间，越可能在同一个查询中  </li>
<li>dataSourcePenalty: 同一个数据源的数据，越可能在同一个查询中</li>
<li>gapPenalty: 重叠区域越多，越可能在同一个查询中   </li>
</ul>
<p>cost越大的因素：seg大小越大、七天内离现在越近、同一个数据源、两段seg的区间重叠或者间距越小。<br>cost越小的因素：seg大小越小、七天内离现在越远、非同一个数据源、两段seg的区间间距越大</p>
<p>同一个server符合cost越小，即数据段离得越远、不重叠且间距大、来自不同的数据源。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line">public double  computeJointSegmentCosts(final DataSegment segment1, final DataSegment segment2)</div><div class="line">&#123;</div><div class="line">    final Interval gap = segment1.getInterval().gap(segment2.getInterval());</div><div class="line"></div><div class="line">    final double baseCost = Math.min(segment1.getSize(), segment2.getSize());//取两个seg的最小值</div><div class="line">    double recencyPenalty = 1;//默认值为1，如果两个seg都为七天之内的数据，最大为4，离得越远则值越小</div><div class="line">    double dataSourcePenalty = 1;//默认为1，两个seg属于同一个数据源则为2</div><div class="line">    double gapPenalty = 1;//两个seg有重叠部分为2，否则最大为2，重叠区域越大值越小</div><div class="line"></div><div class="line">    if (segment1.getDataSource().equals(segment2.getDataSource())) &#123;</div><div class="line">      dataSourcePenalty = 2;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    double segment1diff = referenceTimestamp - segment1.getInterval().getEndMillis();</div><div class="line">    double segment2diff = referenceTimestamp - segment2.getInterval().getEndMillis();</div><div class="line">    if (segment1diff &lt; SEVEN_DAYS_IN_MILLIS &amp;&amp; segment2diff &lt; SEVEN_DAYS_IN_MILLIS) &#123;</div><div class="line">      recencyPenalty = (2 - segment1diff / SEVEN_DAYS_IN_MILLIS) * (2 - segment2diff / SEVEN_DAYS_IN_MILLIS);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    /** gap是null如果两段区间重叠或者他们相邻 */</div><div class="line">    if (gap == null) &#123;</div><div class="line">      gapPenalty = 2;</div><div class="line">    &#125; else &#123;</div><div class="line">      long gapMillis = gap.toDurationMillis();</div><div class="line">      if (gapMillis &lt; THIRTY_DAYS_IN_MILLIS) &#123;</div><div class="line">        gapPenalty = 2 - gapMillis / THIRTY_DAYS_IN_MILLIS;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    final double cost = baseCost * recencyPenalty * dataSourcePenalty * gapPenalty;</div><div class="line"></div><div class="line">    return cost;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h5 id="druid-0-9-1改进"><a href="#druid-0-9-1改进" class="headerlink" title="druid 0.9.1改进"></a>druid 0.9.1改进</h5><p><a href="https://github.com/druid-io/druid/pull/2972" target="_blank" rel="external">https://github.com/druid-io/druid/pull/2972</a>  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">static double computeJointSegmentsCost(final DataSegment segment, final Iterable&lt;DataSegment&gt; segmentSet)</div><div class="line">  &#123;</div><div class="line">    double totalCost = 0;</div><div class="line">    for (DataSegment s : segmentSet) &#123;</div><div class="line">      totalCost += computeJointSegmentsCost(segment, s);</div><div class="line">    &#125;</div><div class="line">    return totalCost;</div><div class="line">  &#125;</div><div class="line">  </div><div class="line">   public static double computeJointSegmentsCost(final DataSegment segmentA, final DataSegment segmentB)</div><div class="line">  &#123;</div><div class="line">    final Interval intervalA = segmentA.getInterval();</div><div class="line">    final Interval intervalB = segmentB.getInterval();</div><div class="line"></div><div class="line">    final double t0 = intervalA.getStartMillis();</div><div class="line">    final double t1 = (intervalA.getEndMillis() - t0) / MILLIS_FACTOR;</div><div class="line">    final double start = (intervalB.getStartMillis() - t0) / MILLIS_FACTOR;</div><div class="line">    final double end = (intervalB.getEndMillis() - t0) / MILLIS_FACTOR;</div><div class="line"></div><div class="line">    // constant cost-multiplier for segments of the same datsource</div><div class="line">    final double multiplier = segmentA.getDataSource().equals(segmentB.getDataSource()) ? 2.0 : 1.0;</div><div class="line"></div><div class="line">    return INV_LAMBDA_SQUARE * intervalCost(t1, start, end) * multiplier;</div><div class="line">    //入参分别为：A区间的end，B区间的start、B区间的end</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
<p>具体函数：<br>两个seg的时间区间 ：X = [x0=0, x1) and Y = [y0, y1)<br><img src="http://note.youdao.com/yws/public/resource/32442f2d923ee4564e15f34e1a33fdd5/B15CA2C4A2A9405F9A5E374F0EAB839D" alt="image">  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div></pre></td><td class="code"><pre><div class="line">public static double intervalCost(double x1, double y0, double y1)</div><div class="line">  &#123;</div><div class="line">    if (x1 == 0 || y1 == y0) &#123;</div><div class="line">      return 0;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    if (y0 &lt; 0) &#123;//y0&lt;x0交换两个区间，便于计算</div><div class="line">      double tmp = x1;</div><div class="line">      x1 = y1 - y0;</div><div class="line">      y1 = tmp - y0;</div><div class="line">      y0 = -y0;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    // 上述情况交换区间之后，肯定满足x0 &lt;= y0</div><div class="line">    if (y0 &lt; x1) &#123;//有重叠,两种情况</div><div class="line">    // X  = [ A )[ B )[ C )   or  [ A )[ B )</div><div class="line">    // Y  =      [   )                 [   )[ C )</div><div class="line">    // A is empty if y0 = 0</div><div class="line">    // C is empty if y1 = x1</div><div class="line">    </div><div class="line">    //cost(X, Y) = cost(A, Y) + cost(B, C) + cost(B, B)</div><div class="line">    </div><div class="line">    //cost(A, Y) and cost(B, C) can be calculated using the non-overlapping case</div><div class="line">    //which reduces the overlapping case to computing</div><div class="line">    </div><div class="line">    //cost(B, B) = \int_0^&#123;\beta&#125; \int_&#123;0&#125;^&#123;\beta&#125; e^&#123;-|x-y|&#125;dxdy</div><div class="line">    //           = 2 \cdot (\beta + e^&#123;-\beta&#125; - 1)</div><div class="line">    </div><div class="line">    //            where \beta is the length of interval B</div><div class="line">    </div><div class="line">      final double beta;  // b1 - y0, length of interval B</div><div class="line">      final double gamma; // c1 - y0, length of interval C</div><div class="line">      if (y1 &lt;= x1) &#123;</div><div class="line">        beta = y1 - y0;</div><div class="line">        gamma = x1 - y0;</div><div class="line">      &#125; else &#123;</div><div class="line">        beta = x1 - y0;</div><div class="line">        gamma = y1 - y0;</div><div class="line">      &#125;</div><div class="line">      return intervalCost(y0, y0, y1) + // cost(A, Y)</div><div class="line">             intervalCost(beta, beta, gamma) + // cost(B, C)</div><div class="line">             2 * (beta + FastMath.exp(-beta) - 1); // cost(B, B)</div><div class="line">    &#125; else &#123;//没有重叠</div><div class="line">    //cost(X, Y) = \int_0^&#123;x_1&#125; \int_&#123;y_0&#125;^&#123;y_1&#125; e^&#123;-|x-y|&#125; dxdy</div><div class="line">    //            = \int_0^&#123;x_1&#125; \int_&#123;y_0&#125;^&#123;y_1&#125; e^&#123;x-y&#125; dxdy</div><div class="line">    //           = (e^&#123;-y_1&#125; - e^&#123;-y_0&#125;) - (e^&#123;x_1-y_1&#125; - e^&#123;x_1-y_0&#125;)</div><div class="line">      final double exy0 = FastMath.exp(x1 - y0);</div><div class="line">      final double exy1 = FastMath.exp(x1 - y1);</div><div class="line">      final double ey0 = FastMath.exp(0f - y0);</div><div class="line">      final double ey1 = FastMath.exp(0f - y1);</div><div class="line"></div><div class="line">      return (ey1 - ey0) - (exy1 - exy0);</div><div class="line">    &#125;</div><div class="line">  &#125;</div></pre></td></tr></table></figure>
</the></excerpt>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[druid.io实践3---sql形式查询接口plyql]]></title>
      <url>https://fangyeqing.github.io/2016/10/30/druid.io%E5%AE%9E%E8%B7%B53---sql%E5%BD%A2%E5%BC%8F%E6%9F%A5%E8%AF%A2%E6%8E%A5%E5%8F%A3/</url>
      <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br>druid提供http rest形式的查询接口，但是默认是json形式的，给没使用过druid的人用还是不太友好。这里介绍几种工具：</excerpt></p>
<ul>
<li>plyql（推荐）:imply.io自家产品，持续更新中。</li>
<li>Sql4D：java客户端，yahoo的，很久都没跟新了，不支持druid新增功能，例如lookup等。</li>
<li>pydruid: python客户端，airbnb/superset使用pydruid。</li>
</ul>
<a id="more"></a>  
<the rest="" of="" contents="" |="" 余下全文="">  

<h2 id="http-rest接口"><a href="#http-rest接口" class="headerlink" title="http rest接口"></a>http rest接口</h2><p>使用方式：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">curl -X POST &apos;&lt;queryable_host&gt;:&lt;port&gt;/druid/v2/?pretty&apos; -H &apos;Content-Type:application/json&apos; -d @&lt;query_json_file&gt;</div></pre></td></tr></table></figure></p>
<p>json内容，例如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">  &quot;queryType&quot;: &quot;timeseries&quot;,</div><div class="line">  &quot;dataSource&quot;: &quot;sample_datasource&quot;,</div><div class="line">  &quot;granularity&quot;: &quot;day&quot;,</div><div class="line">  &quot;aggregations&quot;: [</div><div class="line">    &#123; &quot;type&quot;: &quot;longSum&quot;, &quot;name&quot;: &quot;sample_name1&quot;, &quot;fieldName&quot;: &quot;sample_fieldName1&quot; &#125;</div><div class="line">  ],</div><div class="line">  &quot;intervals&quot;: [ &quot;2012-01-01T00:00:00.000/2012-01-04T00:00:00.000&quot; ],</div><div class="line">  &quot;context&quot; : &#123;</div><div class="line">    &quot;skipEmptyBuckets&quot;: &quot;true&quot;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="plyql"><a href="#plyql" class="headerlink" title="plyql"></a>plyql</h2><h3 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h3><p>需要先行安装安装node+npm环境，node版本&gt;= 4.x.x。这里plyql用的当时最新的0.8.13版本。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">npm install -g plyql@0.8.13</div><div class="line">//添加环境变量</div><div class="line">export PATH=/disk2/node-v4.2.2-linux-x64/bin:$PATH</div></pre></td></tr></table></figure></p>
<p>执行以下操作之后，在本地相当于开起了一个druid-mysql形式的接口，端口为3307。后续操作就跟操作mysql几乎一样了。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">plyql -h druid-broker:port -c 8 --experimental-mysql-gateway 3307</div></pre></td></tr></table></figure></p>
<p>一些可供配置的参数：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">--help	print this help message</div><div class="line">--version	display the version number</div><div class="line">-v, --verbose	display the queries that are being made</div><div class="line">展示查询和转换之后的json</div><div class="line">-h, --host	the host to connect to</div><div class="line">-s, --source	use this source for the query (supersedes FROM clause)</div><div class="line">-i, --interval	add (AND) a __time filter between NOW-INTERVAL and NOW</div><div class="line">-i P2Y 会不查询近6个小时的数据。</div><div class="line">-tz, --timezone	the default timezone</div><div class="line">-tz Asia/Shanghai 为东八区，加不加一样，应该是默认时区</div><div class="line">-q, --query	the query to run</div><div class="line">-o, --output	specify the output format. Possible values: json (default), csv, tsv, flat</div><div class="line">-a, --allow	enable a behaviour that is turned off by default eternity allow queries not filtered on time select allow select queries</div><div class="line">-t, --timeout	the time before a query is timed out in ms (default: 60000)</div><div class="line">超时时间，默认60s</div><div class="line">-r, --retry	the number of tries a query should be attempted on error, 0 = unlimited, (default: 2)</div><div class="line">-c, --concurrent	the limit of concurrent queries that could be made simultaneously, 0 = unlimited, (default: 2)</div><div class="line">并发查询数，默认2</div><div class="line">--rollup	use rollup mode [COUNT() -&gt; SUM(count)]</div></pre></td></tr></table></figure></p>
<h3 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h3><p>这里进行简单的启动、监控。使用linux-crontab执行定时任务，启动并且监听plyql服务。后续可以接入graphite或者其他监控报警系统中。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">* * * * * /disk1/fangyq/start-plyql-cron.sh online &gt;&gt; /disk1/fangyq/log/cron.log</div></pre></td></tr></table></figure></p>
<p>监听3307端口，当没有监听时，启动plyql服务。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">#!/bin/sh</div><div class="line"></div><div class="line">logPath=$(cd `dirname $0`; cd ../log ; pwd)</div><div class="line">listen=$(netstat -nlp|grep 3307)</div><div class="line"></div><div class="line">#start plyql</div><div class="line">if [ &quot;$listen&quot; == &quot;&quot; ]</div><div class="line">then</div><div class="line">    echo &apos;INFO: start plyql service&apos;</div><div class="line">    nohup plyql -h druid-broker:port -c 8 -v --experimental-mysql-gateway 3307 &gt;&gt;$&#123;logPath&#125;/plyql.log &amp;</div><div class="line">fi</div></pre></td></tr></table></figure></p>
<h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><h4 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h4><p>与普通的mysql客户端一样，druid的一个datasource相当于一个table<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mysql -h 127.0.0.1 -P 3307 --default-character-set=utf8</div><div class="line">show tables;</div></pre></td></tr></table></figure></p>
<p>举例：datasource_a如下</p>
<ul>
<li>维度为：id</li>
<li>度量为：impr(展示)，click(点击)<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">desc datasource_a;</div><div class="line">+----------------------------------+--------------+------+------+---------+-------+</div><div class="line">| Field                            | Type         | Null | Key  | Default | Extra |</div><div class="line">+----------------------------------+--------------+------+------+---------+-------+</div><div class="line">| __time                           | timestamp    | YES  |      |    NULL |       | </div><div class="line">| id                               | varchar(255) | YES  |      |    NULL |       | </div><div class="line">| impr                             | double       | YES  |      |    NULL |       |</div><div class="line">| click                            | double       | YES  |      |    NULL |       | </div><div class="line">+----------------------------------+--------------+------+------+---------+-------+</div></pre></td></tr></table></figure>
</li>
</ul>
<p>查询一天内所有的展示和点击。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">SELECT SUM(impr) AS impr,SUM(click) AS click FROM datasource_a WHERE __time BETWEEN &apos;2016-05-19 00:00:00&apos; AND &apos;2016-05-20 00:00:00&apos;;</div></pre></td></tr></table></figure></p>
<p>查询10天内，id为1的展示和点击，按天聚合。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">SELECT id,SUM(impr) AS impr,SUM(click) AS click FROM datasource_a WHERE __time BETWEEN &apos;2016-05-10 00:00:00&apos; AND &apos;2016-05-20 00:00:00&apos; AND id=&apos;1&apos; GROUP BY id,TIME_BUCKET(__time,P1D,&apos;Asia/Shanghai&apos;) HAVING impr&gt;0 OR click&gt;0;</div></pre></td></tr></table></figure></p>
<h4 id="程序"><a href="#程序" class="headerlink" title="程序"></a>程序</h4><p>跟普通的访问mysql一样。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">import lombok.Cleanup;</div><div class="line">import org.junit.Test;</div><div class="line">import java.sql.*;</div><div class="line"></div><div class="line">public class PlyqlTest &#123;</div><div class="line">    @Test</div><div class="line">    public void plyql()&#123;</div><div class="line">        String plyql_url=&quot;jdbc:mysql://plyql-host:3307/plyql1?useUnicode=true&amp;amp;characterEncoding=utf8&quot;;</div><div class="line">        try &#123;</div><div class="line">            Class.forName(&quot;com.mysql.jdbc.Driver&quot;);</div><div class="line">            @Cleanup Connection con = DriverManager.getConnection(plyql_url);</div><div class="line">            @Cleanup Statement stmt = con.createStatement();</div><div class="line">            @Cleanup ResultSet rs = stmt.executeQuery(</div><div class="line">                    &quot;SELECT id,SUM(impr) AS impr,SUM(click) AS click FROM datasource_a WHERE __time BETWEEN &apos;2016-05-10 00:00:00&apos; AND &apos;2016-05-20 00:00:00&apos; GROUP BY id&quot;</div><div class="line">            );</div><div class="line">            while (rs.next()) &#123;</div><div class="line">                String id = rs.getString(&quot;id&quot;);</div><div class="line">                double impr = rs.getDouble(&quot;impr&quot;);</div><div class="line">                System.out.println(id+&quot; &quot;+impr);</div><div class="line">            &#125;</div><div class="line">        &#125; catch (Exception e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="语法说明"><a href="#语法说明" class="headerlink" title="语法说明"></a>语法说明</h3><p>1）聚合字段<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">LONG_SUM   ==&gt;  SUM</div><div class="line">cardinality（hyperLogLog uniques）  ==&gt;  COUNT_DISTINCT</div></pre></td></tr></table></figure></p>
<p>例如，uv字段，COUNT_DISTINCT(uv)算出来为double类型,结果需要取整<br>2）where必须先写__time，再AND其他的。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">WHERE __time &gt;=&apos;2016-05-19T00:00:00.000+08:00&apos; AND __time&lt;=&apos;2016-05-19T23:59:59.999+08:00&apos;</div><div class="line">WHERE __time &gt;=&apos;2016-05-19 00:00:00&apos; AND __time&lt;=&apos;2016-05-19 23:59:59&apos;</div></pre></td></tr></table></figure></p>
<p>3）时间颗粒度：<br>按天和按小时:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">group by day    ==&gt; GROUP BY TIME_BUCKET(__time,P1D,&apos;Asia/Shanghai&apos;)</div><div class="line">group by hour   ==&gt; GROUP BY TIME_BUCKET(__time,PT1H,&apos;Asia/Shanghai&apos;)</div></pre></td></tr></table></figure></p>
<p>4）limit只有一个参数，因为在druid中只有topN查询。分页查询只能在程序中先查出总数，再取子集。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">limit offset,max  ==&gt;   limit offset+max   </div><div class="line">                        lrs.subList(offset,max);</div></pre></td></tr></table></figure></p>
<h2 id="Sql4D"><a href="#Sql4D" class="headerlink" title="Sql4D"></a>Sql4D</h2><h3 id="客户端-1"><a href="#客户端-1" class="headerlink" title="客户端"></a>客户端</h3><p>安装<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">git clone https://github.com/fangyeqing/Sql4D.git</div><div class="line">cd Sql4D/Sql4DClient</div><div class="line">mvn clean install</div><div class="line">vi dsql  #修改如下:</div><div class="line">java -jar target/Sql4DClient-4.1.0.jar  -bh broker-host -bp broker-port  -ch coordinator-host -cp 8050  -oh broker-host -op broker-port -i 100</div><div class="line">./dsql  #启动client</div></pre></td></tr></table></figure></p>
<p>连接上druid之后，操作如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">show tables           (显示datasources)</div><div class="line">describe TableName    (显示数据源的schema)</div><div class="line">trace=[true|false]    (打印转换后的json，默认false)</div><div class="line">querymode=[sql|json]  (查询模式，默认sql)</div><div class="line">quit                  (退出)</div><div class="line">select queries        (GroupBy, TimeSeries, TopN, Select, Search). See wiki for examples: https://github.com/srikalyc/Sql4D/wiki/Sql4DCompiler</div><div class="line">generatebean=BeanName (This command must be preceding a SQL, it generates a java source file BeanName.java which extends DruidBaseBean.</div></pre></td></tr></table></figure></p>
<h3 id="程序-1"><a href="#程序-1" class="headerlink" title="程序"></a>程序</h3><p>maven依赖，可以直接用如下的，不过有一些bug。最好是用修改后的版本重新打包或者发布再添加依赖。<a href="https://github.com/fangyeqing/Sql4D" target="_blank" rel="external">https://github.com/fangyeqing/Sql4D</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">&lt;dependency&gt;</div><div class="line">    &lt;groupId&gt;com.yahoo.sql4d&lt;/groupId&gt;</div><div class="line">    &lt;artifactId&gt;Sql4Ddriver&lt;/artifactId&gt;</div><div class="line">    &lt;version&gt;4.1.0&lt;/version&gt;</div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure></p>
<p>使用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">@CommonsLog</div><div class="line">@Data</div><div class="line">public class DruidDataSource &#123;</div><div class="line">    private String bHost;</div><div class="line">    private int bPort;</div><div class="line">    private String cHost;</div><div class="line">    private int cPort;</div><div class="line">    private int maxConnsInPool;</div><div class="line">    private int maxBrokerConns;</div><div class="line">    private int maxCoordConns;</div><div class="line">    private int maxOverLordConns;</div><div class="line">    public static DDataSource driver;</div><div class="line">    @PostConstruct</div><div class="line">    public void init()&#123;</div><div class="line">        DDataSource.adjustPoolSettings(maxConnsInPool,maxBrokerConns,maxCoordConns,maxOverLordConns);</div><div class="line">        driver = new DDataSource(bHost, bPort, cHost, cPort);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    public List&lt;DruidBaseBean&gt; query(String sql, Class type) &#123;</div><div class="line">        Either&lt;String, Either&lt;List&lt;DruidBaseBean&gt;, Map&lt;Object, DruidBaseBean&gt;&gt;&gt; response = driver.query(sql, null, type, null, false);</div><div class="line">        return response.right().get().left().get();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="pydruid"><a href="#pydruid" class="headerlink" title="pydruid"></a>pydruid</h2><p>null</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://plywood.imply.io/plyql#examples" target="_blank" rel="external">http://plywood.imply.io/plyql#examples</a><br><a href="http://imply.io/post/2016/05/04/programmatic-plyql.html" target="_blank" rel="external">http://imply.io/post/2016/05/04/programmatic-plyql.html</a><br><a href="https://github.com/implydata/plyql" target="_blank" rel="external">https://github.com/implydata/plyql</a><br><a href="https://github.com/srikalyc/Sql4D" target="_blank" rel="external">https://github.com/srikalyc/Sql4D</a></p>
</the>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[druid.io实践2---集群数据迁移]]></title>
      <url>https://fangyeqing.github.io/2016/10/29/druid.io%E5%AE%9E%E8%B7%B52---%E9%9B%86%E7%BE%A4%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB/</url>
      <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br>数据迁移指的是两套Druid、kafka、HDFS集群之间的数据迁移。其中会用到流处理框架Samza，Hadoop distcp命令，Druid重建索引的insert-segment-to-db工具。</excerpt></p>
<h2 id="整体流程"><a href="#整体流程" class="headerlink" title="整体流程"></a>整体流程</h2><p><img src="http://note.youdao.com/yws/public/resource/eb83866d6603d9a10ca5134681ab7970/xmlnote/5525411332C94BC395CFC3E7EF21F06A/23416" alt="image"></p>
<a id="more"></a>  
<p><the rest="" of="" contents="" |="" 余下全文="">   </the></p>
<h3 id="背景交代"><a href="#背景交代" class="headerlink" title="背景交代"></a>背景交代</h3><p>Druid的DeepStorage采用HDFS。</p>
<p>实时输入流通过tranquility从kafka消费topic进行realtime indexing。<br>批量数据通过camus拉取kafka数据到hdfs，部分topic使用camus sweep进行去重。周期提交新提交（修改）目录到overloard进行batch indexing。  </p>
<h3 id="大体思路"><a href="#大体思路" class="headerlink" title="大体思路"></a>大体思路</h3><ul>
<li>kafka镜像流：<br>启动samza任务，从老的kafka集群consume消息，produce到新的kafka集群。直接使用kafka的mirror也可以，由于项目使用的arvo编解码，涉及到schema-id的问题，所以只能通过samza任务。</li>
<li>druid批量数据获取&amp;index：<br>给新druid集群提交任务，camus批量拉取数据，发送post请求提交配置json到overload执行batch index。 </li>
<li>脏数据覆盖(批量路线稳定、数据正确之后)  <ul>
<li>利用hadoop-distcp迁移老hdfs中之前所有的segment数据</li>
<li>利用insert-segment-to-db工具在mysql生成这之前的元数据（索引）。</li>
</ul>
</li>
<li>druid实时数据获取&amp;index：<br>Tranquility任务，获取实时数据，提交给overload执行realtime index   </li>
<li>切换（稳定后）<br>将老的kafka的流的生产者逐个切换到新的kafka上</li>
</ul>
<h2 id="使用工具介绍"><a href="#使用工具介绍" class="headerlink" title="使用工具介绍"></a>使用工具介绍</h2><h3 id="Samza-Task"><a href="#Samza-Task" class="headerlink" title="Samza Task"></a>Samza Task</h3><p>可以参考博客中的<a href="https://fangyeqing.github.io/categories/samza/">Samza相关</a></p>
<h3 id="hadoop-distcp"><a href="#hadoop-distcp" class="headerlink" title="hadoop-distcp"></a>hadoop-distcp</h3><p>迁移老hdfs中之前所有的segment数据  </p>
<h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>DistCp（分布式拷贝）是用于大规模集群内部和集群之间拷贝的工具。 它使用Map/Reduce实现文件分发，错误处理和恢复，以及报告生成。 它把文件和目录的列表作为map任务的输入，每个任务会完成源列表中部分文件的拷贝</p>
<p><a href="https://hadoop.apache.org/docs/r1.0.4/cn/distcp.html" target="_blank" rel="external">https://hadoop.apache.org/docs/r1.0.4/cn/distcp.html</a>  </p>
<p><a href="http://hadoop.apache.org/docs/r2.7.3/hadoop-distcp/DistCp.html" target="_blank" rel="external">http://hadoop.apache.org/docs/r2.7.3/hadoop-distcp/DistCp.html</a>  </p>
<p><a href="http://stackoverflow.com/questions/31862904/how-to-do-i-copy-data-from-one-hdfs-to-another-hdfs" target="_blank" rel="external">http://stackoverflow.com/questions/31862904/how-to-do-i-copy-data-from-one-hdfs-to-another-hdfs</a>  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Usage: $ hadoop distcp &lt;src&gt; &lt;dst&gt;</div><div class="line"></div><div class="line">example: $ hadoop distcp hdfs://nn1:8020/file1 hdfs://nn2:8020/file2</div></pre></td></tr></table></figure>
<p>默认情况下，如果在拷贝的目的地同名文件已经存在，则会默认跳过这些文件。  </p>
<p>可以通过-overwrite选项指定覆盖掉同名文件，或者通过-update选项来更新同名文件。</p>
<p>-overwrite来覆盖刚开启批量任务时的数据不完整那个小时的数据。</p>
<h3 id="insert-segment-to-db"><a href="#insert-segment-to-db" class="headerlink" title="insert-segment-to-db"></a>insert-segment-to-db</h3><h4 id="介绍-1"><a href="#介绍-1" class="headerlink" title="介绍"></a>介绍</h4><p>HDFS上Segment在新的mysql中生成索引    </p>
<p><a href="https://groups.google.com/forum/#!searchin/druid-user/migration$20cluster|sort:relevance/druid-user/1dOMkCrQGmE/b8exkaI4CwAJ" target="_blank" rel="external">https://groups.google.com/forum/#!searchin/druid-user/migration$20cluster|sort:relevance/druid-user/1dOMkCrQGmE/b8exkaI4CwAJ</a><br><a href="https://groups.google.com/forum/#!topic/druid-user/yvnXsDEOkDU" target="_blank" rel="external">https://groups.google.com/forum/#!topic/druid-user/yvnXsDEOkDU</a><br><a href="http://druid.io/docs/0.9.1.1/operations/insert-segment-to-db.html" target="_blank" rel="external">http://druid.io/docs/0.9.1.1/operations/insert-segment-to-db.html</a></p>
<h4 id="参数说明"><a href="#参数说明" class="headerlink" title="参数说明"></a>参数说明</h4><p>–workingDir：segment位置  </p>
<p>–updateDescriptor：默认true，如果desciptor.json的实际路径与“loadSpec”中的路径是不同的，该工具将更新“loadSpec”字段的描述符。 </p>
<p>例如：将老集群的数据迁移过去之后，desciptor.json中的路径没变，生成索引时会更新成现在的路径<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">hadoop fs -cat hdfs://nn1:port/.../dataSource/20161025T060000.000+0800_20161025T070000.000+0800/2016-10-25T07_33_53.379+08_00/0/descriptor.json</div><div class="line"></div><div class="line">其中loadSpec部分：</div><div class="line"></div><div class="line">&quot;loadSpec&quot;: &#123;</div><div class="line">    &quot;type&quot;: &quot;hdfs&quot;,</div><div class="line">    &quot;path&quot;: &quot;hdfs://nn1:port/.../dataSource/20161025T060000.000+0800_20161025T070000.000+0800/2016-10-25T07_33_53.379+08_00/0/index.zip&quot;</div><div class="line">&#125;,</div></pre></td></tr></table></figure></p>
<h4 id="具体操作"><a href="#具体操作" class="headerlink" title="具体操作"></a>具体操作</h4><p>官方例子<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">java </div><div class="line">-Ddruid.metadata.storage.type=mysql </div><div class="line">-Ddruid.metadata.storage.connector.connectURI=jdbc:mysql://mysql-db:3306/druid</div><div class="line">-Ddruid.metadata.storage.connector.user=userxxx</div><div class="line">-Ddruid.metadata.storage.connector.password=passxxxx</div><div class="line">-Ddruid.extensions.loadList=[\&quot;mysql-metadata-storage\&quot;,\&quot;druid-hdfs-storage\&quot;] </div><div class="line">-Ddruid.storage.type=hdfs</div><div class="line">-cp $DRUID_CLASSPATH </div><div class="line">io.druid.cli.Main tools insert-segment-to-db --workingDir hdfs://nn1:port/.../dataSource</div></pre></td></tr></table></figure></p>
<p>打印的日志：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">2016-10-25T17:15:49,342 INFO [main] io.druid.storage.hdfs.HdfsDataSegmentFinder - Found segment [dataSource_2016-01-13T09:00:00.000+08:00_2016-01-13T10:00:00.000+08:00_2016-01-13T10:34:03.820+08:00_6] located at [hdfs://nn1:port/.../dataSource/20160113T090000.000+0800_20160113T100000.000+0800/2016-01-13T10_34_03.820+08_00/6/index.zip]</div><div class="line">2016-10-25T17:15:49,342 INFO [main] io.druid.storage.hdfs.HdfsDataSegmentFinder - Updating loadSpec in descriptor.json at [hdfs://nn1:port/.../dataSource/20160113T090000.000+0800_20160113T100000.000+0800/2016-01-13T10_34_03.820+08_00/6/descriptor.json] with new path [dataSource/20160113T090000.000+0800_20160113T100000.000+0800/2016-01-13T10_34_03.820+08_00/6/index.zip]</div></pre></td></tr></table></figure></p>
<p>会先更新descriptor.json中的路径：由之前的老集群的绝对路径—新集群的相对路径</p>
<h4 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h4><p>后面如果出现找不到新的相对路径的错误，可以把hadoop的配置文件core-site.xml放到common文件夹下。</p>
<blockquote>
<p>java.io.FileNotFoundException:file /dataSource/20161025T060000.000+0800_20161025T070000.000+0800/2016-10-25T07_33_53.379+08_00/0/index.zip does not exist</p>
</blockquote>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[druid.io实践1---查询速度优化]]></title>
      <url>https://fangyeqing.github.io/2016/10/29/druid.io%E5%AE%9E%E8%B7%B51---%E6%9F%A5%E8%AF%A2%E9%80%9F%E5%BA%A6%E4%BC%98%E5%8C%96/</url>
      <content type="html"><![CDATA[<excerpt in="" index="" |="" 首页摘要="">   

<p>当数据维度比较多，存储时间比较长时，数据量会增加到到T级别。如果historical节点只是单机版，查询会特别慢。在生产过程中，主要做了以下几点优化：</p>
<a id="more"></a>  
<the rest="" of="" contents="" |="" 余下全文=""> 

<h2 id="增加缓存"><a href="#增加缓存" class="headerlink" title="增加缓存"></a>增加缓存</h2><p>当集群机器较少时(官方文档推荐&lt;20台)，在broker节点配置缓存，可以适当增加缓存大小，或者从local替换成memcached。</p>
<p>当集群机器较多时，应当只配置historical节点缓存，减轻broker节点压力。</p>
<h3 id="附：broker部分配置"><a href="#附：broker部分配置" class="headerlink" title="附：broker部分配置"></a>附：broker部分配置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"># Query cache</div><div class="line">druid.broker.cache.useCache=true</div><div class="line">druid.broker.cache.populateCache=true</div><div class="line">druid.cache.type=local</div><div class="line">druid.cache.sizeInBytes=2000000000</div></pre></td></tr></table></figure>
<h2 id="historical节点集群化"><a href="#historical节点集群化" class="headerlink" title="historical节点集群化"></a>historical节点集群化</h2><p>查询为CPU密集型，通过合理的数据分配策略，使数据尽量分散在不同的历史节点。</p>
<h3 id="集群分片"><a href="#集群分片" class="headerlink" title="集群分片"></a>集群分片</h3><p>可以根据查询频率的高低分为冷热数据，公司经常查40天内的数据，40天内的数据显然是hot数据。 </p>
<p>这里涉及到coordinate节点的Load Rules配置，druid 0.9版本有coordinator的UI界面，可以设置每个dataSource的Load Rules。如下：</p>
<p><img src="http://note.youdao.com/yws/public/resource/32442f2d923ee4564e15f34e1a33fdd5/4090FB9D383B4F20A177A8245AF84E75" alt="image"></p>
<p>这里设置了两个Load Rules，loadByPeriod部分表示40天内的数据在hot和_default_tier分片各保存一份副本。loadForever部分表示所有数据在_default_tier保存一份。</p>
<h3 id="增加分片的节点数"><a href="#增加分片的节点数" class="headerlink" title="增加分片的节点数"></a>增加分片的节点数</h3><p>增加_default_tier和hot分片的节点数，并且节点存储空间尽量一致，使segment均匀分散在节点间，降低查询时每个historical节点的CPU负载。</p>
<p>例如：_default_tier分片增加到2-3台，hot分片增加到5-10台机器，热数据分散到更多台。 </p>
<h3 id="调整历史节点配置参数"><a href="#调整历史节点配置参数" class="headerlink" title="调整历史节点配置参数"></a>调整历史节点配置参数</h3><h4 id="druid-server-priority"><a href="#druid-server-priority" class="headerlink" title="druid.server.priority"></a>druid.server.priority</h4><p>默认为0。</p>
<p>broker节点中，druid.broker.select.tier的配置默认为highestPriority，表示如果有重复的数据样本，优先查询优先级高的历史节点。</p>
<p>例如：将hot分片的机器druid.server.priority设置为100，_default_tier分片的默认0，则查询热数据时，不会查询_default_tier，只会去查询hot，而hot集群机器比较多，查询速度快。</p>
<h4 id="druid-processing-numThreads"><a href="#druid-processing-numThreads" class="headerlink" title="druid.processing.numThreads"></a>druid.processing.numThreads</h4><p>可以根据自己机器的情况进行调节，如果机器只用于历史节点，可以设置为（核心数-1），32核机器可以设置为31，或者默认值就是31。</p>
<h4 id="druid-segmentCache-locations"><a href="#druid-segmentCache-locations" class="headerlink" title="druid.segmentCache.locations"></a>druid.segmentCache.locations</h4><p>可以将数据存储分散在不同的磁盘上，可以减轻磁盘的读写压力。</p>
<h4 id="附：history节点部分配置"><a href="#附：history节点部分配置" class="headerlink" title="附：history节点部分配置"></a>附：history节点部分配置</h4><p>hot集群中调优查询速度的相关配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">#集群分片，不写默认_default_tier</div><div class="line">druid.server.tier=hot  </div><div class="line">#查询优先级，不写默认0，_default_tier分片的两个节点为0，hot节点的都改为100。这样，热数据只会查hot节点的机器。</div><div class="line">druid.server.priority=100</div><div class="line"></div><div class="line">#processing.buff，可以注释掉，默认是1G</div><div class="line">#processing.numThreads:默认是繁忙时core-1做process，剩余的1个进程做与zk通信和拉取seg等。</div><div class="line">druid.processing.buffer.sizeBytes=1073741824</div><div class="line">druid.processing.numThreads=31</div><div class="line"></div><div class="line">#segment路径和各路径的空间，例如：在disk1、2、3各配了200G</div><div class="line">druid.segmentCache.locations=[&#123;&quot;path&quot;: &quot;/disk1/druid-0.9.1.1-historical-data/persistent&quot;, &quot;maxSize&quot;: 200000000000&#125;,&#123;&quot;path&quot;: &quot;/disk2/druid-0.9.1.1-historical-data/persistent&quot;, &quot;maxSize&quot;: 200000000000&#125;,&#123;&quot;path&quot;: &quot;/disk3/druid-0.9.1.1-historical-data/persistent&quot;, &quot;maxSize&quot;: 200000000000&#125;]</div><div class="line">#segment总空间（字节）=上述空间之和</div><div class="line">druid.server.maxSize=600000000000</div></pre></td></tr></table></figure></p>
<h2 id="老数据roll-up"><a href="#老数据roll-up" class="headerlink" title="老数据roll up"></a>老数据roll up</h2><p>进行实时和批量indexing的时候，一般配置的按小时的粒度进行roll up，最后存储的就是按小时聚合的数据。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">&quot;granularitySpec&quot;: &#123;</div><div class="line">    &quot;type&quot;: &quot;uniform&quot;,</div><div class="line">    &quot;segmentGranularity&quot;: &quot;HOUR&quot;,</div><div class="line">    &quot;queryGranularity&quot;: &quot;HOUR&quot;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>当数据积累较长时间后，按小时聚合必然数据量巨大，可以将不常用或者不太重要的数据，按天存储，数据量会大大减小，必然可以提高查询速度。</p>
<p>例如：将40天之后的数据提交batch indexing任务按天roll up。</p>
<h2 id="最后的效果"><a href="#最后的效果" class="headerlink" title="最后的效果"></a>最后的效果</h2><p>以7台机器为例，配置5台hot分片的机器，2台default分片的机器。hot分片存储的是以小时为粒度的数据，_default_tier分片存的是按天为粒度的数据。  </p>
<p><img src="http://note.youdao.com/yws/public/resource/32442f2d923ee4564e15f34e1a33fdd5/A6979D7951D74EB8BE6A02C27B5AE2EF" alt="image">    </p>
<p>40天之内的热数据根据之前配置的规则，会在hot分片存一份，_default_tier分片存一份<br><img src="http://note.youdao.com/yws/public/resource/32442f2d923ee4564e15f34e1a33fdd5/E4BCCAE548C8454A8922E80E5E6EB9CA" alt="image"></p>
<p>40天之前的数据只会在_default_tier分片存一份<br><img src="http://note.youdao.com/yws/public/resource/32442f2d923ee4564e15f34e1a33fdd5/655AB8A05A8A4067AB2EB57D4A0C453B" alt="image"></p>
<p>查询40天内的数据时，由于hot分片的机器优先级高。只会从hot分片的5台机器读取数据，40天之前的数据只会从default分片读取数据。  </p>
</the></excerpt>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[druid.io 3---druid数据]]></title>
      <url>https://fangyeqing.github.io/2016/10/29/druid.io_3---druid%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3/</url>
      <content type="html"><![CDATA[<excerpt in="" index="" |="" 首页摘要="">   

<h2 id="数据格式"><a href="#数据格式" class="headerlink" title="数据格式"></a>数据格式</h2><ul>
<li><strong>Timestamp列</strong>: 所有的查询都以时间为中心。  </li>
<li><strong>Dimension列（维度）</strong>: Dimensions对应事件的维度,通常用于筛选过滤数据。</li>
<li><strong>Metric列（度量）</strong>: Metrics是用于聚合和计算的列。通常是数字,并且支持count、sum、mean等聚合操作。<br>线上广告的例子：</li>
</ul>
<a id="more"></a>  
<the rest="" of="" contents="" |="" 余下全文=""> 

<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">timestamp             publisher          advertiser  gender  country  click  price</div><div class="line">2011-01-01T01:01:35Z  bieberfever.com    google.com  Male    USA      0      0.65</div><div class="line">2011-01-01T01:03:63Z  bieberfever.com    google.com  Male    USA      0      0.62</div><div class="line">2011-01-01T01:04:51Z  bieberfever.com    google.com  Male    USA      1      0.45</div><div class="line">2011-01-01T01:00:00Z  ultratrimfast.com  google.com  Female  UK       0      0.87</div><div class="line">2011-01-01T02:00:00Z  ultratrimfast.com  google.com  Female  UK       0      0.99</div><div class="line">2011-01-01T02:00:00Z  ultratrimfast.com  google.com  Female  UK       1      1.53</div></pre></td></tr></table></figure>
<p>dimensions: publisher, advertiser, gender, and country。<br>metrics: click和price</p>
<h2 id="预聚合roll-up"><a href="#预聚合roll-up" class="headerlink" title="预聚合roll up"></a>预聚合roll up</h2><p>Roll-up是在一系列维度选定后的数据之上做的初始聚合，一般发生在push/pull数据流阶段，通过realtime node或者tranquility+indexing service的方式。    </p>
<p>通过queryGranularity定义数据roll up的粒度。  </p>
<p>这种预聚合的方式可以很显著的减少数据的存储(可减少100倍)。 Druid也是通过这种方式来减少数据的存储。 这种减少存储的方式也会带来副作用,比如我们没有办法再查询到每条数据具体的明细。换句话说,数据聚合的粒度是我们能查询数据的最小粒度。  </p>
<p>例如定义粒度为HOUR<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">GROUP BY timestamp, publisher, advertiser, gender, country</div><div class="line">  :: impressions = COUNT(1),  clicks = SUM(click),  revenue = SUM(price)</div></pre></td></tr></table></figure></p>
<p>上述例子聚合之后为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">timestamp             publisher          advertiser  gender country impressions clicks revenue</div><div class="line">2011-01-01T01:00:00Z  ultratrimfast.com  google.com  Male   USA     1800        25     15.70</div><div class="line">2011-01-01T01:00:00Z  bieberfever.com    google.com  Male   USA     2912        42     29.18</div><div class="line">2011-01-01T02:00:00Z  ultratrimfast.com  google.com  Male   UK      1953        17     17.31</div><div class="line">2011-01-01T02:00:00Z  bieberfever.com    google.com  Male   UK      3194        170    34.01</div></pre></td></tr></table></figure></p>
<p>也可以将过久时间的历史数据进行自定义的roll up操作，例如近90天的数据按小时进行roll up预处理，然后将90天之后的数据提交batch indexing任务按天roll up。</p>
<h2 id="数据分片"><a href="#数据分片" class="headerlink" title="数据分片"></a>数据分片</h2><p>以segments(段)的形式就行分片,并且以时间作为第一级分片。  </p>
<p>Segments是自包含容器,包含着一个时间段内的数据，通过segmentGranularity定义segments的分片时间粒度。<br>Segments包括基于列的压缩,以及这些列的索引。Druid只需要清楚如何扫描这些segments就可以查询。</p>
<p>Segments通过datasource, interval, version, 和一个可选的partition number来区分。   </p>
<blockquote>
<p>dataSource_interval_version_partitionNumber。</p>
</blockquote>
<p>例如：<br>Segment sampleData_2011-01-01T01:00:00:00Z_2011-01-01T02:00:00:00Z_v1_0 包含<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">2011-01-01T01:00:00Z  ultratrimfast.com  google.com  Male   USA     1800        25     15.70</div><div class="line">2011-01-01T01:00:00Z  bieberfever.com    google.com  Male   USA     2912        42     29.18</div></pre></td></tr></table></figure></p>
<p>Segment sampleData_2011-01-01T02:00:00:00Z_2011-01-01T03:00:00:00Z_v1_0 包含<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">2011-01-01T02:00:00Z  ultratrimfast.com  google.com  Male   UK      1953        17     17.31</div><div class="line">2011-01-01T02:00:00Z  bieberfever.com    google.com  Male   UK      3194        170    34.01</div></pre></td></tr></table></figure></p>
<h2 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h2><p><strong>MVCC</strong>：多版本控制，以HDFS作为DeepStorage为例，HDFS上会保存每次修改的版本，history节点只load最新的数据，即用最新的版本来表示数据。</p>
<p>druid在0.9版本之后，HDFS上存储格式如下:</p>
<p><strong>hdfs://nn1:port/…/ sampleData / startTime_endTime / updateTime / shard / index.zip</strong><br><strong>hdfs://nn1:port/…/ sampleData / startTime_endTime / updateTime / shard / descriptor.json</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">startTime_endTime:看聚合粒度，可能是1个小时之内，可能是1天之内</div><div class="line">updateTime：修改时间，即版本号。取最新的一个版本</div><div class="line">shard:分片，数据比较多，一个分片放不下</div></pre></td></tr></table></figure></p>
<h3 id="HDFS存储举例"><a href="#HDFS存储举例" class="headerlink" title="HDFS存储举例"></a>HDFS存储举例</h3><p><strong>hdfs://nn1:port/…/sampleData/20160801T120000.000+0800_20160801T130000.000+0800/</strong><br>目录下有如下两个版本：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">2016-08-01T12_07_40.483+08_00/	rwxr-xr-x	root/supergroup	    2016-08-01 13:15:12</div><div class="line">2016-08-01T13_17_06.199+08_00/	rwxr-xr-x	root/supergroup	    2016-08-01 13:23:40</div></pre></td></tr></table></figure></p>
<p><strong>2016-08-01T13_17_06.199+08_00</strong>目录下有3个分片：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">0/	rwxr-xr-x	root/supergroup	2016-08-01 13:23:05</div><div class="line">1/	rwxr-xr-x	root/supergroup	2016-08-01 13:23:11</div><div class="line">2/	rwxr-xr-x	root/supergroup	2016-08-01 13:23:46</div></pre></td></tr></table></figure></p>
<p><strong>0/</strong>目录下有两个文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">descriptor.json	rw-r--r--	eadata/supergroup	766 B	128 mb	3	2016-08-01 13:23:05</div><div class="line">index.zip	rw-r--r--	eadata/supergroup	5.56 mb	128 mb	3	2016-08-01 13:23:04</div></pre></td></tr></table></figure></p>
<p>descriptor.json保存的信息：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">    &quot;dataSource&quot;: &quot;sampleData&quot;,//数据源</div><div class="line">    &quot;interval&quot;: &quot;2016-08-01T12:00:00.000+08:00/2016-08-01T13:00:00.000+08:00&quot;,//时间区间</div><div class="line">    &quot;version&quot;: &quot;2016-08-01T13:17:06.199+08:00&quot;,//版本号，即修改时间</div><div class="line">    &quot;loadSpec&quot;: &#123;//存储路径</div><div class="line">        &quot;type&quot;: &quot;hdfs&quot;,</div><div class="line">        &quot;path&quot;: &quot;hdfs://nn1:port/..../sampleData/20160801T120000.000+0800_20160801T130000.000+0800/2016-08-01T13_17_06.199+08_00/0/index.zip&quot;</div><div class="line">    &#125;,</div><div class="line">    &quot;dimensions&quot;: &quot;publisher,advertiser,gender,country&quot;,</div><div class="line">    &quot;metrics&quot;: &quot;click,price&quot;,</div><div class="line">    &quot;shardSpec&quot;: &#123;//分片信息</div><div class="line">        &quot;type&quot;: &quot;hashed&quot;,</div><div class="line">        &quot;partitionNum&quot;: 0,</div><div class="line">        &quot;partitions&quot;: 3,</div><div class="line">        &quot;partitionDimensions&quot;: []</div><div class="line">    &#125;,</div><div class="line">    &quot;binaryVersion&quot;: 9,</div><div class="line">    &quot;size&quot;: 8959843,//index.zip解压后的大小</div><div class="line">    &quot;identifier&quot;: &quot;sampleData_2016-08-01T12:00:00.000+08:00_2016-08-01T13:00:00.000+08:00_2016-08-01T13:17:06.199+08:00&quot;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>当historical节点加载HDFS中的segment到本地存储时，会解压index.zip，解压出00000.smoosh、meta.smoosh、version.bin三个文件。保存在本地路径:</p>
<blockquote>
<p>druid.segmentCache.locations / sampleData / startTime_endTime / updateTime / shard   </p>
</blockquote>
<p>descriptor.json保存在本地路径：</p>
<blockquote>
<p>druid.segmentCache.locations / info_dir / sampleData / startTime_endTime / updateTime / shard</p>
</blockquote>
<p>druid.segmentCache.locations在historical节点配置中配置。</p>
<p><del>druid在0.9版本之前，realtime index放在上述路径中，batch（批量）任务会放在：<br>datasource / datasource / startTime_endTime / updateTime /shard / index.zip</del></p>
<h2 id="数据索引"><a href="#数据索引" class="headerlink" title="数据索引"></a>数据索引</h2><p>Druid是列式存储,每一个列都是单独存储,在查询的过程中只扫描查询所需的列即可。不同的列可以采用不同的压缩方式,也可以关联不同的索引。  </p>
<p>Druid的索引是基于每一个分片(即segment)上的。</p>
<h2 id="数据加载"><a href="#数据加载" class="headerlink" title="数据加载"></a>数据加载</h2><p>Druid使用的通常情况是,联合使用批量和实时数据流的加载方法。近期的数据通过实时方式处理,离线批量处理来来提高精度。 </p>
<p>在一些网络抖动延迟的非正常场景中，实时数据流加载方式有可能出现消息丢失或者消息重复，因此批量再加载方式消除了这种历史数据的潜在错误。或者由于某种原因，需要修改数据，批量再加载方式也提供给你再加载数据的选项。</p>
<h3 id="实时方式"><a href="#实时方式" class="headerlink" title="实时方式"></a>实时方式</h3><ul>
<li>Stream push <ul>
<li><strong>Tranquility+indexing service</strong>，数据来自于一个数据流系统，如Kafka、Storm、Spark Streaming。Tranquility：一个发送数据流到Druid的http客户端。</li>
</ul>
</li>
<li>Stream pull <ul>
<li><strong>Realtime Node</strong>，直接从外部数据源拉数据流进入Druid。  <h3 id="离线批处理方式"><a href="#离线批处理方式" class="headerlink" title="离线批处理方式"></a>离线批处理方式</h3></li>
</ul>
</li>
<li>Files <ul>
<li><strong>Batch Data Ingestion+indexing service</strong>，从HDFS、S3、本地文件、或者其他支持批处理的Hadoop文件系统加载数据。例如：利用camus从kafka拉取数据到hdfs，再提交HDFS上新拉取的数据到overlord进行batch indexing。  </li>
</ul>
</li>
</ul>
<p>下图中，上面的indexing service为realtime，下面的为Batch Data Ingestion<br><img src="http://note.youdao.com/yws/public/resource/32442f2d923ee4564e15f34e1a33fdd5/D6B38A53DFD740328C51FD6093A90BE7" alt="image"></p>
<h2 id="数据查询"><a href="#数据查询" class="headerlink" title="数据查询"></a>数据查询</h2><p>Druid原生的查询方式是通过http发送json,但是社区已经贡献出多种查询库,包括SQL方式的plyql。</p>
<p>Druid被设计为执行单表操作,不支持join操纵(实际上可以做join)。 生产环境需要在ETL阶段进行join,因为数据在加载进Druid之前必须规范化。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://druid.io/docs/0.9.1.1/design/index.html" target="_blank" rel="external">druid.io</a><br><a href="http://druidio.cn/docs/0.9.0/design/" target="_blank" rel="external">druidio.cn</a><br><a href="http://lxw1234.com/archives/2015/11/563.htm" target="_blank" rel="external">lxw的大数据田地–Druid.io实时OLAP数据分析存储系统介绍</a><br><a href="http://dj1211.com/?p=702" target="_blank" rel="external">萌の宇博客–realtime node与index server区别</a><br><a href="http://zqhxuyuan.github.io/2015/12/03/2015-12-03-Druid-Design/#Concepts" target="_blank" rel="external">zqhxuyuan博客–Druid OLAP架构设计</a></p>
</the></excerpt>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[druid.io 2---druid介绍]]></title>
      <url>https://fangyeqing.github.io/2016/10/29/druid.io_2---druid%E4%BB%8B%E7%BB%8D/</url>
      <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要="">   </excerpt></p>
<h2 id="Druid概念"><a href="#Druid概念" class="headerlink" title="Druid概念"></a>Druid概念</h2><p><a href="http://druid.io/" target="_blank" rel="external">Druid.io</a> 是一个开源的，分布式的，<a href="https://fangyeqing.github.io/2016/10/29/druid.io_1---%E5%88%97%E5%BC%8F%E5%AD%98%E5%82%A8%E6%A6%82%E5%BF%B5/">列式存储</a>的，适用于实时数据分析的<a href="https://fangyeqing.github.io/2016/10/29/druid.io_0---OLAP%E6%A6%82%E5%BF%B5/">OLAP</a>系统，能够快速聚合、灵活过滤、毫秒级查询、和低延迟数据导入。</p>
<a id="more"></a>  
<p><the rest="" of="" contents="" |="" 余下全文=""><br>优势：</the></p>
<ul>
<li>高容错性：单个节点挂掉不会影响其他部分。详情在<a href="#容错性">文末</a>有介绍。 </li>
<li>多版本控制（MVCC）：通过数据更新时间来区分版本，历史节点只加载最新版本数据。支持实时数据indexing与批量数据indexing同时进行，实时数据索引满足实时需求，批量数据覆盖实时数据满足准确性需求。详情见<a href="https://fangyeqing.github.io/2016/10/29/druid.io_3---druid%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3/#数据加载">druid数据加载</a>。</li>
<li>高聚合性：数据roll up预处理，减少存储数据量。详情见<a href="https://fangyeqing.github.io/2016/10/29/druid.io_3---druid%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3/#预聚合roll-up">druid预聚合roll-up</a>。</li>
<li>高压缩度：使用Bitmap indexing加速列存储的查询速度，并使用CONCISE算法来对bitmap indexing进行压缩，使得生成的segments比原始文本文件小很多  </li>
</ul>
<h2 id="集群组成"><a href="#集群组成" class="headerlink" title="集群组成"></a>集群组成</h2><p>Druid集群包含不同类型的节点，而每种节点都被设计来做好某组事情。这样的设计可以隔离关注并简化整个系统的复杂度。不同节点的运转几乎都是独立的并且和其他的节点有着最小化的交互，因此集群内的通信故障对于数据可用性的影响非常小。</p>
<p>主要分为四大部分：数据生产、数据存储、数据查询、外部依赖。本小节先做一个简单的介绍，后面每个部分会有详细介绍。</p>
<p><img src="http://druidio.cn/docs/img/druid-dataflow-3.png" alt="image"></p>
<h3 id="数据生产"><a href="#数据生产" class="headerlink" title="数据生产"></a>数据生产</h3><ul>
<li>Indexing Service 索引服务节点：<br>由多个worker组成的集群，负责为加载批量的和实时的数据创建索引，并且允许对已经存在的数据进行修改。</li>
<li>Realtime 实时节点：<br>负责加载实时的数据到系统中，在生产使用的几个限制成本上实时节点比索引服务节点更容易搭建。</li>
</ul>
<p>实时数据和批量数据加载的两种方式在上一篇druid数据相关中介绍到了，就不赘述。</p>
<h3 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h3><ul>
<li>Coordinator 协调节点：<br>对历史节点的分组进行监控，以确保数据可用，和最佳的配置。协调节点通过从元数据存储中读取元数据信息来判断哪些segments是应该加载到集群的，使用Zookeeper去判断哪些历史节点是存活的，在Zookeeper中创建任务条目告诉历史节点去加载和删除segments。</li>
<li>Historical 历史节点：<br>负责处理历史数据存储和查询历史数据（非实时），历史节点从“deep storage”下载segments，将结果数据返回给broker节点，historical加载完segment通知Zookeeper，Historical nodes使用Zookeeper监控需要加载或者删除哪些新的segments。</li>
</ul>
<h3 id="数据查询"><a href="#数据查询" class="headerlink" title="数据查询"></a>数据查询</h3><ul>
<li>Broker 代理节点<br>接收来自外部client的查询请求，并转发这些请求给实时节点和历史节点，当代理节点接收到结果时，将来自实时节点和历史节点的结果合并返回给调用方。为了知道整个拓扑结构，代理节点通过使用Zookeeper在确定哪些实时节点和历史节点存活。</li>
</ul>
<h3 id="外部依赖"><a href="#外部依赖" class="headerlink" title="外部依赖"></a>外部依赖</h3><p>Druid的集群需要有一些外部依赖。  </p>
<ul>
<li>Zookeeper</li>
<li>Metadata Storage</li>
<li>Deep Storage</li>
</ul>
<h2 id="Indexing-Service"><a href="#Indexing-Service" class="headerlink" title="Indexing Service"></a>Indexing Service</h2><p>索引服务负责<strong>实时</strong>和<strong>批量</strong>数据的导入、分析、索引、压缩，生成“segment”（数据段），存入Deep Storage（例如HDFS）。<br>实时数据通过<strong>Tranquility</strong>客户端，批量数据通过<strong>Batch Data Ingestion</strong>，将任务提交给overload，分配给Middle Manager创建Poen执行。  </p>
<h3 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h3><p>索引服务是主从结构，由三个部分组成：</p>
<ul>
<li>peon组件：在一个单独的jvm中运行单个任务，通过单独的jvm对任务做资源隔离和日志隔离。  </li>
<li>Middle Manager：用于创建和管理peon的中层管理组件  </li>
<li>overlord组件：管理任务分配到Middle Manager<br><img src="http://note.youdao.com/yws/public/resource/32442f2d923ee4564e15f34e1a33fdd5/8A3B9817DCAE4598A5D8582FB02E012E" alt="image"><br>综合Tranquility和整个系统之后：<br><img src="http://note.youdao.com/yws/public/resource/32442f2d923ee4564e15f34e1a33fdd5/26967A72BB75437786E663C1A91699D8" alt="image"> </li>
</ul>
<h3 id="流程："><a href="#流程：" class="headerlink" title="流程："></a>流程：</h3><ul>
<li>用户的spec文件在Tranquility中定义，首先Tranquility通过spec初始化，获得zk中Overlord的地址，与Overlord通信。</li>
<li>Overlord得到新写入任务后，查询zk节点信息，选择一个Middle Manager节点启动来启动peon，并将信息写入到zk中。</li>
<li>Middle Manager一直监控zk，发现有新的任务分配后，启动一个Peon进程，并监控Peon进程的状态。</li>
<li>Peon与Realtime Node流程基本一致，所不同的是Peon使用的是HTTP接口来接收数据，RealTime Node更多的是内部的线程不断的拉取Kafka的数据。</li>
<li>Tranquility随后通过zk获取Peon机器地址和端口，将数据不断的发送到Peon中。</li>
<li>Peon根据spec规则，定时或者定量将数据build index，handoff到deep storage(HDFS)中。</li>
<li>Coordinator根据Peon在zk中信息，将元数据写入到mysql中，并分配Historical Node去deep storage拉取index数据。</li>
<li>Historical Node到deep storage拉取index数据到本地，重建index到内存中，至此数据流入完成。</li>
</ul>
<h3 id="配置说明"><a href="#配置说明" class="headerlink" title="配置说明"></a>配置说明</h3><p>overload节点配置时<br>druid.indexer.runner.type=local表示overload以本地模式运行，overload同时负责Middle Manager的作用，创建poen和分配任务。local模式下，overload配置需要对poen进行配置。</p>
<h2 id="real-time-node"><a href="#real-time-node" class="headerlink" title="real-time node"></a>real-time node</h2><p>实时节点是进行存储和查询实时数据的工作区。在Zookeeper中通告它们的在线状态和为哪些数据提供服务。</p>
<p>存储：metadata(元数据)写入MySQL，在ZooKeeper中新增一条记录<br>    Segment定期会转存到DeepStorage<br>查询：提供实时查询索引，响应broker的查询   </p>
<p>下图中的master即为coordinator：<br><img src="http://note.youdao.com/yws/public/resource/32442f2d923ee4564e15f34e1a33fdd5/5D9BEA80D1E642C88D707A330CC9D618" alt="image"><br>具体存储过程：</p>
<ul>
<li>实时节点缓存事件数据到内存中的索引上，然后有规律的持久化到磁盘上。在转移之前，持久化的索引会周期性地合并在一起。（查询会同时命中内存中的和已持久化的索引。）  </li>
<li>实时节点周期性的启动后台的计划任务搜索本地的持久化索引，后台计划任务将这些持久化的索引合并到一起并生成一块不可变的数据，这些数据块包含了  </li>
<li>一段时间内的所有已经由实时节点导入的事件数据，称这些数据块为”Segment”。  </li>
<li>在传送阶段，实时节点将这些segment上传到一个永久持久化的备份存储中,即Deep Storage  </li>
</ul>
<h3 id="realtime-node与indexing-service导入数据的区别"><a href="#realtime-node与indexing-service导入数据的区别" class="headerlink" title="realtime node与indexing service导入数据的区别"></a>realtime node与indexing service导入数据的区别</h3><table>
<thead>
<tr>
<th>比较项</th>
<th>RealTime Node</th>
<th>Realtime Indexing Service</th>
</tr>
</thead>
<tbody>
<tr>
<td>角色</td>
<td>RealTime Node</td>
<td>Overloard Nodes，Middle Manager Nodes，Poens</td>
</tr>
<tr>
<td>部署方式</td>
<td>多台服务器或单台服务器上多个RTN，每个RTN指定不同的spec文件启动</td>
<td>仅部署Overloard Nodes和Middle Manager。Middle Manager创建poen去接收不同的realtime日志，不需要指定spec文件，由Tranquility客户端提供</td>
</tr>
<tr>
<td>使用方式</td>
<td>RTN通过spec文件指定消费的Kafka topic，不断的pull</td>
<td>Poen接收Tranquility客户端push过来的数据</td>
</tr>
<tr>
<td>可扩展性与易用性</td>
<td>通过加机器，启动更多的RealTime Nodes进行扩展，但是需要管理所有的RTN的spec文件，消费的各种属性信息，运维复杂</td>
<td>通过加机器，启动更多的Middle Managers来进行扩展，所有的日志消费属性信息都是通过Tranquility自己指定，运维简单</td>
</tr>
</tbody>
</table>
<p>随着Druid业务增多，规模扩大，对Realtime Node的管理变成了非常繁琐的事情，使用Realtime Index Service是必须的</p>
<h2 id="Coordinator-Node"><a href="#Coordinator-Node" class="headerlink" title="Coordinator Node"></a>Coordinator Node</h2><p>协调节点可以认为是Druid中的master，通过Zookeeper管理历史节的segment放置策略，且通过Mysql中的metadata管理数据段。主要作用：</p>
<ul>
<li>通过从元数据存储（MySQL）读取数据段的元数据信息，来决定哪些Segments应该在集群中被加载。</li>
<li>使用ZK来确定哪个Historical节点存在</li>
<li>创建ZK条目告诉Historical节点管理Segments：加载新的Segments,删除旧的Segments,或者移动Segments进行负载均衡。  </li>
</ul>
<h3 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h3><p>协调节点每次运行时，</p>
<p>计算每一个historical tier（节点层）利用率最高的和最低的差异值。  </p>
<p>如果差异超过某个阈值,部分segment将从最高的节点迁移到最低的节点，并且移动的segment是随机选择的。</p>
<p>每次协调节点运行时，能够迁移的segment的数量是可配置的。</p>
<h4 id="例子："><a href="#例子：" class="headerlink" title="例子："></a>例子：</h4><p>在实际生产过程中，hot节点层本身只有两台机器，增加hot层到5台。负载最高的机器数据会往低的迁移。到最后每台机器上的数据大致相等。</p>
<h2 id="Historical-Node"><a href="#Historical-Node" class="headerlink" title="Historical Node"></a>Historical Node</h2><p>历史节点负责加载历史Segment并且提供针对这些历史Segment的查询。Historical Nodes可分为多个tier， 比如热数据放在一个tier， 冷数据放到另外一个tier，以达到冷热数据分开处理的目的。</p>
<h3 id="Historical节点segment创建流程"><a href="#Historical节点segment创建流程" class="headerlink" title="Historical节点segment创建流程"></a>Historical节点segment创建流程</h3><ul>
<li>Coordinator在ZK下与Historical节点相关联的加载队列路径下创建一个临时记录。</li>
<li>每个历史节点与ZK保持一个长连接监测ZK。</li>
<li>当一个历史节点发现在Zookeeper中与它关联的加载队列目录下有一个新的加载记录时。</li>
<li>它首先检查本地磁盘目录（缓存）中关于新的Segment的信息。如果缓存中没有关于新的Segment的信息，历史节点将下载新的Segment的元数据信息并告知Zookeeper。元数据包含新的Segment在“Deep Storage”中的存储位置，怎样去解压缩和处理新的Segment的信息。</li>
<li>一旦一个历史节点处理完成一个Segment，该Segment在Zoookeeper与该节点关联的服务Segments路径中公布可以提供服务。</li>
<li>此刻，这个Segment可以用于查询。</li>
</ul>
<h2 id="Broker-Node"><a href="#Broker-Node" class="headerlink" title="Broker Node"></a>Broker Node</h2><p>broker（代理）提供针对segment的路由查询，代理节点从Zookeeper获取Segments存储在哪些节点和怎样找到正确的节点的元数据。将查询转发到Realtime和Historical节点。把来自于所有单个节点的结果合并在一起。  </p>
<h3 id="转发查询"><a href="#转发查询" class="headerlink" title="转发查询"></a>转发查询</h3><p>Zookeeper维护有关历史和实时的节点信息和他们所能提供服务的Segment。  </p>
<p>在Zookeeper的每一个数据源，代理节点建立相关Segments的时间轴和为这些Segments提供服务的节点。</p>
<p>当收到一个特定数据源和时间间隔的查询请求，代理节点执行查找与查询数据源时间间隔相关的时间轴和检索包含数据查询的节点。代理节点然后将查询转发到所选节点。</p>
<h3 id="缓存策略"><a href="#缓存策略" class="headerlink" title="缓存策略"></a>缓存策略</h3><p>Broker节点包含一个支持LRU失效策略的缓存。</p>
<ul>
<li>首先将这个查询映射到一组Segments，这些Segment结果的子集可能在缓存中已经存在，在缓存中已经存在的结果可以被直接拉取。  </li>
<li>对于一些缓存中不存在的结果。代理节点会转发查询到历史节点。一旦历史节点返回其结果，代理节点将结果存储到缓存中。  </li>
<li>实时节点返回的结果将永远不会被缓存，因此实时节点的查询请求将永远被转发到实时节点。实时节点的数据是不断变化的，缓存实时节点的结果是不可靠的。</li>
</ul>
<h2 id="外部依赖-1"><a href="#外部依赖-1" class="headerlink" title="外部依赖"></a>外部依赖</h2><p><img src="http://note.youdao.com/yws/public/resource/32442f2d923ee4564e15f34e1a33fdd5/0E59F34342744B8ABBDCE92DA750B186" alt="image"></p>
<h3 id="Metadata-Storage（Mysql）"><a href="#Metadata-Storage（Mysql）" class="headerlink" title="Metadata Storage（Mysql）"></a>Metadata Storage（Mysql）</h3><p>存储segments的元数据和配置，而不是存储实际数据，包含3张表：<br>“druid_config”（通常是空的）,<br>“druid_rules”（协作节点使用的一些规则信息，比如哪个segment从哪个node去load）<br>“druid_segments”（存储 每个segment的metadata信息） </p>
<h3 id="Deep-storage"><a href="#Deep-storage" class="headerlink" title="Deep storage"></a>Deep storage</h3><p>segments的永久备份，Druid目前已经支持本地磁盘、NFS挂载磁盘、HDFS、S3等。<br>创建segments的服务上传segments到Deep storage,然后historical节点下载。  </p>
<h3 id="ZooKeeper"><a href="#ZooKeeper" class="headerlink" title="ZooKeeper"></a>ZooKeeper</h3><p>管理当前集群状态, 发现和维持当前的数据拓扑。（节点状态、数据操作、数据同步） </p>
<ul>
<li>realtime-node和historical-node在Zookeeper中通告它们的在线状态和为哪些数据提供服务。 </li>
<li>管理当前cluster的状态，比如记录哪些segments从实时节点移到了历史节点  </li>
</ul>
<p>主要发生：</p>
<ul>
<li>协调节点的leader选举</li>
<li>历史和实时节点发布segment协议</li>
<li>协调节点和历史节点之间的segment Load/Drop协议</li>
<li>overlord的leader选举</li>
<li>索引服务任务管理</li>
</ul>
<h2 id="数据流过程"><a href="#数据流过程" class="headerlink" title="数据流过程"></a>数据流过程</h2><p><img src="http://note.youdao.com/yws/public/resource/32442f2d923ee4564e15f34e1a33fdd5/69D6BCF5B4A3476898CF5599ED461232" alt="image">  </p>
<ol>
<li>实时数据写入到实时节点,会创建索引结构的Segment  </li>
<li>实时节点的Segment经过一段时间会转存到DeepStorage  </li>
<li>元数据写入MySQL; 实时节点转存的Segment会在ZooKeeper中新增一条记录  </li>
<li>协调节点从MySQL获取元数据,比如schema信息(维度列和指标列)  </li>
<li>协调节点监测ZK中有新分配/要删除的Segment,写入ZooKeeper信息:历史节点需要加载/删除Segment  </li>
<li>历史节点监测ZK, 从ZooKeeper中得到要执行任务的Segment  </li>
<li>历史节点从DeepStorage下载Segment并加载到内存/或者将已经保存的Segment删除掉  </li>
<li>历史节点的Segment可以用于Broker的查询路由  </li>
</ol>
<h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><p>上述流程中的实时节点，换成indexing service，流程基本一致。</p>
<h2 id="容错性"><a href="#容错性" class="headerlink" title="容错性"></a>容错性</h2><h3 id="历史节点挂掉"><a href="#历史节点挂掉" class="headerlink" title="历史节点挂掉"></a>历史节点挂掉</h3><p>该节点就不会服务这个节点上的Segments。<br>但是只要这些Segments仍然存在于DeepStorage,其他节点就会下载它们并服务这些Segments。   </p>
<p>可以从集群中移除所有的历史节点,并且重新发布它们,也不会有任何的数据损失(因为数据最终都保存到DeepStorage中)</p>
<h3 id="DeepStorage不可用"><a href="#DeepStorage不可用" class="headerlink" title="DeepStorage不可用"></a>DeepStorage不可用</h3><p>历史节点上已经加载了DeepStorage的Segments,仍然可用于查询。<br>但是新进来的数据无法进入到集群中(DS挂掉)。</p>
<h3 id="协调节点挂掉"><a href="#协调节点挂掉" class="headerlink" title="协调节点挂掉"></a>协调节点挂掉</h3><p>数据的拓扑(data topology)停止服务,就不会有新的数据以及数据的负载均衡。因为协调节点会通知历史节点下载新数据。   </p>
<p>如果实时节点将Segment转存到DeepStorage,而没有历史节点去下载这些数据,会导致实时节点最终会丢弃这份过期的数据。</p>
<h3 id="Broker挂掉"><a href="#Broker挂掉" class="headerlink" title="Broker挂掉"></a>Broker挂掉</h3><p>还会有其他的Broker接管请求,但是要至少保证有多余的Broker。<br>当然如果不向Broker发送请求,而只关心最新的实时数据,可以直接访问实时节点. 不过这种情况是很少见的.</p>
<h3 id="实时节点"><a href="#实时节点" class="headerlink" title="实时节点"></a>实时节点</h3><p>根据发送流的语义,可以有多个实时节点或者tranquility同时运行,处理同一个输入流,每个实时节点分担输入流的一部分数据.</p>
<h3 id="元数据存储挂掉"><a href="#元数据存储挂掉" class="headerlink" title="元数据存储挂掉"></a>元数据存储挂掉</h3><p>协调节点就无法找到集群中新的Segments(因为新的Segment一定会写入记录到元数据存储中)。但仍然可以提供当前集群的数据视图.</p>
<h3 id="ZooKeeper挂掉"><a href="#ZooKeeper挂掉" class="headerlink" title="ZooKeeper挂掉"></a>ZooKeeper挂掉</h3><p>数据拓扑不会被更新(同协调节点挂掉),但是Broker仍然可以维护最近的数据拓扑,并继续提供查询的服务。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://druid.io/docs/0.9.1.1/design/index.html" target="_blank" rel="external">druid.io</a><br><a href="http://druidio.cn/docs/0.9.0/design/" target="_blank" rel="external">druidio.cn</a><br><a href="http://lxw1234.com/archives/2015/11/563.htm" target="_blank" rel="external">lxw的大数据田地–Druid.io实时OLAP数据分析存储系统介绍</a><br><a href="http://dj1211.com/?p=702" target="_blank" rel="external">萌の宇博客–realtime node与index server区别</a><br><a href="http://zqhxuyuan.github.io/2015/12/03/2015-12-03-Druid-Design/#Concepts" target="_blank" rel="external">zqhxuyuan博客–Druid OLAP架构设计</a></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[druid.io 1---列式存储概念]]></title>
      <url>https://fangyeqing.github.io/2016/10/29/druid.io_1---%E5%88%97%E5%BC%8F%E5%AD%98%E5%82%A8%E6%A6%82%E5%BF%B5/</url>
      <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要="">  </excerpt></p>
<h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><ul>
<li>OLTP类型的查询访问的行数比较少，但往往需要大部分的数据列。传统的行式数据库将一个个完整的数据行存储在数据页中。这种方式在磁盘IO上是比较高效的。</li>
<li>OLAP类型的查询可能需要访问几百万甚至几十亿个数据行，数据量大需要进行压缩，且往往只关心少数几个数据列。这种情况下就需要列式存储。列式存储每一列单独存储，并且同一列里面的数据类型基本是相同，天生适合压缩。</li>
</ul>
<a id="more"></a>  
<the rest="" of="" contents="" |="" 余下全文=""> 

<p>当然，列式数据库不是万能的，每次读取某个数据行时，需要分别从不同的地方读取各个数据列的值，然后合并在一起形成数据行。因此，如果每次查询涉及的数据量较小或者大部分查询都需要整行的数据，列式数据库并不适用。</p>
<h2 id="列式存储vs行式存储"><a href="#列式存储vs行式存储" class="headerlink" title="列式存储vs行式存储"></a>列式存储vs行式存储</h2><p>简单来说两者的区别就是如何组织表，具体区别如下：</p>
<table>
<thead>
<tr>
<th>对比项</th>
<th>行式存储</th>
<th>列式存储</th>
</tr>
</thead>
<tbody>
<tr>
<td>存储</td>
<td>每一行数据作为一个整体来存储</td>
<td>每一列数据作为一个整体来存储</td>
</tr>
<tr>
<td>存储顺序</td>
<td>把一行中的数据值串在一起存储起来，然后再存储下一行的数据</td>
<td>把一列中的数据值串在一起存储起来，每列存储的位置分开</td>
</tr>
<tr>
<td>插入/更新</td>
<td>只需对一行进行操作，相对容易</td>
<td>需要对多个列进行操作，相对麻烦</td>
</tr>
<tr>
<td>索引</td>
<td>对个别列建立索引</td>
<td>任何列都能作为索引</td>
</tr>
<tr>
<td>查询</td>
<td>选择(Select)即使只涉及某几列，所有数据会被读取,存在冗余列</td>
<td>查询时只有涉及到的列会被读取，被选择的列要重新组装</td>
</tr>
<tr>
<td>查询适合场景</td>
<td>随机查询</td>
<td>范围查询（聚合）</td>
</tr>
<tr>
<td>应用</td>
<td>OLTP</td>
<td>OLAP</td>
</tr>
</tbody>
</table>
<p>从下图可以很清楚地看到，行式存储下一张表的数据都是放在一起顺序保存的，但列式存储下都被分开保存了。</p>
<p><img src="http://note.youdao.com/yws/public/resource/32442f2d923ee4564e15f34e1a33fdd5/0F29469CDE7443F8BD895003AA92432D" alt="image">  </p>
<h2 id="数据压缩"><a href="#数据压缩" class="headerlink" title="数据压缩"></a>数据压缩</h2><p>列式存储天生就是适合压缩，因为同一列里面的数据类型基本是相同。经过字典表进行数据压缩后，表中的字符串才都变成数字了。正因为每个字符串在字典表里只出现一次了，所以达到了压缩的目的。  </p>
<p><img src="http://note.youdao.com/yws/public/resource/32442f2d923ee4564e15f34e1a33fdd5/881EB576D1864CBAB00F56BB36B62F03" alt="image"></p>
<h2 id="查询性能"><a href="#查询性能" class="headerlink" title="查询性能"></a>查询性能</h2><p>通过一条查询的执行过程说明列式存储(以及数据压缩)的优点，下图为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">select * from table where Customer Name = &apos;Miller&apos; and Materiral = &apos;Refrigerator&apos;</div></pre></td></tr></table></figure></p>
<p><img src="http://note.youdao.com/yws/public/resource/32442f2d923ee4564e15f34e1a33fdd5/B2562E40B5A045BFB18DCD1DF911A803" alt="image"></p>
<p>关键步骤如下：</p>
<ul>
<li>去字典表里找到字符串对应数字(只进行一次字符串比较)。</li>
<li>用数字去列表里匹配，匹配上的位置设为1。</li>
<li>把不同列的匹配结果进行位运算得到符合所有条件的记录下标。</li>
<li>使用这个下标组装出最终的结果集。</li>
</ul>
<h2 id="索引优化"><a href="#索引优化" class="headerlink" title="索引优化"></a>索引优化</h2><p>可以针对列式存储做专门的索引优化。比如，性别列只有两个值，“男”和“女”，可以对这一列建立位图索引：</p>
<p><img src="http://note.youdao.com/yws/public/resource/32442f2d923ee4564e15f34e1a33fdd5/AAAF33C2767A45C9A8C89FDA35D578F2" alt="image"></p>
<p>“男”对应的位图为100101，表示第1、4、6行值为“男”；“女”对应的位图为011010，表示第2、3、5行值为“女”。如果需要查找男性或者女性的个数，只需要统计相应的位图中1出现的次数即可。另外，建立位图索引后0和1的重复度高，可以采用专门的编码方式对其进行压缩。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://blog.csdn.net/dc_726/article/details/41143175" target="_blank" rel="external">http://blog.csdn.net/dc_726/article/details/41143175</a><br><a href="http://chattool.sinaapp.com/?p=1234" target="_blank" rel="external">http://chattool.sinaapp.com/?p=1234</a></p>
</the>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[druid.io 0---OLAP概念]]></title>
      <url>https://fangyeqing.github.io/2016/10/29/druid.io_0---OLAP%E6%A6%82%E5%BF%B5/</url>
      <content type="html"><![CDATA[<excerpt in="" index="" |="" 首页摘要="">   

<h2 id="OLAP"><a href="#OLAP" class="headerlink" title="OLAP"></a>OLAP</h2><ul>
<li>OLAP的主要特点是直接仿照用户的多角度思考模式，预先为用户组建多维的数据模型。</li>
<li>维指的是用户的分析角度，例如对销售数据的分析，时间周期是一个维度，产品类别、分销渠道、地理分布、客户群类也分别是不同的维度。  </li>
<li>一旦多维数据模型建立完成，用户可以快速地从各个分析角度获取数据，也能动态地在各个角度之间切换数据或者进行多角度综合分析，具有极大的分析灵活性。</li>
</ul>
<a id="more"></a>  
<the rest="" of="" contents="" |="" 余下全文=""> 

<h3 id="主要名词"><a href="#主要名词" class="headerlink" title="主要名词"></a>主要名词</h3><ul>
<li>维(Dimension)：是用户观察数据的特定角度，是问题的一类属性，属性集合构成一个维(时间维、地理维等)。</li>
<li>维的层次(Level)：用户观察数据的某个特定角度(即某个维)还可能存在细节程度不同的各个描述方面(时间维包括日期、月份、季度、年)。  </li>
<li>维的成员(Member)：即维的一个取值，是数据项在某个维中位置的描述，如“某年某月某日”是在时间维上的位置描述。  </li>
<li>度量(Measure)：多维数组的取值。  </li>
</ul>
<h3 id="多维分析操作"><a href="#多维分析操作" class="headerlink" title="多维分析操作"></a>多维分析操作</h3><ul>
<li>钻取（Drill-up和Drill-down）：改变维的层次，变换分析的粒度。它包括向下钻取(Drill-down)和向上钻取(Drill-up)/上滚(Roll-up)。向上钻取是在某一维上将低层次的细节数据概括到高层次的汇总数据，或者减少维数;而向下钻取则相反，从汇总数据深入到细节数据进行观察或增加新维。  </li>
<li>切片和切块（Slice&amp;Dice）：在一部分维上选定值后，关心度量数据在剩余维上的分布。如果剩余的维只有两个，则是切片;如果有三个或以上，则是切块。  </li>
<li>旋转（Pivot）：变换维的方向，即在表格中重新安排维的放置(如行列互换)。</li>
</ul>
<h3 id="与OLTP区别"><a href="#与OLTP区别" class="headerlink" title="与OLTP区别"></a>与OLTP区别</h3><ul>
<li>联机事务处理OLTP（on-line transaction processing）：<br>传统的关系型数据库的主要应用，主要是基本的、日常的事务处理，例如银行交易。  </li>
<li>联机分析处理OLAP（On-Line Analytical Processing）：<br>数据仓库系统的主要应用，支持复杂的分析操作，侧重决策支持，并且提供直观易懂的查询结果。   </li>
</ul>
<table>
<thead>
<tr>
<th>比较</th>
<th>OLTP</th>
<th>OLAP</th>
</tr>
</thead>
<tbody>
<tr>
<td>用户</td>
<td>操作人员,低层管理人员</td>
<td>决策人员,高级管理人员</td>
</tr>
<tr>
<td>功能</td>
<td>日常操作处理</td>
<td>分析决策</td>
</tr>
<tr>
<td>DB设计</td>
<td>面向应用</td>
<td>面向主题</td>
</tr>
<tr>
<td>数据</td>
<td>当前的, 最新的细节的,二维的分立的</td>
<td>历史的, 聚集的, 多维的集成的, 统一的</td>
</tr>
<tr>
<td>存</td>
<td>简单快速的insert和update</td>
<td>定期批量任务更新</td>
</tr>
<tr>
<td>取</td>
<td>简单的读取少量结果</td>
<td>读取大量结果并做聚合操作</td>
</tr>
<tr>
<td>工作单位</td>
<td>简单的事务</td>
<td>复杂的查询</td>
</tr>
<tr>
<td>用户数</td>
<td>上千个</td>
<td>上百个</td>
</tr>
<tr>
<td>DB 大小</td>
<td>100MB-GB</td>
<td>100GB-TB</td>
</tr>
<tr>
<td>主要应用</td>
<td>数据库</td>
<td>数据仓库</td>
</tr>
</tbody>
</table>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://datawarehouse4u.info/OLTP-vs-OLAP.html" target="_blank" rel="external">http://datawarehouse4u.info/OLTP-vs-OLAP.html</a><br><a href="http://www.voidcn.com/blog/nisjlvhudy/article/p-3330989.html" target="_blank" rel="external">http://www.voidcn.com/blog/nisjlvhudy/article/p-3330989.html</a></p>
</the></excerpt>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[kafka---部署]]></title>
      <url>https://fangyeqing.github.io/2016/10/28/kafka---%E9%83%A8%E7%BD%B2/</url>
      <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br>Kafka是一种分布式的消息系统。本文基于0.9.0版本，利用自带的zookeeper，部署了3个broker节点的kafka集群。</excerpt></p>
<h2 id="下载、配置"><a href="#下载、配置" class="headerlink" title="下载、配置"></a>下载、配置</h2><p>下载<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">wget http://mirrors.cnnic.cn/apache/kafka/0.9.0.0/kafka_2.11-0.9.0.0.tgz</div><div class="line">tar -xzf kafka_2.11-0.9.0.0.tgz</div><div class="line">cd kafka_2.11-0.9.0.0</div></pre></td></tr></table></figure></p>
<a id="more"></a>  
<the rest="" of="" contents="" |="" 余下全文=""> 

<h2 id="启动zookeeper"><a href="#启动zookeeper" class="headerlink" title="启动zookeeper"></a>启动zookeeper</h2><p>config/zookeeper.properties,配置可以改数据目录，端口可以不改<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">dataDir=data/zookeeper              #数据目录，默认/tmp/zookeeper</div><div class="line">clientPort=2181                     #默认2181</div></pre></td></tr></table></figure></p>
<p>启动zk<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">nohup bin/zookeeper-server-start.sh config/zookeeper.properties &gt;&gt; zk.log &amp;</div></pre></td></tr></table></figure></p>
<h2 id="启动kafka-broker"><a href="#启动kafka-broker" class="headerlink" title="启动kafka-broker"></a>启动kafka-broker</h2><h3 id="broker配置"><a href="#broker配置" class="headerlink" title="broker配置"></a>broker配置</h3><p>配置可以改一下日志目录，端口冲突了可以改一下端口。</p>
<p>kafka-broker配置：config/server.properties<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">log.dirs=data/kafka-logs            #数据目录，默认/tmp/kafka-logs</div><div class="line">broker.id=0</div><div class="line">listeners=PLAINTEXT://:9092         #默认PLAINTEXT://:9092</div><div class="line">port=9092                           #端口默认为9092</div><div class="line">zookeeper.connect=localhost:2181    #zk连接信息</div><div class="line">delete.topic.enable=true            #在最后添加：可以删除topic</div></pre></td></tr></table></figure></p>
<p>另外两个broker配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cp config/server.properties config/server-1.properties</div><div class="line">cp config/server.properties config/server-2.properties</div></pre></td></tr></table></figure></p>
<p>config/server-1.properties<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">broker.id=1</div><div class="line">port=9093</div><div class="line">listeners=PLAINTEXT://:9093</div><div class="line">log.dir=data/kafka-logs-1</div></pre></td></tr></table></figure></p>
<p>config/server-2.properties<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">broker.id=2</div><div class="line">port=9094</div><div class="line">listeners=PLAINTEXT://:9094</div><div class="line">log.dir=data/kafka-logs-2</div><div class="line">``` </div><div class="line"></div><div class="line">broker启动</div></pre></td></tr></table></figure></p>
<p>nohup bin/kafka-server-start.sh config/server.properties &gt;&gt; broker1.log &amp;<br>nohup bin/kafka-server-start.sh config/server-1.properties &gt;&gt; broker2.log &amp;<br>nohup bin/kafka-server-start.sh config/server-2.properties &gt;&gt; broker3.log &amp;<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">## 创建topic</div><div class="line">- 创建topic：</div></pre></td></tr></table></figure></p>
<p>bin/kafka-topics.sh –create –zookeeper localhost:2181 –partitions 3 –topic test3partitions –replication-factor 1  #包含3个分区，1个副本<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">为Topic创建分区时，分区数最好是broker数量的整数倍,这样才能是一个Topic的分区均匀的分布在整个Kafka集群中。  </div><div class="line"></div><div class="line">- 查看已经创建的topic：</div></pre></td></tr></table></figure></p>
<p>bin/kafka-topics.sh –list –zookeeper localhost:2181<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">- 查看某个topic：</div></pre></td></tr></table></figure></p>
<p>bin/kafka-topics.sh –describe –zookeeper localhost:2181 –topic test3partitions<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">- 删除topic：</div></pre></td></tr></table></figure></p>
<p>bin/kafka-topics.sh –delete –topic test3partitions –zookeeper localhost:2181<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">## producer</div><div class="line">在一终端A启动producer</div></pre></td></tr></table></figure></p>
<p>bin/kafka-console-producer.sh –broker-list localhost:9092,localhost:9093,localhost:9094 –topic test3partitions<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">## consumer</div><div class="line">config/consumer.properties修改：</div></pre></td></tr></table></figure></p>
<p>zookeeper.connect=localhost:2181    #zookeeper，后面以host:port,host port,….<br>group.id=test-consumer-group          #消费者group-id<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">在另外的终端B、C、D启动consumer：</div></pre></td></tr></table></figure></p>
<p>bin/kafka-console-consumer.sh –zookeeper localhost:2181 –topic test3partitions</p>
<p>bin/kafka-console-consumer.sh –zookeeper localhost:2181 –consumer.config config/consumer.properties –topic test3partitions</p>
<p>bin/kafka-console-consumer.sh –zookeeper localhost:2181 –consumer.config config/consumer.properties –topic test3partitions</p>
<p>bin/kafka-console-consumer.sh –zookeeper localhost:2181 –consumer.config config/consumer.properties –topic test3partitions<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">后面加 --from-beginning表示从头开始收消息</div><div class="line"></div><div class="line">其中，B终端不配置group-id,将会为console-consumer-，加上随机数字。C、D、E终端读取配置文件中的group.id，为tet-consumer-group。</div><div class="line"></div><div class="line">### 测试</div><div class="line">在producer终端输入消息从1-20。可以看到B终端会输出1-20全部消息，图中B所示。而C、D、E终端由于属于同一个Consumer Group，partitions数量等于consumer，每个consumer消费了一个partition里的消息。图中为C、D、E。</div><div class="line"></div><div class="line">将C终端断开，剩下B、D、E去消费消息。B终端还是会输出1-20全部消息，图中为B1所示。而D、E属于同一个Consumer Group，且consumer数量少于partition数，可以看到D消费了两个partition中的数据，见图中D1所示。    </div><div class="line">![image](http://note.youdao.com/yws/public/resource/027eae2659928c104735afa6fe77369a/xmlnote/A6002CC243CC471FBF51E6BFDE0E1BA2/23687)  </div><div class="line"></div><div class="line">## Java api 测试</div><div class="line">利用Java api自己写一个与上面测试用例相同的例子。</div><div class="line"></div><div class="line">Producer</div></pre></td></tr></table></figure></p>
<p>public class NewProducerSimple {<br>    public static void main(String [] args) {<br>        Properties props = new Properties();<br>        props.put(“bootstrap.servers”, “localhost:9092,localhost:9093,localhost:9094”);<br>        props.put(“acks”, “all”);<br>        props.put(“retries”, 0);<br>        props.put(“batch.size”, 16384);<br>        props.put(“linger.ms”, 1);<br>        props.put(“buffer.memory”, 33554432);<br>        props.put(“key.serializer”, “org.apache.kafka.common.serialization.StringSerializer”);<br>        props.put(“value.serializer”, “org.apache.kafka.common.serialization.StringSerializer”);<br>        props.put(“partitioner.class”,”com.youdao.newClient.SimplePartitioner”);<br>        Producer<string, string=""> producer = new KafkaProducer&lt;&gt;(props);<br>        for(int i = 0; i &lt; 20; i++)<br>            producer.send(new ProducerRecord<string, string="">(“test3partitions”, Integer.toString(i), Integer.toString(i)));</string,></string,></p>
<pre><code>    producer.close();
}
</code></pre><p>}<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">分区规则，key.hash%3</div></pre></td></tr></table></figure></p>
<p>public class SimplePartitioner implements Partitioner {</p>
<pre><code>@Override
public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
    int partitionNum = 3;
    String k = (String)key;
    int partition = Math.abs(k.hashCode()) % partitionNum;
    return partition;
}
@Override
public void close() {
}
@Override
public void configure(Map&lt;String, ?&gt; map) {
}
</code></pre><p>}<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Consumer,同样，可以启动3个相同的consumer</div></pre></td></tr></table></figure></p>
<p>public class NewConsumerSimple {<br>    public static void main(String [] args) {<br>        Properties props = new Properties();<br>        props.put(“bootstrap.servers”, “localhost:9092,localhost:9093,localhost:9094”);<br>        props.put(“group.id”, “test”);<br>        props.put(“enable.auto.commit”, “true”);<br>        props.put(“auto.commit.interval.ms”, “1000”);<br>        props.put(“key.deserializer”, “org.apache.kafka.common.serialization.StringDeserializer”);<br>        props.put(“value.deserializer”, “org.apache.kafka.common.serialization.StringDeserializer”);<br>        KafkaConsumer<string, string=""> consumer = new KafkaConsumer&lt;&gt;(props);<br>        consumer.subscribe(Arrays.asList(“test3partitions”));<br>        while (true) {<br>            ConsumerRecords<string, string=""> records = consumer.poll(100);<br>            for (ConsumerRecord<string, string=""> record : records)<br>                System.out.printf(“offset = %d, key = %s, value = %s%n”, record.offset(), record.key(), record.value());<br>        }<br>    }<br>}<br>```</string,></string,></string,></p>
</the>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[kafka---介绍]]></title>
      <url>https://fangyeqing.github.io/2016/10/28/kafka---%E4%BB%8B%E7%BB%8D/</url>
      <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br>Kafka是一种分布式的消息系统。本文基于0.9.0版本，新版kafka加入了流处理组件kafka stream，最新的官方文档又自称分布式流处理平台。</excerpt></p>
<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><ul>
<li>Broker<br>Kafka的节点。kafka集群包含一个或多个broker</li>
<li>Producer<br>消息的生产者。负责发布消息到Kafka broker</li>
</ul>
<a id="more"></a>  
<the rest="" of="" contents="" |="" 余下全文="">   

<ul>
<li>Consumer<br>消息的消费者。每个consumer属于一个特定的consumer group（若不指定group id则属于默认的group）。使用consumer high level API时，同一topic的一条消息只能被同一个consumer group内的一个consumer消费，但多个consumer group可同时消费这一消息。</li>
<li>Topic<br>消息主题。例如pv日志、click日志、转化日志都可以作为topic。</li>
<li>Partition<br>topic物理上的分组。每个topic包含一个或多个partition，创建topic时可指定parition数量。每个partition是一个有序的队列，对应于一个文件夹，该文件夹下存储该partition的数据和索引文件。在发送一条消息时，生产者可以指定这条消息的key和分区机制来发送到不同的分区。</li>
<li>offset<br>每个partition中的每条消息被分配的有序id，是消息的唯一标识。每个partition都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partition中。<h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><img src="http://kafka.apache.org/090/images/producer_consumer.png" alt="image"><br>producers(生产者)通过网络将不同topic的messages(消息)发送到Kafka 集群，consumers(消费者)在集群订阅自己想要消费的topic。</li>
</ul>
<p>一个典型的kafka集群中包含若干producer（可以是web前端产生的page view，或者是服务器日志，系统CPU、memory等），若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干consumer group，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在consumer group发生变化时进行rebalance。producer使用push模式将消息发布到broker，consumer使用pull模式从broker订阅并消费消息。 　</p>
<h2 id="topic-amp-amp-partitions"><a href="#topic-amp-amp-partitions" class="headerlink" title="topic&amp;&amp;partitions"></a>topic&amp;&amp;partitions</h2><p>对于每个Topic，Kafka会为其维护一个如下图所示的分区的日志文件<br><img src="http://kafka.apache.org/090/images/log_anatomy.png" alt="image"><br>每个partition(分区)是一个有序的、不可修改的消息组成的队列；这些消息是被不断的appended到这个commit log（提交日志文件）上的。在这些patitions之中的每个消息都会被赋予一个叫做offset的顺序id编号，用来在partition之中唯一性的标示这个消息。</p>
<p>Kafka集群会保存一个时间段内所有被发布出来的信息，无论这个消息是否已经被消费过。</p>
<h3 id="partition内有序"><a href="#partition内有序" class="headerlink" title="partition内有序"></a>partition内有序</h3><p>Kafka仅仅提供提供partition之内的消息的全局有序，在不同的partition之间不能担保。partition的消息有序性加上可以按照指定的key划分消息的partition，这基本上满足了大部分应用的需求。如果你必须要实现一个全局有序的消息队列，那么可以采用Topic只划分1个partition来实现。但是这就意味着你的每个消费组只能有唯一的一个消费者进程。</p>
<h2 id="Consumer-Group"><a href="#Consumer-Group" class="headerlink" title="Consumer Group"></a>Consumer Group</h2><p>每一个consumer实例都属于一个consumer group，每一条消息都会被所有订阅了该topic的consumer group消费。通过group id指定consumer group。</p>
<p>并且使用high-level consumer时，同一个consumer group里只有一个consumer能消费到该消息。  </p>
<p>因为high level不用client关心offset, 会自动的读zookeeper中该Consumer group的last offset，相当于所有consumer都公用这个offset。当其中一个consumer消费一条消息时，offset就移动到下一条。  </p>
<p><img src="http://note.youdao.com/yws/public/resource/027eae2659928c104735afa6fe77369a/xmlnote/41CC44BBC283484B9E01F28C50A8991D/23720" alt="image">  </p>
<h3 id="不同形式的消息播发"><a href="#不同形式的消息播发" class="headerlink" title="不同形式的消息播发"></a>不同形式的消息播发</h3><p>订阅模式:每个Consumer都采用不同的group，每一条消息都会发送给所有消费者<br>消息队列模式:所有的Consumer在同一个Group里，消费者之间负载均衡  </p>
<h2 id="Producer-amp-amp-Consumer-amp-amp-partitions"><a href="#Producer-amp-amp-Consumer-amp-amp-partitions" class="headerlink" title="Producer&amp;&amp;Consumer&amp;&amp;partitions"></a>Producer&amp;&amp;Consumer&amp;&amp;partitions</h2><p>新建topic时，通过–partitions 可以设置分区数。可以指定partitions数为broker的整数倍，这样，每个broker会对应相同个数的partitions。</p>
<p>生产者在生产数据的时候，可以为每条消息指定Key，这样消息被发送到broker时，会根据分区规则选择被存储到哪一个partitions中。如果分区规则设置的合理，那么所有的消息将会被均匀的分布到不同的partitions中，这样就实现了负载均衡和水平扩展。</p>
<p>Kafka保证同一consumer group中只有一个consumer会消费某条消息，实际上，Kafka保证的是稳定状态下每一个consumer实例只会消费某一个或多个特定partition的数据，而某个partition的数据只会被某一个特定的consumer实例所消费。其中consumer和partition数量关系如下表所示：</p>
<table>
<thead>
<tr>
<th>consumer和partition数量关系</th>
<th>消费情况</th>
</tr>
</thead>
<tbody>
<tr>
<td>小于</td>
<td>至少有一个consumer会消费多个partition的数据</td>
</tr>
<tr>
<td>相等</td>
<td>一个consumer消费一个partition的数据</td>
</tr>
<tr>
<td>大于</td>
<td>部分consumer无法消费该topic下任何一条消息，浪费</td>
</tr>
</tbody>
</table>
<p>增减consumer，broker，partition会导致rebalance，rebalance后consumer对应的partition会发生变化，在后面的实例中也可以看到。</p>
<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>利用kafka中自带的生产者和消费者例子来做个简单的测试。具体步骤在另一篇<a href="https://fangyeqing.github.io/2016/10/28/kafka---%E9%83%A8%E7%BD%B2/">kakfa部署</a>中。</p>
<p>kafka集群有3个broker节点。新建一个partitions数量为3的topic。启动一个A终端为生产者，启动B、C、D、E终端为消费者。C、D、E终端为一个consumer group，B为单独的一个consumer group。</p>
<p>在producer终端输入消息从1-20。可以看到B终端会输出1-20全部消息，图中B所示。而C、D、E终端由于属于同一个Consumer Group，partitions数量等于consumer，每个consumer消费了一个partition里的消息。图中为C、D、E。</p>
<p>将C终端断开，剩下B、D、E去消费消息。B终端还是会输出1-20全部消息，图中为B1所示。而D、E属于同一个Consumer Group，且consumer数量少于partition数，可以看到D消费了两个partition中的数据，见图中D1所示。<br><img src="http://note.youdao.com/yws/public/resource/027eae2659928c104735afa6fe77369a/xmlnote/A6002CC243CC471FBF51E6BFDE0E1BA2/23687" alt="image">  </p>
<h2 id="Replication-amp-amp-broker节点故障处理"><a href="#Replication-amp-amp-broker节点故障处理" class="headerlink" title="Replication&amp;&amp;broker节点故障处理"></a>Replication&amp;&amp;broker节点故障处理</h2><h3 id="Replication"><a href="#Replication" class="headerlink" title="Replication"></a>Replication</h3><p>replication策略是基于partition。kafka通过创建topic时可以通过–replication-factor配置partition副本数。配置副本之后,每个partition都有一个唯一的leader，有0个或多个follower。</p>
<p>所有的读写操作都在leader上完成，leader批量从leader上pull数据。followers从leader消费消息来复制message，就跟普通的consumer消费消息一样。</p>
<p>一般情况下partition的数量大于等于broker的数量，并且所有partition的leader均匀分布在broker上。</p>
<h3 id="follower故障处理"><a href="#follower故障处理" class="headerlink" title="follower故障处理"></a>follower故障处理</h3><p>broker是否alive包含两个条件：</p>
<ul>
<li>一是它必须维护与Zookeeper的session(这个通过Zookeeper的heartbeat机制来实现)。</li>
<li>二是follower必须能够及时将leader的writing复制过来，不能“落后太多”。</li>
</ul>
<p>leader会track“in sync”的node list。如果一个follower宕机，或者落后太多，leader将把它从”in sync” list中移除。</p>
<p>一条消息只有被“in sync” list里的所有follower都从leader复制过去才会被认为已提交。这样就避免了部分数据被写进了leader，还没来得及被任何follower复制就宕机了，而造成数据丢失（consumer无法消费这些数据）</p>
<p>而对于producer而言，它可以选择是否等待消息commit，这可以通过producer的“acks”来设置。默认为acks=all ，这意味着leader将等待所有follower复制完消息。</p>
<h3 id="leader故障处理"><a href="#leader故障处理" class="headerlink" title="leader故障处理"></a>leader故障处理</h3><p>leader挂掉后，怎样在follower中选举出新的leader？</p>
<p>Kafka在Zookeeper中动态维护了一个ISR（in-sync replicas） set，这个set里的所有replica都跟上了leader，只有ISR里的成员才有被选为leader的可能。</p>
<p>如果某一个partition的所有replica都挂了，就无法保证数据不丢失了。这种情况下有两种可行的方案：</p>
<ul>
<li>一致性高：等待ISR中的任一个replica“活”过来，并且选它作为leader。可能会等待比较长的时间</li>
<li>可用性高：选择第一个“活”过来的replica（不一定是ISR中的）作为leader。有可能会丢失数据</li>
</ul>
<p>kafka采用第二种方案，可以通过配置unclean.leader.election.enable来关闭这种方案。</p>
<h3 id="测试-1"><a href="#测试-1" class="headerlink" title="测试"></a>测试</h3><p>kafka集群有3个broker节点。具体部署在另一篇<a href="https://fangyeqing.github.io/2016/10/28/kafka---%E9%83%A8%E7%BD%B2/">kafka部署</a>中。</p>
<p>做个简单的测试，创建一个3分区的topic，不指定副本数，可以看到默认一个副本，Partition均匀分布在各broker。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[fangyeqing@xxxx kafka_2.11-0.9.0.0]$bin/kafka-topics.sh --create --zookeeper localhost:2181 --partitions 3 --topic test3partitions</div><div class="line">[fangyeqing@xxxx kafka_2.11-0.9.0.0]$bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic test3partitions</div><div class="line">Topic:test3partitions	PartitionCount:3	ReplicationFactor:1	Configs:</div><div class="line">	Topic: test3partitions	Partition: 0	Leader: 1	Replicas: 1	Isr: 1</div><div class="line">	Topic: test3partitions	Partition: 1	Leader: 2	Replicas: 2	Isr: 2</div><div class="line">	Topic: test3partitions	Partition: 2	Leader: 0	Replicas: 0	Isr: 0</div></pre></td></tr></table></figure></p>
<p>创建一个3分区2副本的topic，可以看到Replicas和Isr中有1个follower。例如Partitions：0的Leader为broker：1,follower为broker：2，并且2在Isr中，理论上当Leader挂掉之后，2会顶上。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[fangyeqing@xxxx kafka_2.11-0.9.0.0]$bin/kafka-topics.sh --create --zookeeper localhost:2181 --partitions 3 --topic test3partition2replication --replication-factor 2</div><div class="line">[fangyeqing@xxxx kafka_2.11-0.9.0.0]$ bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic test3partition2replication</div><div class="line">Topic:test3partition2replication	PartitionCount:3	ReplicationFactor:2	Configs:</div><div class="line">	Topic: test3partition2replication	Partition: 0	Leader: 1	Replicas: 1,2	Isr: 1,2</div><div class="line">	Topic: test3partition2replication	Partition: 1	Leader: 2	Replicas: 2,0	Isr: 2,0</div><div class="line">	Topic: test3partition2replication	Partition: 2	Leader: 0	Replicas: 0,1	Isr: 0,1</div></pre></td></tr></table></figure></p>
<p>创建一个3分区2副本的topic，可以看到Replicas和Isr中有2个follower<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[fangyeqing@xxxx kafka_2.11-0.9.0.0]$bin/kafka-topics.sh --create --zookeeper localhost:2181 --partitions 3 --topic test3partition3replication --replication-factor 3</div><div class="line">[fangyeqing@xxxx kafka_2.11-0.9.0.0]$ bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic test3partition3replication</div><div class="line">Topic:test3partition3replication	PartitionCount:3	ReplicationFactor:3	Configs:</div><div class="line">	Topic: test3partition3replication	Partition: 0	Leader: 1	Replicas: 1,0,2	Isr: 1,0,2</div><div class="line">	Topic: test3partition3replication	Partition: 1	Leader: 2	Replicas: 2,1,0	Isr: 2,1,0</div><div class="line">	Topic: test3partition3replication	Partition: 2	Leader: 0	Replicas: 0,2,1	Isr: 0,2,1</div></pre></td></tr></table></figure></p>
<h2 id="Message-delivery-guarantees"><a href="#Message-delivery-guarantees" class="headerlink" title="Message delivery guarantees"></a>Message delivery guarantees</h2><p>目前有下面几种消息确保机制：</p>
<ul>
<li>At most once 消息可能会丢，但绝不会重复传输</li>
<li>At least one 消息绝不会丢，但可能会重复传输</li>
<li>Exactly once 每条消息肯定会被传输一次且仅传输一次，很多时候这是用户所想要的。</li>
</ul>
<p>Kafka默认保证At least once，并且允许通过设置producer异步提交来实现At most once。下面分阶段分析：</p>
<h3 id="Producer向broker发送消息"><a href="#Producer向broker发送消息" class="headerlink" title="Producer向broker发送消息"></a>Producer向broker发送消息</h3><p>当Producer向broker发送消息，由上述Replication的分析可知，一旦这条消息已经被commit，如果这个topic有多个replication（副本），某个broker挂掉也不会丢失消息。</p>
<p>Producer发送数据给broker的过程中，如果遇到网络问题而造成通信中断：</p>
<ul>
<li>At least once：Producer就无法判断该条消息是否已经commit，再重复提交时就会是At least once。</li>
<li>Exactly once：在以后的版本中producer可以生成一种类似于primary key的东西，发生故障时幂等性的retry多次。</li>
<li>At most once：Producer异步提交来实现At most once</li>
</ul>
<h3 id="Consumer从broker消费消息"><a href="#Consumer从broker消费消息" class="headerlink" title="Consumer从broker消费消息"></a>Consumer从broker消费消息</h3><p>当Consumer从broker消费消息时，consumer如果在消费消息时crash：</p>
<ul>
<li>At least once：读完消息先处理再commit消费状态(保存offset)</li>
<li>At most once：读完消息先commit消费状态(保存offset)再处理消息</li>
<li>Exactly once：需要协调offset和实际操作的输出，目前比较麻烦。离线数据可以做到去重，利用Camus或者Gobbin将kafka topic落地到HDFS，然后做去重即可。其中Camus可以参考我的另一篇博客<a href="https://fangyeqing.github.io/2016/12/01/Camus%E4%BB%8B%E7%BB%8D/">Camus介绍</a>。</li>
</ul>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://www.jasongj.com/2015/01/02/Kafka%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90/" target="_blank" rel="external">http://www.jasongj.com/2015/01/02/Kafka%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90/</a><br><a href="http://kafkadoc.beanmr.com/010_getting_started/01_introduction_cn.html" target="_blank" rel="external">http://kafkadoc.beanmr.com/010_getting_started/01_introduction_cn.html</a><br><a href="http://tech.meituan.com/kafka-fs-design-theory.html" target="_blank" rel="external">http://tech.meituan.com/kafka-fs-design-theory.html</a>  </p>
</the>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[hexo+github page搭建博客]]></title>
      <url>https://fangyeqing.github.io/2016/10/28/hexo+github_page%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/</url>
      <content type="html"><![CDATA[<excerpt in="" index="" |="" 首页摘要="">   

<h2 id="环境安装"><a href="#环境安装" class="headerlink" title="环境安装"></a>环境安装</h2><p>在windows和linux下都配置了，感觉还是Linux方便一点</p>
<a id="more"></a>  
<the rest="" of="" contents="" |="" 余下全文="">   

<h3 id="node-js环境-windows-linux略"><a href="#node-js环境-windows-linux略" class="headerlink" title="node.js环境(windows,linux略)"></a>node.js环境(windows,linux略)</h3><p><a href="https://nodejs.org/en/download/" target="_blank" rel="external">官方下载地址</a>，选择对应版本，改个安装路径，然后一路下一步。  </p>
<p>安装完成可以在windows命令行，查看是否安装成功。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">node -v</div><div class="line">npm -v</div></pre></td></tr></table></figure></p>
<h3 id="git环境"><a href="#git环境" class="headerlink" title="git环境"></a>git环境</h3><p>略</p>
<h2 id="配置github"><a href="#配置github" class="headerlink" title="配置github"></a>配置github</h2><p><a href="https://github.com/" target="_blank" rel="external">https://github.com/</a></p>
<h3 id="新建repository"><a href="#新建repository" class="headerlink" title="新建repository"></a>新建repository</h3><p>点击<strong>New repository</strong>  </p>
<p><strong>Repository name</strong>下填写博客目录，例如：username.github.io<br><strong>Description</strong>下填写描述，例如：我的博客  </p>
<h3 id="生成github-page"><a href="#生成github-page" class="headerlink" title="生成github page"></a>生成github page</h3><p>创建目录后进入该目录，“<strong>Setting</strong>”进行设置。  </p>
<p>下拉到“<strong>GitHub Pages</strong>”模块，点击“<strong>Launch automatic page generator</strong>”按钮，生成github page。</p>
<p>刚才配置的“username.github.io”已经可以访问了。</p>
<h2 id="Hexo"><a href="#Hexo" class="headerlink" title="Hexo"></a>Hexo</h2><p>linux的cd很简单，但是windows有点坑爹，中间加一个/d。</p>
<p>通过cmd命令行窗口进入到想要安装的目录。当然也可以通过文件系统进入当该目录，shift+右键点进去。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cd /d D:\coding files\Workspace\hexo</div></pre></td></tr></table></figure></p>
<p>然后执行安装命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">npm install hexo-cli -g</div></pre></td></tr></table></figure></p>
<p>等待比较久之后安装完了，会有WARN，但没事，查看是否成功<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hexo -v</div></pre></td></tr></table></figure></p>
<p>初始化。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">hexo init              #不加路径表示当前文件夹作为hexo目录 </div><div class="line">npm install</div><div class="line">hexo generate          #生成静态文件,从source/_post目录将md转成public中的html</div><div class="line">hexo server            #启动本地server，端口4000</div></pre></td></tr></table></figure></p>
<p>到这里已经可以在本地访问到了，<a href="http://localhost:4000" target="_blank" rel="external">http://localhost:4000</a></p>
<h3 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h3><p>修改配置文件：_config.yml。主要配置网站url、deploy到github的地址。每个冒号后面一定要有空格。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"># Site</div><div class="line">title: 小懒的博客</div><div class="line">subtitle:</div><div class="line">description:Re0: 从零开始的程序猿世界</div><div class="line">author: 小懒</div><div class="line">language: zh-Hans</div><div class="line">timezone: Asia/Shanghai</div><div class="line"></div><div class="line"># URL</div><div class="line">url: https://fangyeqing.github.io/</div><div class="line">root: /</div><div class="line"></div><div class="line"># Deployment</div><div class="line">deploy:</div><div class="line">  type: git</div><div class="line">  repo: https://github.com/fangyeqing/fangyeqing.github.io.git</div><div class="line">  branch: master</div></pre></td></tr></table></figure></p>
<h2 id="部署到github-page"><a href="#部署到github-page" class="headerlink" title="部署到github page"></a>部署到github page</h2><p>部署之前安装一下hexo-git部署插件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">npm install hexo-deployer-git --save</div></pre></td></tr></table></figure></p>
<p>部署加-g参数表示部署之前执行生成静态文件操作，相当于<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hexo deploy -g</div></pre></td></tr></table></figure></p>
<h3 id="出现问题"><a href="#出现问题" class="headerlink" title="出现问题"></a>出现问题</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Username for &apos;https://github.com&apos;: error: unable to read askpass response from &apos;/usr/libexec/openssh/gnome-ssh-askpass&apos;</div></pre></td></tr></table></figure>
<p>执行如下指令，或者直接把它加入到.bash_profile中<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">unset SSH_ASKPASS</div></pre></td></tr></table></figure></p>
<h2 id="添加新文章"><a href="#添加新文章" class="headerlink" title="添加新文章"></a>添加新文章</h2><p>source/_post文件夹: 新建md类型的文档,新建的文章头需要添加一些信息，比如标题、日期、分类、标签等，如下所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">---</div><div class="line">title: Hello World</div><div class="line">date: 2015-12-03 00:00:00</div><div class="line">categories: samza</div><div class="line">tags: [samza,学习,hello world] </div><div class="line">toc: true</div><div class="line">---</div></pre></td></tr></table></figure></p>
<p>categories：分类<br>toc：设定是否开启目录，需要主题支持。</p>
<p>可以现在本地测试一下，确认没问题再deploy上去<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hexo g</div><div class="line">hexo s</div></pre></td></tr></table></figure></p>
<p>重新发布<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hexo d -g</div></pre></td></tr></table></figure></p>
<h2 id="主题修改"><a href="#主题修改" class="headerlink" title="主题修改"></a>主题修改</h2><p>去<a href="https://github.com/hexojs/hexo/wiki/Themes" target="_blank" rel="external">hexo的github</a>下载主题，放到themes目录下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git clone https://github.com/MOxFIVE/hexo-theme-yelee.git themes/yelee</div></pre></td></tr></table></figure></p>
<p>然后根据<a href="http://moxfive.coding.me/yelee/" target="_blank" rel="external">作者的gitbook</a>修改_config.yml文件，实现各种配置，改完继续重新发布出去</p>
<p>其中比较重要的如下，其他的个性化定制可以去<a href="http://moxfive.coding.me/yelee/" target="_blank" rel="external">作者的gitbook</a>：</p>
<h3 id="评论系统"><a href="#评论系统" class="headerlink" title="评论系统"></a>评论系统</h3><p>可以利用多说或者有言。</p>
<p>先去<a href="http://duoshuo.com/create-site/" target="_blank" rel="external">多说</a>注册一个账号，创建站点。例如我注册的为：fangyeqing.duoshuo.com，在配置disqus中反注释掉duoshuo的on: true,然后在domain 中填入你设定的域名前半部分。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">duoshuo:</div><div class="line">  on: true</div><div class="line">  domain: fangyeqing</div></pre></td></tr></table></figure>
<h3 id="站内搜索"><a href="#站内搜索" class="headerlink" title="站内搜索"></a>站内搜索</h3><p>需要先安装一个插件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">npm install hexo-generator-search --save</div></pre></td></tr></table></figure></p>
<p>然后修改配置文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">#主题配置themes/yelee/_config.yml</div><div class="line">search: </div><div class="line">  on: true</div><div class="line">  onload: false</div><div class="line">  </div><div class="line">#根目录配置_config.yml  </div><div class="line">search:</div><div class="line">  path: search.xml</div><div class="line">  field: all</div></pre></td></tr></table></figure></p>
<h3 id="文章摘要"><a href="#文章摘要" class="headerlink" title="文章摘要"></a>文章摘要</h3><p>在首页显示摘要，非全文。在文章头部加入以下内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">---</div><div class="line">title: Hello World</div><div class="line">date: 2015-12-03 00:00:00</div><div class="line">categories: samza</div><div class="line">tags: [samza,学习,hello world] </div><div class="line">toc: true</div><div class="line">---</div><div class="line">&lt;Excerpt in index | 首页摘要&gt; </div><div class="line">摘要内容...</div><div class="line">&lt;!-- more --&gt;</div><div class="line">&lt;The rest of contents | 余下全文&gt;</div><div class="line">余下的全文内容...</div></pre></td></tr></table></figure></p>
<h3 id="关于我"><a href="#关于我" class="headerlink" title="关于我"></a>关于我</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hexo new page about</div></pre></td></tr></table></figure>
<p>在hexo\source\about\index.md中修改</p>
<h3 id="标签云"><a href="#标签云" class="headerlink" title="标签云"></a>标签云</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hexo new page tags</div></pre></td></tr></table></figure>
<p>会自动生成标签云</p>
</the></excerpt>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[程序员快捷键]]></title>
      <url>https://fangyeqing.github.io/2016/10/27/%E7%A8%8B%E5%BA%8F%E5%91%98%E5%BF%AB%E6%8D%B7%E9%94%AE/</url>
      <content type="html"><![CDATA[<excerpt in="" index="" |="" 首页摘要="">   

<p>工欲善其事必先利其器，程序员通常需要通过摆脱鼠标或者触摸板提高效率，各种插件或者快捷键必不可少。</p>
<ul>
<li>通常出现问题会去google一发，浏览器插件Vimium值得拥有，常用的vim操作就可以玩转浏览器。</li>
<li>Intellij IDEA中常用的AceJump可以实现光标眼球定位，IdeaVim类似于Vim操作，可以解放你的鼠标。</li>
<li>公司配了两三个显示屏幕，需要切来切去，切屏快捷键也需要掌握。由于只有windows的笔记本，也只介绍windows相关的快捷键。</li>
<li>linux和vim相关快捷键肯定也是必不可少的。</li>
</ul>
<a id="more"></a>  
<the rest="" of="" contents="" |="" 余下全文=""> 

<h2 id="chrome插件-Vimium"><a href="#chrome插件-Vimium" class="headerlink" title="chrome插件-Vimium"></a>chrome插件-Vimium</h2><h3 id="光标移动："><a href="#光标移动：" class="headerlink" title="光标移动："></a>光标移动：</h3><p>j/k/h/l ：上下左右移动。<br>gg/G    ：跳转到页面的上下。<br>u/d     ：向下翻页（PageUp/Down）  </p>
<h3 id="各种模式"><a href="#各种模式" class="headerlink" title="各种模式"></a>各种模式</h3><h4 id="Hint-模式-f-F"><a href="#Hint-模式-f-F" class="headerlink" title="Hint 模式    f/F"></a>Hint 模式    f/F</h4><p>f/F : 在当前/新的页面打开一个新的链接。</p>
<h4 id="查找模式-string"><a href="#查找模式-string" class="headerlink" title="查找模式    /string"></a>查找模式    /string</h4><p>n: 向下查找匹配内容<br>N：向上查找匹配内容</p>
<h4 id="输入模式（i-如果发现命令不起作用，进入输入模式，按Esc回到命令模式）"><a href="#输入模式（i-如果发现命令不起作用，进入输入模式，按Esc回到命令模式）" class="headerlink" title="输入模式（i    如果发现命令不起作用，进入输入模式，按Esc回到命令模式）"></a>输入模式（i    如果发现命令不起作用，进入输入模式，按Esc回到命令模式）</h4><p>gi：将焦点集中到第一个输入框，Tab键在多个输入框切换<br>Ngi：则焦点集中到第N个输入框</p>
<h4 id="visual-caret模式（目前用于复制粘贴）"><a href="#visual-caret模式（目前用于复制粘贴）" class="headerlink" title="visual/caret模式（目前用于复制粘贴）"></a>visual/caret模式（目前用于复制粘贴）</h4><p>v：进入visual模式，c 切换caret模式，然后jkhl可以选择复制起点。再v切换到visual模式，jkhl选择复制内容，y复制<br>V：进入visual-line模式，复制方法同上</p>
<h3 id="标签页操作："><a href="#标签页操作：" class="headerlink" title="标签页操作："></a>标签页操作：</h3><p>t：创建一个新的标签页<br>yy：拷贝当前页面的URL到剪贴板<br>p/P：直接搜索clipboard中的内容<br>o/O：打开url，书签，历史<br>b/B：打开书签<br>T：标签页快速切换，Tab切换（Ctrl+Tab也可以）    </p>
<p>J/K，gt/gT：跳转到左/右边的一个标签页<br>H/L：回退上/下一个历史页面（相当于浏览器中的左右箭头）<br>x/X：关闭当前/恢复关闭的标签页<br>r：重新载入该页（F5）<br>gu：跳转到父页面  </p>
<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p>？：显示命令的帮助提示（再按一次关闭）<br>F6：当前的标签页直接输入一个新的网址<br>Tab：输入、标签切换。（如果光标定位到地址栏，可以Tab或者F6跳出）</p>
<h3 id="chrome自带快捷键："><a href="#chrome自带快捷键：" class="headerlink" title="chrome自带快捷键："></a>chrome自带快捷键：</h3><p>alt+F4 关闭chrome<br>ctrl+t 打开标签页<br>ctrl+F4/w 关闭标签页<br>ctrl+n 新建窗口<br>ctrl+1,2,3,4… 切换到相应标签页（在Vimium失效时使用）</p>
<h2 id="Intellij-IDEA快捷键"><a href="#Intellij-IDEA快捷键" class="headerlink" title="Intellij IDEA快捷键"></a>Intellij IDEA快捷键</h2><h3 id="插件AceJump"><a href="#插件AceJump" class="headerlink" title="插件AceJump:"></a>插件AceJump:</h3><p>Ctrl+:  进入模式，输入想要跳转到的字母，类似于Chrome插件的Hint模式</p>
<h3 id="插件IdeaVim："><a href="#插件IdeaVim：" class="headerlink" title="插件IdeaVim："></a>插件IdeaVim：</h3><p>安装之后，会有按键冲突，可以将常用的设置为Intellij IDEA自己的按键。</p>
<p>还可以设置开启关闭快捷键：Setting-Keymap查找Vim Emulator，设置激活、关闭的快捷键为Ctrl+”</p>
<h3 id="编辑："><a href="#编辑：" class="headerlink" title="编辑："></a>编辑：</h3><p>Alt+Enter  补全<br>Shift+F6 重命名  </p>
<h3 id="查找："><a href="#查找：" class="headerlink" title="查找："></a>查找：</h3><p>Double Shift<br>Ctrl+F<br>Ctrl+Shift+F<br>Ctrl+R<br>Ctrl+Shift+R<br>Alt+F7     #找出用处  </p>
<h3 id="调试："><a href="#调试：" class="headerlink" title="调试："></a>调试：</h3><p>F8  Step over<br>F7 Step into<br>Shift+F8 Step out<br>F9 Resume  </p>
<h3 id="导航："><a href="#导航：" class="headerlink" title="导航："></a>导航：</h3><p>Esc：切换到编辑窗<br>Alt+1：切换到 project<br>Ctrl+Tab：切换编辑窗口和工具窗口  </p>
<h3 id="跳转："><a href="#跳转：" class="headerlink" title="跳转："></a>跳转：</h3><p>Ctrl+B 进入定义（方法，类。。）<br>Ctrl+Alt+B 进入接口实现<br>Alt+Up/Down 跳转到下一个方法<br>Ctrl+Alt+左/右 跳转到上一个位置<br>Ctrl+Shift+回退 跳转到上一个编辑位置  </p>
<h3 id="版本管理："><a href="#版本管理：" class="headerlink" title="版本管理："></a>版本管理：</h3><p>Ctrl+K  提交  </p>
<h2 id="windows-7快捷键"><a href="#windows-7快捷键" class="headerlink" title="windows 7快捷键"></a>windows 7快捷键</h2><p>Win + 1,2,3,4…    #任务栏中任务切换，按几下相同的数字切换多个相同任务<br>Win+ T              #任务栏中任务切换，配合左右切换多个相同任务<br>Win+ b              #光标移动至右下角小图标  </p>
<p>Win + 上下左右      #窗口在当前屏幕内移动<br>Win + Shift + 左右  #窗口在多屏之间移动  </p>
<p>Ctrl + Shift + Esc  #快速打开 Windows 任务管理器<br>Win + L             #锁定屏幕  </p>
<h2 id="xshell快捷键"><a href="#xshell快捷键" class="headerlink" title="xshell快捷键"></a>xshell快捷键</h2><p>Shift+Alt+N 新建选项卡<br>Alt+o 打开选项卡<br>Ctrl+Tab 切换窗体<br>Alt+N 切换到第几个窗体<br>open  打开session<br>exit 已连接则退出session，未连接则退出终端<br>Alt+Enter 切换到全屏模式<br>Shift+ ↑↓（PageUp，PageDown） 翻页  </p>
<h2 id="linux-快捷键"><a href="#linux-快捷键" class="headerlink" title="linux 快捷键"></a>linux 快捷键</h2><p>sz afile：从服务器下载文件a到本机<br>sz path/* : 下载路径下所有的文件<br>rz：从本机上传到当前目录<br>history：显示历史指令<br>Ctrl+p\n：显示上/下一条指令<br>Ctrl+f/b光标向前/后移动一个字符,相当-&gt; &lt;-（forward，back）<br>Alt+f/b 光标向前/后移动一个单词<br>Ctrl+d 删除当前字符<br>Ctrl+a/e：移动到当前行开头/结尾<br>Ctrl+r/s：搜索之前/后的指令，继续按Ctrl+r为上一条  </p>
<h2 id="vim快捷键"><a href="#vim快捷键" class="headerlink" title="vim快捷键"></a>vim快捷键</h2><p>vi filename 打开或者新建文件</p>
<h3 id="visual-mode：可视化模式，用于复制一个矩形区域的内容"><a href="#visual-mode：可视化模式，用于复制一个矩形区域的内容" class="headerlink" title="visual mode：可视化模式，用于复制一个矩形区域的内容"></a>visual mode：可视化模式，用于复制一个矩形区域的内容</h3><p>v:字符选择，会将光标经过的地方反白选择；<br>V:行选择；<br>Ctrl+v：块选择；<br>y：复制反白的地方；<br>d：删除反白的地方。<br>p：粘贴复制的地方  </p>
<h3 id="insert-mode：编辑模式"><a href="#insert-mode：编辑模式" class="headerlink" title="insert mode：编辑模式"></a>insert mode：编辑模式</h3><p>a/A，i/I ,o/O开始编辑，编辑完按esc<br>:wq回车保存退出，:q为直接退出  </p>
<h3 id="一般模式：esc进入"><a href="#一般模式：esc进入" class="headerlink" title="一般模式：esc进入"></a>一般模式：esc进入</h3><p>/abc      #向下查找abc<br>?abc     #向上查找abc<br>n下一个目标，N上一个<br>jkhl：上下左右移动<br>ctrl +u/d上下翻页<br>gg/G:跳转到顶部/底部<br>：n　跳转到ｎ行<br>yy：复制当前行<br>p：在光标下行粘贴<br>x：删除当前光标<br>dd：删除当前行<br>u：撤销<br>Ctrl+r撤销的撤销  </p>
<h3 id="删除操作：删除后按p可以复制删除内容。"><a href="#删除操作：删除后按p可以复制删除内容。" class="headerlink" title="删除操作：删除后按p可以复制删除内容。"></a>删除操作：删除后按p可以复制删除内容。</h3><p>daw 删除一个单词<br>d$删除至行尾<br>d0删除至行首（包括缩进）<br>d^删除至行首（保留缩进）<br>dd删除当前行。  </p>
<p>J ：直接把下一行连接到本行末尾，去除缩进 </p>
<h3 id="光标移动：-1"><a href="#光标移动：-1" class="headerlink" title="光标移动："></a>光标移动：</h3><p>10G : 直接移动到10行<br> H - 光标移动到屏幕第一行。<br>L - 光标移动到屏幕最后一行。<br>M - 光标移动到屏幕中间。<br> zz - 光标所在行居中。   </p>
<h3 id="改变大小写"><a href="#改变大小写" class="headerlink" title="改变大小写"></a>改变大小写</h3><p>~ ：将光标下的字母改变大小写<br> g~aw ：改变当前单词的大小写</p>
</the></excerpt>]]></content>
    </entry>
    
  
  
    
    <entry>
      <title><![CDATA[about]]></title>
      <url>https://fangyeqing.github.io/about/index.html</url>
      <content type="html"><![CDATA[<p>程序员并不是木头和绝缘体，是有血有肉的逗比</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[tags]]></title>
      <url>https://fangyeqing.github.io/tags/index.html</url>
      <content type="html"></content>
    </entry>
    
  
</search>
