<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
    
    <entry>
      <title><![CDATA[Samza 5---Samza API]]></title>
      <url>https://fangyeqing.github.io/2016/11/17/Samza_5---Samza_API/</url>
      <content type="html"><![CDATA[<excerpt in="" index="" |="" 首页摘要="">   

<p>Samza任务类必须实现StreamTask,可选 InitableTask, ClosableTask,WindowableTask<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">public class xxxxTask implements StreamTask, InitableTask, ClosableTask,WindowableTask &#123;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<a id="more"></a>  
<p><the rest="" of="" contents="" |="" 余下全文="">   </the></p>
<h2 id="StreamTask"><a href="#StreamTask" class="headerlink" title="StreamTask"></a>StreamTask</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">public interface StreamTask &#123;</div><div class="line">    void process(IncomingMessageEnvelope var1, //接收到的消息封装</div><div class="line">                MessageCollector var2,//用来发送其他消息</div><div class="line">                TaskCoordinator var3) </div><div class="line">    throws Exception;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="IncomingMessageEnvelop"><a href="#IncomingMessageEnvelop" class="headerlink" title="IncomingMessageEnvelop"></a>IncomingMessageEnvelop</h3><p>代表接收到的消息的封装,表示StreamTask收到一个分区的一个特定的输入流。包括：</p>
<ul>
<li>message</li>
<li>key</li>
<li>消息来源（system+stream+partition）<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">public class IncomingMessageEnvelope &#123;</div><div class="line">  /** A deserialized message. */</div><div class="line">  Object getMessage() &#123; ... &#125;</div><div class="line"></div><div class="line">  /** A deserialized key. */</div><div class="line">  Object getKey() &#123; ... &#125;</div><div class="line"></div><div class="line">  /** The stream and partition that this message came from. */</div><div class="line">  SystemStreamPartition getSystemStreamPartition() &#123; ... &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="SystemStreamPartition"><a href="#SystemStreamPartition" class="headerlink" title="SystemStreamPartition"></a>SystemStreamPartition</h4><p>消息来源包括：</p>
<ul>
<li>消息来源system名</li>
<li>消息来源stream/topic/queue名</li>
<li>消息流的分区<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">/** A triple of system name, stream name and partition. */</div><div class="line">public class SystemStreamPartition extends SystemStream &#123;</div><div class="line"></div><div class="line">  /** The name of the system which provides this stream. It is</div><div class="line">      defined in the Samza job&apos;s configuration. */</div><div class="line">  public String getSystem() &#123; ... &#125;</div><div class="line"></div><div class="line">  /** The name of the stream/topic/queue within the system. */</div><div class="line">  public String getStream() &#123; ... &#125;</div><div class="line"></div><div class="line">  /** The partition within the stream. */</div><div class="line">  public Partition getPartition() &#123; ... &#125;</div><div class="line">  </div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="MessageCollector"><a href="#MessageCollector" class="headerlink" title="MessageCollector"></a>MessageCollector</h3><p> 为了发送一个消息， 你会创建一个OutgoingMessageEnvelop对象并且把它传递给消息收集器。它至少会确定你想要发送的消息、系统和数据流名字再发送出去。你也可以确定分区的key和另一些参数。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">public interface MessageCollector &#123;</div><div class="line">  void send(OutgoingMessageEnvelope envelope);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>注意：<br>请只在process()方法里使用MessageCollector对象。如果你保持住一个MessageCollector实例并且之后再次使用它，你的消息可能会错误地发送出去。</p>
<h4 id="OutgoingMessageEnvelope"><a href="#OutgoingMessageEnvelope" class="headerlink" title="OutgoingMessageEnvelope"></a>OutgoingMessageEnvelope</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">public class OutgoingMessageEnvelope &#123;</div><div class="line">    private final SystemStream systemStream;</div><div class="line">    private final String keySerializerName;</div><div class="line">    private final String messageSerializerName;</div><div class="line">    private final Object partitionKey;</div><div class="line">    private final Object key;</div><div class="line">    private final Object message;</div><div class="line">    </div><div class="line">    public OutgoingMessageEnvelope(SystemStream systemStream, String keySerializerName, String messageSerializerName, Object partitionKey, Object key, Object message) &#123; ... &#125;</div><div class="line">    </div><div class="line">     public OutgoingMessageEnvelope(SystemStream systemStream, Object partitionKey, Object key, Object message) &#123; ... &#125;</div><div class="line"></div><div class="line">    public OutgoingMessageEnvelope(SystemStream systemStream, Object key, Object message) &#123; ... &#125;</div><div class="line">    </div><div class="line">    public OutgoingMessageEnvelope(SystemStream systemStream, Object message) &#123; ... &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="InitableTask"><a href="#InitableTask" class="headerlink" title="InitableTask"></a>InitableTask</h2><p>用来处理初始化工作，init 函数会首先被调用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">public interface InitableTask &#123;</div><div class="line">    void init(Config var1, TaskContext var2) throws Exception;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="ClosableTask"><a href="#ClosableTask" class="headerlink" title="ClosableTask"></a>ClosableTask</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">public interface ClosableTask &#123;</div><div class="line">    void close() throws Exception;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="WindowableTask"><a href="#WindowableTask" class="headerlink" title="WindowableTask"></a>WindowableTask</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">public interface WindowableTask &#123;</div><div class="line">    void window(MessageCollector var1, </div><div class="line">                TaskCoordinator var2) throws Exception;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h2><p>有一个简单的任务，它把每个输入的消息拆成单词，并且发送每一个单词作为一个消息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"> public class SplitStringIntoWords implements StreamTask, InitableTask, ClosableTask &#123;</div><div class="line"></div><div class="line">    private String outputSystem;</div><div class="line">    </div><div class="line">    //官网教程中直接使用固定的SystemStream,稍加改造</div><div class="line">    //private final SystemStream output_stream = new SystemStream(&quot;kafka&quot;, &quot;words&quot;);</div><div class="line">    </div><div class="line">    @Override</div><div class="line">    public void close() throws Exception &#123;</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    @Override</div><div class="line">    public void init(Config config, TaskContext context) throws Exception &#123;//初始化时从配置文件读output system</div><div class="line">        outputSystem = config.get(&quot;task.output.system&quot;);</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    public void process(IncomingMessageEnvelope envelope,</div><div class="line">                      MessageCollector collector,</div><div class="line">                      TaskCoordinator coordinator) &#123;</div><div class="line">        String topic = envelope.getSystemStreamPartition().getSystemStream().getStream();</div><div class="line">        </div><div class="line">        topic=topic+&quot;_split&quot;;//获取输入消息的topic，加上后缀</div><div class="line">        </div><div class="line">        SystemStream output_stream=new SystemStream(outputSystem, topic);//构造新的发送消息的System+Stream</div><div class="line">        </div><div class="line">        String message = (String) envelope.getMessage();//接收到的消息</div><div class="line">        </div><div class="line">        for (String word : message.split(&quot; &quot;)) &#123;</div><div class="line">          //单词作为key，1作为value，后续任务可以将1相加计数</div><div class="line">          collector.send(new OutgoingMessageEnvelope(output_stream, word, 1));</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h2><p><a href="https://samza.apache.org/learn/documentation/0.10/" target="_blank" rel="external">https://samza.apache.org/learn/documentation/0.10/</a><br><a href="https://github.com/feuyeux/hello-samza/blob/master/doc/0.hello_samza.md" target="_blank" rel="external">https://github.com/feuyeux/hello-samza/blob/master/doc/0.hello_samza.md</a><br><a href="http://wdxtub.com/vault/cc-21.html" target="_blank" rel="external">http://wdxtub.com/vault/cc-21.html</a><br><a href="http://www.infoq.com/cn/articles/linkedin-samza" target="_blank" rel="external">http://www.infoq.com/cn/articles/linkedin-samza</a><br><a href="http://blog.csdn.net/colorant/article/details/12082145" target="_blank" rel="external">http://blog.csdn.net/colorant/article/details/12082145</a><br><a href="https://wyyhzc.gitbooks.io/hadoop2x/content/samzacontainer.html" target="_blank" rel="external">https://wyyhzc.gitbooks.io/hadoop2x/content/samzacontainer.html</a></p>
</excerpt>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Samza 4---核心部件]]></title>
      <url>https://fangyeqing.github.io/2016/11/17/Samza_4---%E6%A0%B8%E5%BF%83%E9%83%A8%E4%BB%B6/</url>
      <content type="html"><![CDATA[<excerpt in="" index="" |="" 首页摘要="">   

<h2 id="SamzaContainer"><a href="#SamzaContainer" class="headerlink" title="SamzaContainer"></a>SamzaContainer</h2><p>SamzaContainer负责管理一个或多个StreamTask实例的启动，执行和关闭。每个SamzaContainer通常在独立的Java虚拟机上运行。一个Samza job可以由几个SamzaContainers组成，并可以在在不同的机器上运行。</p>
<p>当SamzaContainer启动时，它按照顺序执行以下操作：  </p>
<a id="more"></a>  
<the rest="" of="" contents="" |="" 余下全文=""> 

<ul>
<li>获取每个输入流的分区的最后一个checkpoint记录的偏移量，并从此位置开始处理消息  </li>
<li>作为消费者，对于每一个输入流分区创建一个“reader”线程</li>
<li>启动度量监控器（metrics reporters），监控度量指标</li>
<li>启动定时器检查站（checkpoint timer），每隔一段时间，保存任务的输入流中的偏移量</li>
<li>如果定义了任务的windows方法，将启动一个窗口定时器（window timer），触发任务的windows方法</li>
<li>为每个kafka输入流的分区实例化和初始化StreamTask（即调用InitableTask的init方法）</li>
<li>启动事件循环（event loop），从reader线程读取消息，传递到StreamTask</li>
</ul>
<h3 id="Event-Loop"><a href="#Event-Loop" class="headerlink" title="Event Loop"></a>Event Loop</h3><p>事件循环是container的一个单线程，负责读写消息,传递指标（metrix）、checkpoint周期执行和window周期执行。事件循环的工作原理如下:</p>
<ul>
<li>从传入消息队列获取消息;</li>
<li>通过调用process()给适当的任务实例传递信息;</li>
<li>如果任务实例实现WindowableTask并且窗口周期时间到了,在该任务实例上调用window();</li>
<li>从process()和window()调用适当的SystemProducers输出消息;</li>
<li>时间间隔到了，写checkpoint</li>
</ul>
<h3 id="任务与分区-Tasks-and-Partitions"><a href="#任务与分区-Tasks-and-Partitions" class="headerlink" title="任务与分区(Tasks and Partitions)"></a>任务与分区(Tasks and Partitions)</h3><p>通过前面的介绍可以得知，samza job划分为task，samza stream划分为partition。单个task消费并处理stream中单个partition的消息。</p>
<p>因此，samza job的input stream有多少个partition，就会创建多少个samza task 的实例。</p>
<p><img src="http://samza.apache.org/img/0.8/learn/documentation/container/tasks-and-partitions.svg" alt="image"></p>
<p>samza stream的partition数量，取决于消费的系统。</p>
<p>例如，如果的数据流是通过kafka系统来实现的，那么数据流的partition数量是kafka的topic的分区数。是你创建kafka队列的时候的cmd决定的。如果cmd中没有指定，那么默认是通过 kafka的服务器端配置中的num.partitions这个阐述。</p>
<p>如果samza job多于一个input stream，那么，对应到Samza job 的task实例，将是所有input stream中partition的最大值。例如：如果一个Samza job从PageViewEvent（12 partition）和ServiceMetricEvent（14 partition），那么，将会产生14个task实例（从0到13）。task实例12和13将只用来读取和ServiceMetricEvent事件，因为PageViewEvent没有对应的partition。</p>
<h3 id="容器和资源分配"><a href="#容器和资源分配" class="headerlink" title="容器和资源分配"></a>容器和资源分配</h3><p>task实例的数量由input stream的partition数决定。</p>
<p>SamzaContainer数，是否什么决定的呢?如果使用yarn，容器的数量是由分配给你的CPU和内存资源决定的。</p>
<p>每一个SamzaContainer被设计成只是用一个CPU，因此他用了单线程事件循环的模式。因此，你在开发程序的时候，不要再SamzaContainer创建自己的多线程。如果你需要进行并行，你需要配置一下你的job利用多SamzaContainer。</p>
<h3 id="多个输入流"><a href="#多个输入流" class="headerlink" title="多个输入流 　　 　　"></a>多个输入流 　　 　　</h3><p>如果你的工作有多个输入流,Samza提供了一个简单但强大的机制来加入数据从不同的来源:每个任务实例接收消息从一个分区的每个输入流。例如,假设您有两个输入流,A和B,每四个分区。Samza创建了四个任务实例流程,分配分区如下:<br>Task instance|Consumes stream partitions<br>—|—<br>0|stream A partition 0, stream B partition 0<br>1|stream A partition 1, stream B partition 1<br>2|stream A partition 2, stream B partition 2<br>3|stream A partition 3, stream B partition 3</p>
<p>因此,如果想要两个在不同的流中的事件被同样的任务实例处理,需要确保它们被发送到相同的分区号，即使用相同的key发送消息。</p>
<h2 id="Stream"><a href="#Stream" class="headerlink" title="Stream"></a>Stream</h2><p>SamzaContainer 是通过 SystemConsumer 与 SystemProducer 接口进行消息得读取与写入。你可以通过这两个接口实现对任何消息系统得整合。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">public interface SystemConsumer &#123;</div><div class="line">  void start();</div><div class="line">  void stop();</div><div class="line">  void register(SystemStreamPartition systemStreamPartition, String lastReadOffset);</div><div class="line"></div><div class="line">  List&lt;IncomingMessageEnvelope&gt; poll(</div><div class="line">      Map&lt;SystemStreamPartition, Integer&gt; systemStreamPartitions,</div><div class="line">      long timeout)</div><div class="line">    throws InterruptedException;</div><div class="line">&#125;</div><div class="line"></div><div class="line">public interface SystemProducer &#123;</div><div class="line">  void start();</div><div class="line">  void stop();</div><div class="line">  void register(String source);</div><div class="line"></div><div class="line">  void send(String source, OutgoingMessageEnvelope envelope);</div><div class="line">  void flush(String source);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>特点：</p>
<ul>
<li><p>插件式：开箱即用，Samza实现了对kafka的支持（KafkaSystemConsumer和KafkaSystemProducer）。然而，任何消息总线系统都可以被整合，只要它能提供由Samza所需的接口。</p>
</li>
<li><p>消息类型多样：SystemConsumers和SystemProducers可以读取和写入任何数据类型的消息。<br>  Samza没有规定任何具体的数据模型或序列化格式，具体形式可以由开发人员实现。如果他们只支持byte数组也没有关系——Samza有一个独立的串行化层,将之转化为应用程序代码可以使用对象。</p>
</li>
</ul>
<h3 id="流处理"><a href="#流处理" class="headerlink" title="流处理"></a>流处理</h3><p>如果job从多个输入数据流处处理消息，并且所有输入流消息可用，缺省情况下将在一个循环赛的方式逐个处理。</p>
<p>例如，如果一个job需要处理AdImpressionEvent和AdClickEvent的消息，任务实例的process（）方法被调用，来处理AdImpressionEvent消息，再处理AdClickEvent消息，然后从AdImpressionEvent处理另一个消息，…，并继续在这两者之间交替处理。</p>
<p>如果流处理系统处理中如果一个输入流没有消息，那么流处理系统将跳过这个输入流进行处理另外一个输入流。同时，还会继续检查空输入流是否有新的消息进来。</p>
<h3 id="MessageChooser"><a href="#MessageChooser" class="headerlink" title="MessageChooser"></a>MessageChooser</h3><p>当Samza容器对不同的流分区传入的消息进行处理的时候，它是如何决定要首先处理拿一个？该行为是由一个MessageChooser决定。默认选择器是RoundRobinChooser，但你可以自己实现自定义选择器覆盖它。</p>
<p>实现自己的MessageChooser，你需要实现MessageChooserFactory接口，并在配置文件中设置“task.chooser.class”，并配置您实现的完全类名：</p>
<p>task.chooser.class=com.example.samza.YourMessageChooserFactory</p>
<h3 id="优先输入流"><a href="#优先输入流" class="headerlink" title="优先输入流"></a>优先输入流</h3><p>在一定得时间窗口内，可以让一个输入流得处理比另一个输入流得处理有更高得优先级别，我们可以通过设置输入流得优先级别。例如：samza得job需要处理2个输入流，其中一个输入流由实时系统提供消息，另外一个由批处理系统提供处理消息。在这个案例中，我们将给实时输入流提供更高得优先级。可以使实时输入数据流系统不会产生突然变慢得情况。</p>
<p>例如，我们可以再配置文件中设置如下：</p>
<p>systems.kafka.streams.my-real-time-stream.samza.priority=2<br>systems.kafka.streams.my-batch-stream.samza.priority=1</p>
<h3 id="引导顺序"><a href="#引导顺序" class="headerlink" title="引导顺序"></a>引导顺序</h3><p>略</p>
<h3 id="批处理"><a href="#批处理" class="headerlink" title="批处理"></a>批处理</h3><p>在某些情况下，可以提高每次从多个分区消费多个消息，从而提高消息得处理能力。 Samza支持这种操作模式，被称为批处理。</p>
<p>例如，如果你想读的100条信息从每个流分区行，你可以使用这个配置参数：</p>
<p>task.consumer.batch.size=100</p>
<h2 id="Serialization"><a href="#Serialization" class="headerlink" title="Serialization"></a>Serialization</h2><p>任何消息最终都需要被序列化成字节（通过网络发送或写到本地磁盘），包括读取或写入的流数据或者持久化状态信息存储。序列化和反序列化可能发生在各种地方：</p>
<ol>
<li>在客户端lib库中：例如，从kafka进行生产或者消费支持可插入的序列化。</li>
<li>在任务的执行中：你的process程序将原始字节作为inputs与outputs，并进行任何解析和序列化。</li>
<li>在两者之间: Samza 提供了一层专门进行序列化与反序列化，叫做SERDE层。 </li>
</ol>
<p>你可以使用任何方式做这块工作;samza不会强加任何特定的数据模型或序列化模式。然而，<strong>最合理的做法，通常是使用Samza的SERDE层</strong>。</p>
<h3 id="Serde层类型"><a href="#Serde层类型" class="headerlink" title="Serde层类型"></a>Serde层类型</h3><p>每个serde通过一个工厂类定义。可以通过实现SerdeFactory接口创建自己的序列化器。以下是Samza自带的serde类型的列表：</p>
<table>
<thead>
<tr>
<th>Serde Name</th>
<th>Data Handled</th>
</tr>
</thead>
<tbody>
<tr>
<td>string</td>
<td>UTF-8 strings</td>
</tr>
<tr>
<td>integer</td>
<td>binary-encoded integers</td>
</tr>
<tr>
<td>serializable</td>
<td>Serializable Object Type</td>
</tr>
<tr>
<td>long</td>
<td>long data type</td>
</tr>
<tr>
<td>json</td>
<td>JSON formatted data</td>
</tr>
<tr>
<td>byte</td>
<td>Plain Bytes (effectively no-op) - Useful for Binary Messages</td>
</tr>
<tr>
<td>bytebuffer</td>
<td>Byte Buffer</td>
</tr>
</tbody>
</table>
<p>例如：在配置文件中，定义名为“string”的serde。将用于名为“kafka”的system中对输入流中的key反序列化,并序列化输出流中的key<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">serializers.registry.byte.class=org.apache.samza.serializers.ByteSerdeFactory</div><div class="line">serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory</div><div class="line"></div><div class="line">systems.kafka.samza.msg.serde=byte</div><div class="line">systems.kafka.samza.key.serde=string</div></pre></td></tr></table></figure></p>
<h2 id="Checkpointing"><a href="#Checkpointing" class="headerlink" title="Checkpointing"></a>Checkpointing</h2><p>Samza提供对流的容错性处理：Samza保证信息不会丢失，即使你的job崩溃，或者是一台机器down掉了，再或是网络故障，还是其他什么地方出了问题。为了提供这种保障，Samza期望的输入流系统，要能以满足以下要求：</p>
<ul>
<li>该流可以分成一个或多个分区。每个分区是独立的，分区的副本在多台机器复制（即使一台机器出现故障，流仍然可用）。</li>
<li>每个分区包含在一个固定的顺序的序列消息。每个消息都有一个偏移量，这表明其在该序列的位置。每个分区内消息总是按顺序消费</li>
<li>一个Samza作业可以从消息序列的任何位置开始处理消息。</li>
</ul>
<p>kafka满足上面的要求。samza也可以整合其他的message broker系统。</p>
<p>我们描述一下SamzaContainer的处理场景，每个task实例将会消费一个输入流的一个分区，每个task都会保存每个分区当前处理得offset值。每一次处理一个消息，offset将往前移动一位。</p>
<p>如果SamzaContainer失败，需要重新启动能够恢复到处理失败的地方，为了能够做到这一点，需要SamzaContainer能够保存每个task实例当前处理的offset位置。</p>
<p><img src="https://samza.apache.org/img/0.11/learn/documentation/container/checkpointing.svg" alt="image"></p>
<p>Checkpoint源码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">public interface CheckpointManager &#123;</div><div class="line">  void start();</div><div class="line">  void register(Partition partition);</div><div class="line">  void writeCheckpoint(Partition partition, Checkpoint checkpoint);</div><div class="line">  Checkpoint readLastCheckpoint(Partition partition);</div><div class="line">  void stop();</div><div class="line">&#125;</div><div class="line"></div><div class="line">public class Checkpoint &#123;</div><div class="line">    private final Map&lt;SystemStreamPartition, String&gt; offsets;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="at-least-once处理"><a href="#at-least-once处理" class="headerlink" title="at-least-once处理"></a>at-least-once处理</h3><p>通过event loop，container定期为每一个任务实例checkpoint——即：记录每个partition的当前offset。</p>
<p>container启动时,它寻找最近的checkpoint,开始从该checkpoint记录的partion的offset处消费消息。如果前面的container 意外失败,checkpoint记录的offset不会移动，最近的checkpoint会落后当前topic的offset(即这个job下次再执行时，可能重复process了一些消息，但是不会错过任何消息)</p>
<p>有些场景下，“at-least-once”这种策略满足不了要求。exact once在后续版本会开发。目前只能通过减少写checkpoint的时间间隔来减少这种影响,可能要以性能开销为代价。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">task.commit.ms</div></pre></td></tr></table></figure></p>
<h3 id="配置checkpoint"><a href="#配置checkpoint" class="headerlink" title="配置checkpoint"></a>配置checkpoint</h3><p>提供两种：FileSystemCheckpointManager and KafkaCheckpointManager  </p>
<p>分别将checkpoint存在本地文件中和kafka中<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"># The name of your job determines the name under which checkpoints will be stored</div><div class="line">job.name=example-job</div><div class="line"></div><div class="line"># Define a system called &quot;kafka&quot; for consuming and producing to a Kafka cluster</div><div class="line">systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory</div><div class="line"></div><div class="line"># Declare that we want our job&apos;s checkpoints to be written to Kafka</div><div class="line">task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory</div><div class="line">task.checkpoint.system=kafka</div><div class="line"></div><div class="line"># By default, a checkpoint is written every 60 seconds. You can change this if you like.</div><div class="line">task.commit.ms=60000</div></pre></td></tr></table></figure></p>
<p>samza会向kafka中写入单独的一个topic–<strong>__samza<em>checkpoint</em><job-name>_<job-id></job-id></job-name></strong><br>上述配置的叫：__samza_checkpoint_example-job_1</p>
<h2 id="State-Management"><a href="#State-Management" class="headerlink" title="State Management"></a>State Management</h2><h3 id="状态管理的分类"><a href="#状态管理的分类" class="headerlink" title="状态管理的分类"></a>状态管理的分类</h3><table>
<thead>
<tr>
<th>分类</th>
<th>是否保留state</th>
<th>场景</th>
<th>类比sql</th>
</tr>
</thead>
<tbody>
<tr>
<td>stateless</td>
<td>不需要</td>
<td>一次处理一条消息、基于某些条件过滤消息</td>
<td>select … where…</td>
</tr>
<tr>
<td>stateful</td>
<td>需要</td>
<td>Windowed aggregation(ranking, trend detection, count)、Join (Stream-table, Stream-stream)</td>
<td>aggregation和join</td>
</tr>
</tbody>
</table>
<p>那么，问题来了, 如果保证临时state不丢失?</p>
<h3 id="老的管理任务状态的方法"><a href="#老的管理任务状态的方法" class="headerlink" title="老的管理任务状态的方法"></a>老的管理任务状态的方法</h3><h4 id="In-memory-state-with-checkpointing"><a href="#In-memory-state-with-checkpointing" class="headerlink" title="In-memory state with checkpointing"></a>In-memory state with checkpointing</h4><p>周期性的把task在内存中的数据做checkpoint. S4的状态管理就是这样做的。<br>缺点是当作为state的数据量很大时，每次都完全dump所有数据不切实际，如果用diff又太复杂。</p>
<h4 id="Using-an-external-store"><a href="#Using-an-external-store" class="headerlink" title="Using an external store"></a>Using an external store</h4><p>把状态写进一个外部的数据库或者key-value store中。</p>
<p>这样数据是不会丢了, 但是明显效率会有问题<br>而且会产生对其他系统的依赖性<br>还会影响正确性, 比如当task失败了, 之前的state需要作废,   如何让外部存储上的数据回滚  </p>
<h3 id="Samza管理任务的方法——Local-state-in-Samza"><a href="#Samza管理任务的方法——Local-state-in-Samza" class="headerlink" title="Samza管理任务的方法——Local state in Samza"></a>Samza管理任务的方法——Local state in Samza</h3><p>samza相当于结合上述两处的优点。   </p>
<ul>
<li>local：存整个state，但是存在硬盘上。采用Key-value数据库存储：RocksDB    </li>
<li>external：state的change会生成changelog stream放在kafka上,。<br>这样当有task failover的时候, 可以从kafka上读出change log, 并replay出local state</li>
</ul>
<p><img src="http://samza.apache.org/img/0.10/learn/documentation/container/stateful_job.png" alt="image"></p>
<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"># Use the key-value store implementation for a store called &quot;my-store&quot;</div><div class="line">stores.my-store.factory=org.apache.samza.storage.kv.RocksDbKeyValueStorageEngineFactory</div><div class="line"></div><div class="line"># Use the Kafka topic &quot;my-store-changelog&quot; as the changelog stream for this store.</div><div class="line"># This enables automatic recovery of the store after a failure. If you don&apos;t</div><div class="line"># configure this, no changelog stream will be generated.</div><div class="line">stores.my-store.changelog=kafka.my-store-changelog</div><div class="line"></div><div class="line"># Encode keys and values in the store as UTF-8 strings.</div><div class="line">serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory</div><div class="line">stores.my-store.key.serde=string</div><div class="line">stores.my-store.msg.serde=string</div></pre></td></tr></table></figure>
<h3 id="举例"><a href="#举例" class="headerlink" title="举例"></a>举例</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">public class MyStatefulTask implements StreamTask, InitableTask &#123;</div><div class="line">  private KeyValueStore&lt;String, String&gt; store;</div><div class="line"></div><div class="line">  public void init(Config config, TaskContext context) &#123;</div><div class="line">    this.store = (KeyValueStore&lt;String, String&gt;) context.getStore(&quot;my-store&quot;);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  public void process(IncomingMessageEnvelope envelope,</div><div class="line">                      MessageCollector collector,</div><div class="line">                      TaskCoordinator coordinator) &#123;</div><div class="line">    store.put((String) envelope.getKey(), (String) envelope.getMessage());</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="Windowing"><a href="#Windowing" class="headerlink" title="Windowing"></a>Windowing</h2><p>有些流处理job需要周期执行。  </p>
<h3 id="配置-1"><a href="#配置-1" class="headerlink" title="配置"></a>配置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># Call the window() method every 60 seconds</div><div class="line">task.window.ms=60000</div></pre></td></tr></table></figure>
<h3 id="举例-1"><a href="#举例-1" class="headerlink" title="举例"></a>举例</h3><p>假设你想报告每分钟pv。每当你看到pv事件，需要增加一个计数。每到一分钟,你当前的计数器值发送到输出流，计数器重置为零。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">public class EventCounterTask implements StreamTask, WindowableTask &#123;</div><div class="line"></div><div class="line">  public static final SystemStream OUTPUT_STREAM =</div><div class="line">    new SystemStream(&quot;kafka&quot;, &quot;events-per-minute&quot;);</div><div class="line"></div><div class="line">  private int eventsSeen = 0;</div><div class="line"></div><div class="line">  public void process(IncomingMessageEnvelope envelope,</div><div class="line">                      MessageCollector collector,</div><div class="line">                      TaskCoordinator coordinator) &#123;</div><div class="line">    eventsSeen++;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  public void window(MessageCollector collector,</div><div class="line">                     TaskCoordinator coordinator) &#123;</div><div class="line">    collector.send(new OutgoingMessageEnvelope(OUTPUT_STREAM, eventsSeen));</div><div class="line">    eventsSeen = 0;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><ol>
<li><p>与process一样，不要在windows()之外使用MessageCollector。</p>
</li>
<li><p>Samza使用单线程执行,所以window()调用不能和一个process()同时发生调用。</p>
<ul>
<li>优势：不需要担心线程安全的代码(没有需要同步)</li>
<li>缺点:如果process()方法需要很长时间返回，window()调用可能推迟。</li>
</ul>
</li>
</ol>
<h2 id="Metrix"><a href="#Metrix" class="headerlink" title="Metrix"></a>Metrix</h2><p>当在生产中运行stream process过程,有合理的metrix（度量）来跟踪job的运行是很重要的。Samza提供封装好的metrix库。Samza本身生成消息吞吐量等标准指标,也可以自定义指标。</p>
<h3 id="metrix上报方式"><a href="#metrix上报方式" class="headerlink" title="metrix上报方式"></a>metrix上报方式</h3><ul>
<li>JmxReporterFactory方式（jvm）：<br>每个容器的指标作为JMX mbean，即通过jmx可以监控，见下节。</li>
<li>MetricsSnapshotReporterFactory方式（kafka）：<br>reporter每分钟将指标作为消息发送到kafka输出流。输出流用metrics.reporter.*.stream配置<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"># Define a metrics reporter called &quot;snapshot&quot;, which publishes metrics every 60 seconds.</div><div class="line">metrics.reporters=snapshot</div><div class="line">metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory</div><div class="line"></div><div class="line"># Tell the snapshot reporter to publish to a topic called &quot;metrics&quot;in the &quot;kafka&quot; system.</div><div class="line">metrics.reporter.snapshot.stream=kafka.metrics</div><div class="line"></div><div class="line"># Encode metrics data as JSON.</div><div class="line">serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory</div><div class="line">systems.kafka.streams.metrics.samza.msg.serde=metrics</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="默认metrix内容"><a href="#默认metrix内容" class="headerlink" title="默认metrix内容"></a>默认metrix内容</h3><p>这个配置,job每隔60秒自动发送几个json编码的消息到kafka的“metrics”话题。像这样的消息:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">  &quot;header&quot;: &#123;</div><div class="line">    &quot;container-name&quot;: &quot;samza-container-0&quot;,</div><div class="line">    &quot;host&quot;: &quot;samza-grid-1234.example.com&quot;,</div><div class="line">    &quot;job-id&quot;: &quot;1&quot;,</div><div class="line">    &quot;job-name&quot;: &quot;my-samza-job&quot;,</div><div class="line">    &quot;reset-time&quot;: 1401729000347,</div><div class="line">    &quot;samza-version&quot;: &quot;0.0.1&quot;,</div><div class="line">    &quot;source&quot;: &quot;Partition-2&quot;,</div><div class="line">    &quot;time&quot;: 1401729420566,</div><div class="line">    &quot;version&quot;: &quot;0.0.1&quot;</div><div class="line">  &#125;,</div><div class="line">  &quot;metrics&quot;: &#123;</div><div class="line">    &quot;org.apache.samza.container.TaskInstanceMetrics&quot;: &#123;</div><div class="line">      &quot;commit-calls&quot;: 7,</div><div class="line">      &quot;commit-skipped&quot;: 77948,</div><div class="line">      &quot;kafka-input-topic-offset&quot;: &quot;1606&quot;,</div><div class="line">      &quot;messages-sent&quot;: 985,</div><div class="line">      &quot;process-calls&quot;: 1093,</div><div class="line">      &quot;send-calls&quot;: 985,</div><div class="line">      &quot;send-skipped&quot;: 76970,</div><div class="line">      &quot;window-calls&quot;: 0,</div><div class="line">      &quot;window-skipped&quot;: 77955</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>每个任务实例有一个单独的消息。</p>
<ul>
<li>header包括：job名称、job的ID、task分区。</li>
<li>metrics包括：已处理和发送消息的数量、当前输入流的分区的offset、其他细节。还有上述没有展示出来的：JVM信息(堆大小、垃圾收集信息、线程等),kafka的生产者和消费者的内部指标等</li>
</ul>
<h3 id="自定义metrix内容"><a href="#自定义metrix内容" class="headerlink" title="自定义metrix内容"></a>自定义metrix内容</h3><p>你可以通过MetricsRegistry注册您的自定义指标。需要实现InitableTask流任务,从TaskContext注册表得到指标。  </p>
<p><strong>自定义metrix种类</strong>:  </p>
<ul>
<li>counters（计数器）：当想要跟踪事物发生的频率</li>
<li>仪表(guages)：当想要报告事物的level,比如一个缓冲区的大小</li>
<li>定时器(timer)：当你想要知道代码块花多少时间</li>
</ul>
<p>counter源码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">public class Counter implements Metric &#123;</div><div class="line">    private final String name;</div><div class="line">    private final AtomicLong count;</div><div class="line"></div><div class="line">    public Counter(String name) &#123;</div><div class="line">        this.name = name;</div><div class="line">        this.count = new AtomicLong(0L);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    public long inc() &#123;</div><div class="line">        return this.inc(1L);</div><div class="line">    &#125;</div><div class="line">    .....</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这个简单的例子显示了如何计算你的任务处理的消息数量:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">public class MyJavaStreamTask implements StreamTask, InitableTask &#123;</div><div class="line">  private Counter messageCount;</div><div class="line"></div><div class="line">  public void init(Config config, TaskContext context) &#123;</div><div class="line">    this.messageCount = context</div><div class="line">      .getMetricsRegistry()</div><div class="line">      .newCounter(getClass().getName(), &quot;message-count&quot;);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  public void process(IncomingMessageEnvelope envelope,</div><div class="line">                      MessageCollector collector,</div><div class="line">                      TaskCoordinator coordinator) &#123;</div><div class="line">    messageCount.inc();</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="JMX"><a href="#JMX" class="headerlink" title="JMX"></a>JMX</h2><p>Samza容器和YARN ApplicationMaster默认支持JMX。可以使用JMX管理JVM;例如,可以使用包含在JDK中的jconsole连接到它。</p>
<p>可以告诉Samza发布其内部指标,你和任何自定义指标定义,作为JMX mbean。需要设置以下属性:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"># Define a Samza metrics reporter called &quot;jmx&quot;, which publishes to JMX</div><div class="line">metrics.reporter.jmx.class=org.apache.samza.metrics.reporter.JmxReporterFactory</div><div class="line"></div><div class="line"># Use it (if you have multiple reporters defined, separate them with commas)</div><div class="line">metrics.reporters=jmx</div></pre></td></tr></table></figure></p>
<p>JMX需要配置为使用一个特定的端口,但是在分布式环境中,没有办法提前知道哪些端口可用的机器运行您的容器。因此Samza JMX端口随机选择。如果你需要连接到它,你可以通过容器的日志找到port,报告JMX服务器详细信息如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">2014-06-02 21:50:17 JmxServer [INFO] According to InetAddress.getLocalHost.getHostName we are samza-grid-1234.example.com</div><div class="line">2014-06-02 21:50:17 JmxServer [INFO] Started JmxServer registry port=50214 server port=50215 url=service:jmx:rmi://localhost:50215/jndi/rmi://localhost:50214/jmxrmi</div><div class="line">2014-06-02 21:50:17 JmxServer [INFO] If you are tunneling, you might want to try JmxServer registry port=50214 server port=50215 url=service:jmx:rmi://samza-grid-1234.example.com:50215/jndi/rmi://samza-grid-1234.example.com:50214/jmxrmi</div></pre></td></tr></table></figure></p>
<h2 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h2><p><a href="https://samza.apache.org/learn/documentation/0.10/" target="_blank" rel="external">https://samza.apache.org/learn/documentation/0.10/</a><br><a href="https://github.com/feuyeux/hello-samza/blob/master/doc/0.hello_samza.md" target="_blank" rel="external">https://github.com/feuyeux/hello-samza/blob/master/doc/0.hello_samza.md</a><br><a href="http://wdxtub.com/vault/cc-21.html" target="_blank" rel="external">http://wdxtub.com/vault/cc-21.html</a><br><a href="http://www.infoq.com/cn/articles/linkedin-samza" target="_blank" rel="external">http://www.infoq.com/cn/articles/linkedin-samza</a><br><a href="http://blog.csdn.net/colorant/article/details/12082145" target="_blank" rel="external">http://blog.csdn.net/colorant/article/details/12082145</a><br><a href="https://wyyhzc.gitbooks.io/hadoop2x/content/samzacontainer.html" target="_blank" rel="external">https://wyyhzc.gitbooks.io/hadoop2x/content/samzacontainer.html</a></p>
</the></excerpt>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Samza 3---架构]]></title>
      <url>https://fangyeqing.github.io/2016/11/17/Samza_3---%E6%9E%B6%E6%9E%84/</url>
      <content type="html"><![CDATA[<excerpt in="" index="" |="" 首页摘要="">   

<p>Samza是由以下三层构成：  </p>
<ul>
<li>数据流层（A streaming layer）：分布式消息中间件Kafka  </li>
<li>执行层（An execution layer）：Hadoop资源调度管理系统YARN  </li>
<li>处理层（A progressing layer）：Samza API   </li>
</ul>
<p><img src="https://samza.apache.org/img/0.10/learn/documentation/introduction/samza-ecosystem.png" alt="image"></p>
<a id="more"></a>  
<the rest="" of="" contents="" |="" 余下全文="">  

<h2 id="kafka"><a href="#kafka" class="headerlink" title="kafka"></a>kafka</h2><p>Kafka是一个分布式发布/订阅消息队列系统，它支持<strong>at-least once</strong>通信保障（即系统保证没有信息丢失，但是在某些故障情况下，消费者可能收到超过一条同样的信息）和<strong>高度可用的分区</strong>特性（即使一台机器宕机了，分区依然是可用的）。</p>
<p>每一条数据流被称为一个topic。每一个话题都在多台被称作broker的机器上进行分区和复制。当一个生产者发送一条消息给一个话题，它会提供一个key，这个key被用来决定这条消息应该被发送到哪一个分区。生产者发送信息而Kafka的broker则接收和存储它们。Kafka的消费者能通过在一个话题的所有分区上订阅消息来读取消息。</p>
<p>Kafka有一些有趣的特点：</p>
<ul>
<li>同一个key的所有消息都被划分到同一个分区，这就意味着如果你想要读到一个特定用户的所有消息，你只要从包含这个用户id的分区读取即可，而不是整个topic（假设把用户id用作key）</li>
<li>一个topic的分区是按顺序到达的一序列消息，所以你可以通过单调递增偏移量offset来引用任何消息（就好比放一个索引到一个数组里）；这也意味着broker不需要跟踪被一个特定的消费者读取的消息，为什么呢？因为消费者保存了消息的偏移量offset能够跟踪到它。然后我们知道的是带着一个比当前偏移量小的消息是已经被处理过的，而每一个带着更大偏移量的消息还没有被处理过。</li>
</ul>
<h2 id="YARN"><a href="#YARN" class="headerlink" title="YARN"></a>YARN</h2><p>YARN有三个组成部分：资源管理器（ResourceManager）、节点管理器（NodeManager）和应用管理器（ApplicationMaster）。</p>
<ul>
<li>NodeManager：在一个YARN网格里，每一台机器上都跑着NodeManager，它负责在所在的机器上启动进程。</li>
<li>ResourceManager与所有的NodeMananger交互告诉它们跑什么应用，反过来NodeManager也会告诉ResourceManager它们希望什么时间在集群里跑这些东东。</li>
<li>ApplicationMaster让特定应用的代码跑在YARN集群上，它负责管理应用的负载、容器（通常是UNIX进程），并且当其中一个容器失败时发出通知。</li>
</ul>
<p>Samza提供了一个YARN ApplicationMaster和一个开箱即用的YARN Job运行器。如图所示（不同的颜色表示不同的机器）</p>
<p><img src="https://samza.apache.org/img/0.10/learn/documentation/introduction/samza-yarn-kafka-integration.png" alt="image"></p>
<p>Samza的客户端告诉YARN的RM（ResourceManager，以下简称RM）运行一个新的Job，RM会告诉YARN的一个NodeManager（简称NM）为Samza的ApplicationMaster（AM）在集群里分配空间。一旦NM分配了空间，就会启动这个Samza的AM。AM开始后，它会向RM请求运行SamzaContainers所需的YARN containers。RM和NMs一起为containers分配空间。一旦空间被分配，NMs就会开启Samza containers。  </p>
<p>YARN启动并且监控一个或者多个SamzaContainers，并且你的处理逻辑代码（使用StreamTask API）在这些容器里运行。这些Samza 流任务的输入和输出都来自Kafka的Brokers（通常他们都是作为YARN NMs位于同台机器）</p>
<p>通过对topic的分区，将数据流处理拆解到任务中以及在多台机器上并行执行任务，使得Samza具有很高的消息吞吐量。通过结合YARN和Kafka，Samza实现了高容错：如果一个进程或者机器失败，它会自动在另一台机器上重启它并且继续从消息终端的地方开始处理，这些都是自动化的。</p>
<h2 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h2><p><a href="https://samza.apache.org/learn/documentation/0.10/" target="_blank" rel="external">https://samza.apache.org/learn/documentation/0.10/</a><br><a href="https://github.com/feuyeux/hello-samza/blob/master/doc/0.hello_samza.md" target="_blank" rel="external">https://github.com/feuyeux/hello-samza/blob/master/doc/0.hello_samza.md</a><br><a href="http://wdxtub.com/vault/cc-21.html" target="_blank" rel="external">http://wdxtub.com/vault/cc-21.html</a><br><a href="http://www.infoq.com/cn/articles/linkedin-samza" target="_blank" rel="external">http://www.infoq.com/cn/articles/linkedin-samza</a><br><a href="http://blog.csdn.net/colorant/article/details/12082145" target="_blank" rel="external">http://blog.csdn.net/colorant/article/details/12082145</a><br><a href="https://wyyhzc.gitbooks.io/hadoop2x/content/samzacontainer.html" target="_blank" rel="external">https://wyyhzc.gitbooks.io/hadoop2x/content/samzacontainer.html</a></p>
</the></excerpt>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Samza 2---基本概念]]></title>
      <url>https://fangyeqing.github.io/2016/11/17/Samza_2---%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</url>
      <content type="html"><![CDATA[<excerpt in="" index="" |="" 首页摘要="">   

<p>samza是一个分布式的流式数据处理框架（streaming processing），它是基于Kafka消息队列来实现类实时的流式数据处理的。</p>
<h2 id="为什么需要samza"><a href="#为什么需要samza" class="headerlink" title="为什么需要samza"></a>为什么需要samza</h2><p>kafka作为一个分布式的消息队列系统，已经实现了流式处理框架底层的许多核心基础架构，把消息串联流动起来就是Streaming了。</p>
<p>但是要构建一个可用的流式数据处理框架，还是有许多事情要做。例如生产者和消费者进程的管理，作业调度和容错处理，辅助工具和监控管理手段，更友好方便的用户接口等等，本质上说，Samza是在消息队列系统上的更高层的抽象，是一种应用流式处理框架在消息队列系统上的一种应用模式的实现。  </p>
<a id="more"></a>  
<p><the rest="" of="" contents="" |="" 余下全文="">  </the></p>
<h3 id="需要解决的问题"><a href="#需要解决的问题" class="headerlink" title="需要解决的问题"></a>需要解决的问题</h3><p>比如分区：如何划分流？如何划分处理器？如何管理状态，其中状态本质上是指在处理器中维护的介于消息之间的东西，或者如果每次有消息到达的时候，计数器就会加1，那么它也可以是像总数这样的东西。如何重新处理？</p>
<p>至于失败语义，我们会得到至少一次，或者至多一次，或者恰好一次消息，也有不确定性。如果流处理器与另一个系统交互，无论它是个数据库，还是依赖于时间或者消息的顺序，如何处理那些真正决定最终输出结果的数据？</p>
<h2 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h2><p>Samza的一个job的基本处理流程是一个用户任务从一个或多个输入流中读取数据，再输出到一个或多个输出流中，具体映射到kafka上就是从一个或多个topic读入数据，再写出到另一个或多个topic中去。多个job串联起来就完成了流式的数据处理流程。</p>
<p>这种模式其实有点像MapReduce的过程，stream输入部分由kafka的partition决定了分区和task数目，类似于一个Map过程，输出时由用户task指定topic和分区（或者框架自动由Key决定分区），这相当于一次shuffle的过程，下一个job读取新的stream时，可以认为是一个reduce，也可以认为是下一个map过程的开始。</p>
<p>不同之处在于job之间的串联无需等待上一个job的结束，类实时的消息分发机制决定了整个串联的job是连续不间断的，亦即流式的。</p>
<h2 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h2><p>Samza是一个流式计算框架，它有以下特性：</p>
<ul>
<li>简单的API：和绝大多数低层次消息系统API不同，相比MapReduce，Samza提供了一个非常简单的“基于回调（callback-based）”的消息处理API</li>
<li>管理状态：Samza管理快照和流处理器的状态恢复。当处理器重启，Samza恢复其状态一致的快照。Samza的建立是为了处理大量的状态</li>
<li>容错性：当集群中有一台机器宕机了，基于Yarn管理的Samza会立即将你的任务导向另一台机器；</li>
<li>持久性：Samza通过Kafka保证消息按顺序写入对应分区，并且不会丢失消息；</li>
<li>扩展性：Samza在每一层都做了分区和分布。Kafka提供了顺序的、分区、可复制的、容错的流。YARN则为Samza的运行提供了一个分布式环境</li>
<li>可插拔：虽然Samza在Kafka和YARN的外部工作，但是Samza提供了可以让你在其它消息系统和执行环境里运行的可插拔的API</li>
<li>处理器隔离：运行在YARN上的Samza同样支持Hadoop安全模型以及通过linux CGroups进行资源隔离</li>
</ul>
<p>Samza区别于其他框架的几个方面：</p>
<ul>
<li>Samza支持局部状态的容错。状态自己作为一个流被构造。如果因为机器宕机本地状态丢失，那么状态流会回放重新存储它</li>
<li>流是有序、分区的、可回放的并且是容错的</li>
<li>YARN用来处理隔离、安全和容错</li>
<li>任务之间是解耦的：如果有一个任务慢了并且造成了消息的积压，系统其它部分不会受到影响；</li>
</ul>
<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><h3 id="流（Streams）"><a href="#流（Streams）" class="headerlink" title="流（Streams）"></a>流（Streams）</h3><p>Samza处理流。流是由一定数量的类型或类别相似的不可变消息组成。  </p>
<ul>
<li>kafka里，流是一个topic（话题） </li>
<li>数据库里，我们可以通过消费从一个表里更新操作读取一个流  </li>
<li>hadoop里，我们可能跟踪在hdfs上的一个目录下的文件</li>
</ul>
<h3 id="作业（job）"><a href="#作业（job）" class="headerlink" title="作业（job）"></a>作业（job）</h3><p>Samza的jobs 是将输入流进行逻辑处理，然后转化成输出流的程序。</p>
<p>为了扩展流处理器的吞吐量，stream拆分成：分区Partitions</p>
<blockquote>
<p>Streams–&gt;Partitions</p>
</blockquote>
<p>job拆分更小的并行单元：任务Tasks</p>
<blockquote>
<p>job–&gt;tasks</p>
</blockquote>
<h3 id="分区（Partitions）"><a href="#分区（Partitions）" class="headerlink" title="分区（Partitions）"></a>分区（Partitions）</h3><p>每个流都被分割成一个或多个分区，并且在流里的每一个分区都总是一个有序的消息序列。每个消息在这个序列里有一个被叫做offset（中文称它为偏移量），它在每一个分区里都是唯一的。这个偏移量可以是一个连续的整数、字节偏移量或者字符串，这取决于底层的系统实现了。</p>
<p>当有一个消息加入到流中，它只会追加到流的分区中的一个。这个消息通过写入者带着一个被选择的key分配到它对应的分区中。举个例子，如果用户id被用作key，那么所有和用户id相关的消息都应该追加到这个分区中。<br><img src="https://samza.apache.org/img/0.10/learn/documentation/introduction/stream.png" alt="image"></p>
<h3 id="任务（task）"><a href="#任务（task）" class="headerlink" title="任务（task）"></a>任务（task）</h3><p>一个Job通过把他分割成多个任务Task进行扩展。每个任务Task消费来自一个Partitions的数据。</p>
<p>按照消息的偏移，一个任务按序处理来自它的输入分区的消息。分区之间没有定义顺序，这就允许每一个任务独立执行。YARN调度器负责分发任务给一台机器，所以作为一个整体的工作Job可以分配到多个机器并行执行。</p>
<p>在一个Job中任务Task的数量是由输入分区决定的（也就是说任务数目不能超过分区数目，否则就会存在没有输入的任务）。可是，你能改变分配给Job的计算资源（比如内存、cpu核数等）去满足job的需要，可以参考下面关于container的介绍。</p>
<p>另外一个值得注意的是分配给task的分区的任务绝不会改变：如果有一个任务在一台失效的机器上，这个task会被在其它地方重启，仍然会消费同一个流的分区。</p>
<p><img src="https://samza.apache.org/img/0.10/learn/documentation/introduction/job_detail.png" alt="image"></p>
<h3 id="Dataflow-Graphs"><a href="#Dataflow-Graphs" class="headerlink" title="Dataflow Graphs"></a>Dataflow Graphs</h3><p>我们能组合多个Jobs去创建一个数据流图（DAG 有向无环图），其中节点表示包含数据的流，而边则是进行数据传输。这个组合纯粹是通过Jobs作为输入和输出的流来完成。这些Jobs也是解耦的：他们不需要基于相同的代码库，并且添加、删除或者重启一个下游任务不会影响上游的任务。<br><img src="https://samza.apache.org/img/0.10/learn/documentation/introduction/dag.png" alt="image"></p>
<h3 id="Containers"><a href="#Containers" class="headerlink" title="Containers"></a>Containers</h3><p>分区Partitions和任务Tasks都是并行的逻辑单元。</p>
<p>Containers是物理的并行单元，并且一个容器本质上是一个Unix进程（或者Linux cgroup）。</p>
<p>每个容器跑着一个或多个Tasks。Tasks的数量是从输入的分区数自动确定和固定下来的，但是容器的数量（CPU、内存资源）是在运行时用户设定的并且能在任何时刻改变。</p>
<h3 id="其他概念"><a href="#其他概念" class="headerlink" title="其他概念"></a>其他概念</h3><ul>
<li>容器——分区和任务是逻辑并行单元，而容器是物理并行单元。每个容器是一个运行一个或多个任务的Unix进程（或者Linux cgroup）。</li>
<li>TaskRunner——TaskRunner是Samza的流处理容器。它负责启动、执行以及关闭一个或多个StreamTask实例。</li>
<li>“检查点（Checkpointing）”——检查点通常用于故障恢复。如果一个taskrunner由于某种原因宕掉了（比如，硬件故障），当重新启动时，它应该使用最后离开时的消息——这是通过检查点实现的。</li>
<li>状态管理——需要在不同的消息处理之间传递的数据称之为状态——它可以是保存一个总数那样简单的东西，也可以是复杂得多的东西。Samza允许任务维持一种持久可变且可查询的状态，而且，它与每个任务在物理上处于同一位置。状态需要具备高可用性：如果出现任务失败的情况，它可以在任务故障转移到另一台机器时还原。</li>
</ul>
<h2 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h2><p><a href="https://samza.apache.org/learn/documentation/0.10/" target="_blank" rel="external">https://samza.apache.org/learn/documentation/0.10/</a><br><a href="https://github.com/feuyeux/hello-samza/blob/master/doc/0.hello_samza.md" target="_blank" rel="external">https://github.com/feuyeux/hello-samza/blob/master/doc/0.hello_samza.md</a><br><a href="http://wdxtub.com/vault/cc-21.html" target="_blank" rel="external">http://wdxtub.com/vault/cc-21.html</a><br><a href="http://www.infoq.com/cn/articles/linkedin-samza" target="_blank" rel="external">http://www.infoq.com/cn/articles/linkedin-samza</a><br><a href="http://blog.csdn.net/colorant/article/details/12082145" target="_blank" rel="external">http://blog.csdn.net/colorant/article/details/12082145</a><br><a href="https://wyyhzc.gitbooks.io/hadoop2x/content/samzacontainer.html" target="_blank" rel="external">https://wyyhzc.gitbooks.io/hadoop2x/content/samzacontainer.html</a></p>
</excerpt>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Samza1---Hello Samza]]></title>
      <url>https://fangyeqing.github.io/2016/11/17/Samza_1---Hello_Samza/</url>
      <content type="html"><![CDATA[<excerpt in="" index="" |="" 首页摘要="">   

<p><a href="http://samza.apache.org/startup/hello-samza/0.10/" target="_blank" rel="external">hello-samza</a>是官方给的例子，包括一整套运行环境，包括zookeeper、kafka、yarn、samza。虽然例子看起来很容易，但是跑起来感觉全是坑，毕竟用的公司的集群，没有root权限，然后例子给的都是国外的地址，访问速度很慢或者根本被墙了。想say hello不容易！<br><a id="more"></a>   </p>
<the rest="" of="" contents="" |="" 余下全文=""> 

<p>安装和配置Apache-Samza，需要jdk1.7+、maven2的环境</p>
<h2 id="下载源码"><a href="#下载源码" class="headerlink" title="下载源码"></a>下载源码</h2><p>官方给的<a href="https://git.apache.org/samza-hello-samza.git可能连接不上，换了一个" target="_blank" rel="external">https://git.apache.org/samza-hello-samza.git可能连接不上，换了一个</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">git clone https://github.com/apache/samza-hello-samza.git hello-samza</div><div class="line">cd hello-samza/</div></pre></td></tr></table></figure></p>
<h2 id="运行grid"><a href="#运行grid" class="headerlink" title="运行grid"></a>运行grid</h2><p>下载、安装相关系统<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bin/grid bootstrap</div></pre></td></tr></table></figure></p>
<p>虽然只有一句话，但是会执行如下，会下载并安装samza，zookeeper，yarn，kafka<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">stop all           #停止yarn|kafka|zookeeper</div><div class="line">install all        #安装</div><div class="line">start all          #启动</div></pre></td></tr></table></figure></p>
<p>可能出现很多问题</p>
<h4 id="出现问题："><a href="#出现问题：" class="headerlink" title="出现问题："></a>出现问题：</h4><ol>
<li>公司开发机，没有root权限，会有错误：  <blockquote>
<p>Caused by: java.io.IOException: No locks available</p>
</blockquote>
</li>
</ol>
<p>gradle的默认本地仓库是home下的 如~/.gradle<br>需要修改gradle和samza目录，在用户的home目录下建立软连接：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ln -s /disk1/fangyq/gradle ~/.gradle</div><div class="line">ln -s /disk1/fangyq/samza ~/.samza</div></pre></td></tr></table></figure></p>
<ol>
<li>改完继续执行bin/grid bootstrap,会出现超时，</li>
</ol>
<blockquote>
<p>fatal: unable to connect to git.apache.org:<br>git.apache.org[0: 54.84.58.65]: errno=Connection timed out</p>
</blockquote>
<p>修改bin/grid文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">git clone git://git.apache.org/samza.git                 #原地址</div><div class="line">git clone https://github.com/apache/samza.git            #现地址</div></pre></td></tr></table></figure></p>
<p>继续执行bin/grid bootstrap，下载、安装持续了很久。<br>再给我一次机会，肯定会改下载地址，下面自带的地址太慢了，hadoop的用了一个多小时。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">DOWNLOAD_KAFKA=http://www.us.apache.org/dist/kafka/0.8.2.1/kafka_2.10-0.8.2.1.tgz</div><div class="line">DOWNLOAD_YARN=https://archive.apache.org/dist/hadoop/common/hadoop-2.6.1/hadoop-2.6.1.tar.gz</div><div class="line">DOWNLOAD_ZOOKEEPER=http://archive.apache.org/dist/zookeeper/zookeeper-3.4.3/zookeeper-3.4.3.tar.gz</div></pre></td></tr></table></figure></p>
<p>安装完后，在deploy目录下有kafka，yarn，zookeeper的系统。<br>在自己建立软连接的目录下有samza。</p>
<p>查看是否安装成功：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">jps</div><div class="line"></div><div class="line">50500 NodeManager</div><div class="line">43877 Kafka</div><div class="line">56215 Jps</div><div class="line">50439 ResourceManager</div><div class="line">43721 QuorumPeerMain</div></pre></td></tr></table></figure></p>
<p>还可以通过浏览器访问来查看YARN UI：<br><a href="http://localhost:8088" target="_blank" rel="external">http://localhost:8088</a>   </p>
<h2 id="利用maven打包并解压"><a href="#利用maven打包并解压" class="headerlink" title="利用maven打包并解压"></a>利用maven打包并解压</h2><p>打包，要等很久。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mvn clean package</div></pre></td></tr></table></figure></p>
<h4 id="出现问题：-1"><a href="#出现问题：-1" class="headerlink" title="出现问题："></a>出现问题：</h4><blockquote>
<p>Too many files with unapproved license samza</p>
</blockquote>
<p>修改之后继续打包：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mvn -Drat.ignoreErrors=true  clean package</div></pre></td></tr></table></figure></p>
<p>解压：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mkdir -p deploy/samza</div><div class="line">tar -xvf target/hello-samza-0.10.1-dist.tar.gz -C deploy/samza</div></pre></td></tr></table></figure></p>
<h2 id="运行samza-job："><a href="#运行samza-job：" class="headerlink" title="运行samza job："></a>运行samza job：</h2><h3 id="数据获取job"><a href="#数据获取job" class="headerlink" title="数据获取job"></a>数据获取job</h3><p>该job是从在线的wikimedia实时消费数据，作为kafka的wikipedia-raw这个topic的producer。  </p>
<p>先看下将要运行的示例的input<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">less deploy/samza/config/wikipedia-feed.properties</div></pre></td></tr></table></figure></p>
<p>测试一下是否能连接上<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">telnet irc.wikimedia.org 6667</div></pre></td></tr></table></figure></p>
<ul>
<li><p>如果有响应</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">deploy/samza/bin/run-job.sh --config-factory=org.apache.samza.config.factories.PropertiesConfigFactory --config-path=file://$PWD/deploy/samza/config/wikipedia-feed.properties</div></pre></td></tr></table></figure>
</li>
<li><p>如果没有响应。只能使用本地的数据，作为kafka的producer：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">bin/produce-wikipedia-raw-data.sh</div><div class="line"></div><div class="line">#或者可以修改kafka-broker地址和zookeeper地址</div><div class="line">bin/produce-wikipedia-raw-data.sh -b yourKafkaBrokerAddress -z yourZookeeperAddress</div></pre></td></tr></table></figure>
</li>
</ul>
<p>测试是否成功，开一个消费者实时消费wikipedia-raw<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">deploy/kafka/bin/kafka-console-consumer.sh  --zookeeper localhost:2181 --topic wikipedia-raw</div></pre></td></tr></table></figure></p>
<p>将会有实时的消息输出<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&#123;&quot;raw&quot;:&quot;[[Paul Henreid]]  http://en.wikipedia.org/w/index.php?diff=606587718&amp;oldid=603654278 * .48.142.193 * (-1) original name Wasel, not Wassel - see ref &amp; ext link&quot;,&quot;time&quot;:1398926962623,&quot;source&quot;:&quot;rc-pmtpa&quot;,&quot;channel&quot;:&quot;#en.wikipedia&quot;&#125;</div></pre></td></tr></table></figure></p>
<h3 id="数据统计job"><a href="#数据统计job" class="headerlink" title="数据统计job"></a>数据统计job</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">deploy/samza/bin/run-job.sh --config-factory=org.apache.samza.config.factories.PropertiesConfigFactory --config-path=file://$PWD/deploy/samza/config/wikipedia-parser.properties</div><div class="line"></div><div class="line">deploy/samza/bin/run-job.sh --config-factory=org.apache.samza.config.factories.PropertiesConfigFactory --config-path=file://$PWD/deploy/samza/config/wikipedia-stats.properties</div></pre></td></tr></table></figure>
<p>前面的wikipedia-parser负责解析wikipedia-raw中消息，从而抽取edit的大小,修改者等信息</p>
<blockquote>
<p>wikipedia-raw–&gt;wikipedia-edits</p>
</blockquote>
<p>后面的wikipedia-stats负责统计来自wikipedia-edits中的消息，计算消息的个数。而后通过一个10秒钟长的滑动时间窗口将统计个数发送到kafka的wikipedia-statstopic中</p>
<blockquote>
<p>wikipedia-edits–&gt;wikipedia-statstopic  </p>
</blockquote>
<p>可以查看结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">deploy/kafka/bin/kafka-console-consumer.sh  --zookeeper localhost:2181 --topic wikipedia-edits</div><div class="line"></div><div class="line">deploy/kafka/bin/kafka-console-consumer.sh  --zookeeper localhost:2181 --topic wikipedia-stats</div></pre></td></tr></table></figure></p>
<p>最后的输出结果类似：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&#123;&quot;is-minor&quot;:948,&quot;unique-titles&quot;:763,&quot;is-talk&quot;:90,&quot;is-bot-edit&quot;:513,&quot;bytes-added&quot;:350253,&quot;edits&quot;:2790,&quot;is-new&quot;:135,&quot;edits-all-time&quot;:3720,&quot;is-unpatrolled&quot;:78&#125;</div><div class="line">&#123;&quot;is-minor&quot;:632,&quot;unique-titles&quot;:763,&quot;is-talk&quot;:60,&quot;is-bot-edit&quot;:342,&quot;bytes-added&quot;:233502,&quot;edits&quot;:1860,&quot;is-new&quot;:90,&quot;edits-all-time&quot;:5580,&quot;is-unpatrolled&quot;:52&#125;</div></pre></td></tr></table></figure></p>
<h2 id="关闭samza"><a href="#关闭samza" class="headerlink" title="关闭samza"></a>关闭samza</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bin/grid stop all</div></pre></td></tr></table></figure>
<h2 id="开启samza"><a href="#开启samza" class="headerlink" title="开启samza"></a>开启samza</h2><p>如果不是首次，则通过之前的bootstrap已经下载了相应的东西，只需要start<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bin/grid start all</div></pre></td></tr></table></figure></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://blog.jassassin.com/2015/04/30/samza/hello-samza/" target="_blank" rel="external">http://blog.jassassin.com/2015/04/30/samza/hello-samza/</a><br><a href="http://samza.apache.org/startup/hello-samza/0.10/" target="_blank" rel="external">http://samza.apache.org/startup/hello-samza/0.10/</a></p>
</the></excerpt>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Java程序员学python3.0--面向对象篇]]></title>
      <url>https://fangyeqing.github.io/2016/11/06/Java%E7%A8%8B%E5%BA%8F%E5%91%98%E5%AD%A6python3.0--%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%AF%87/</url>
      <content type="html"><![CDATA[<excerpt in="" index="" |="" 首页摘要="">  

<p>参考廖雪峰大神的<a href="http://www.liaoxuefeng.com/" target="_blank" rel="external">python3.0教程</a>，适用于有一定基础的Java程序员，会对比着Java来学习python。代码在PyCharm中运行通过，地址为<a href="https://github.com/fangyeqing/hello-python/tree/master" target="_blank" rel="external">github</a>。本篇主要介绍python面向对象编程相关的知识，在上一篇介绍了python的一些基础知识，包括安装运行、基础语法、函数、高级特性、函数式编程、模块等。</p>
<h2 id="面向对象编程"><a href="#面向对象编程" class="headerlink" title="面向对象编程"></a>面向对象编程</h2><h3 id="类和对象"><a href="#类和对象" class="headerlink" title="类和对象"></a>类和对象</h3><ul>
<li>定义类语法：class ClassName(superClass/object),其中括号里为父类，没有的话写object</li>
<li>类中定义的函数第一个参数永远是实例变量self，调用时，不用传递该参数。</li>
<li>允许对实例动态增加变量和方法，类的不同实例拥有的变量和方法可能不同</li>
<li>允许对类动态添加方法，添加后对象都能访问</li>
<li>类动态添加属性限制<strong>slots</strong>：定义一个特殊的<strong>slots</strong>变量，来限制该class实例能动态添加的属性。仅对当前类实例起作用，子类不起作用</li>
</ul>
<a id="more"></a>  
<p><the rest="" of="" contents="" |="" 余下全文=""><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">from types import MethodType</div><div class="line"></div><div class="line">class Student(object):</div><div class="line">    def __init__(self, name, score):</div><div class="line">        self.name = name</div><div class="line">        self.score = score</div><div class="line"></div><div class="line">    def print_score(self):</div><div class="line">        print(&apos;%s: %s&apos; % (self.name, self.score))</div><div class="line"># 对象动态添加属性</div><div class="line">bart = Student(&apos;Bart Simpson&apos;, 59)</div><div class="line">bart.age = 8</div><div class="line">bart.print_score()</div><div class="line">print(bart.age)</div><div class="line"># 对象动态添加方法</div><div class="line">def set_age(self, age):</div><div class="line">    self.age = age</div><div class="line">lisa = Student(&apos;Lisa Simpson&apos;, 87)</div><div class="line">lisa.set_age = MethodType(set_age, lisa)</div><div class="line">lisa.set_age(8)</div><div class="line">print(lisa.age)</div><div class="line"># 给类动态添加方法</div><div class="line">def set_score(self, score):</div><div class="line">    self.score = score</div><div class="line">Student.set_score = set_score</div><div class="line">lisa.set_score(10)</div><div class="line">bart.set_score(10)</div><div class="line">print(lisa.score)</div></pre></td></tr></table></figure></the></p>
<h3 id="访问限制"><a href="#访问限制" class="headerlink" title="访问限制"></a>访问限制</h3><p>私有变量(private):两个下划线开头<strong>xxx，跟java一样可以有set和get方法。区别于两个下划线开头和结尾的特殊变量</strong>xxx__<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">class Student(object):</div><div class="line">    def __init__(self, name, score):</div><div class="line">        self.__name = name</div><div class="line">        self.__score = score</div><div class="line">    def print_score(self):</div><div class="line">        print(&apos;%s: %s&apos; % (self.__name, self.__score))</div><div class="line">bart = Student(&apos;Bart Simpson&apos;, 98)</div><div class="line">bart.print_score()</div></pre></td></tr></table></figure></p>
<h3 id="继承和多态"><a href="#继承和多态" class="headerlink" title="继承和多态"></a>继承和多态</h3><ul>
<li>与java相同点：继承父类的所有功能，支持方法覆盖</li>
<li>与java不同点：<ul>
<li>Python动态语言–Java静态语言。下例：只需要保证传入的对象有一个run()方法就可以了，不需要是Animal类</li>
<li>Python支持多重继承，可以同时继承多个类。而Java的继承extends只能去继承一个类<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"># 父类-动物</div><div class="line">class Animal(object):</div><div class="line">    def run(self):</div><div class="line">        print(&apos;Animal is running...&apos;)</div><div class="line"># 父类-尖叫</div><div class="line">class MixlnBark(object):</div><div class="line">    def bark(self):</div><div class="line">        print(&quot;Barking....&quot;);</div><div class="line"># 方法：依赖于run方法</div><div class="line">def run_twice(animal):</div><div class="line">    animal.run()</div><div class="line">    animal.run()</div><div class="line"># 多重继承示例</div><div class="line">class Dog(Animal,MixlnBark):</div><div class="line">    def run(self):</div><div class="line">        print(&quot;Dog is Running&quot;);</div><div class="line">dog = Dog();</div><div class="line">dog.run()</div><div class="line">dog.bark()</div><div class="line"># 动态语言示例</div><div class="line">class Timer(object):</div><div class="line">    def run(self):</div><div class="line">        print(&apos;Start...&apos;)</div><div class="line">run_twice(Dog())</div><div class="line">run_twice(Timer())</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h3 id="获取对象信息"><a href="#获取对象信息" class="headerlink" title="获取对象信息"></a>获取对象信息</h3><ul>
<li>type(对象)：获取类型</li>
<li>isinstance(判断的实例,类型1,类型2…)：判断实例是否是这几种类型</li>
<li>dir(对象):获取对象所有属性和方法。配合以下方法，直接操作一个对象的状态，通常先通过has判断对象有没有该方法，有的话执行：<ul>
<li>hasattr(对象,’属性名/方法名’)</li>
<li>getattr(对象,’属性名/方法名’)</li>
<li>setattr(对象,’属性名/方法名’,set值)<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">import types</div><div class="line"># type</div><div class="line">print(type(abs)==types.BuiltinFunctionType)</div><div class="line"># isinstance</div><div class="line">print(isinstance(&apos;a&apos;, str))</div><div class="line">print(isinstance([1, 2, 3], (list, tuple)))</div><div class="line"># dir</div><div class="line">print(dir(&apos;abc&apos;))</div><div class="line">print(hasattr(&apos;abc&apos;, &apos;__init__&apos;))</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h3 id="类属性和实例属性"><a href="#类属性和实例属性" class="headerlink" title="类属性和实例属性"></a>类属性和实例属性</h3><p>类属性就类似于java中的类的静态属性，static<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"># 学生</div><div class="line">class Student(object):</div><div class="line">    # 用于记录已经注册学生数</div><div class="line">    student_number = 0</div><div class="line"></div><div class="line">    def __init__(self, name):</div><div class="line">        self.name = name</div><div class="line"># 注册一个学生:注册必填项名字，选填项利用关键字参数传递。注册完成，学生数+1</div><div class="line">def register(name, **kw):</div><div class="line">    a = Student(name)</div><div class="line">    for k, v in kw.items():</div><div class="line">        setattr(a, k, v)</div><div class="line">    Student.student_number += 1</div><div class="line">    return a</div><div class="line">bob = register(&apos;Bob&apos;, score=90)</div><div class="line">ah = register(&apos;Ah&apos;, age=8)</div><div class="line"></div><div class="line">print(getattr(bob, &apos;score&apos;))</div><div class="line">print(getattr(ah, &apos;age&apos;))</div><div class="line">print(Student.student_number)</div></pre></td></tr></table></figure></p>
<h2 id="面向对象高级编程"><a href="#面向对象高级编程" class="headerlink" title="面向对象高级编程"></a>面向对象高级编程</h2><h3 id="检查参数与-property"><a href="#检查参数与-property" class="headerlink" title="检查参数与@property"></a>检查参数与@property</h3><h3 id="定制类"><a href="#定制类" class="headerlink" title="定制类"></a>定制类</h3><p><strong>xxx</strong>前后两个下划线的函数帮助定制类，重写这些方法之后，可以实现一些功能。</p>
<ul>
<li><strong>str</strong>:类似于java的toString()</li>
<li><strong>getattr</strong>:获取属性,可以用于防止没有此属性,也可以用于链式调用</li>
<li><p><strong>call</strong>:相当于直接运行一个对象，不需要方法，这个方法相当于默认方法。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line">class Student(object):</div><div class="line">    def __init__(self, name):</div><div class="line">        self.name = name</div><div class="line"></div><div class="line">    def __str__(self):</div><div class="line">        return &apos;Student object (name: %s)&apos; % self.name</div><div class="line"></div><div class="line">    def __getattr__(self, attr):</div><div class="line">        if attr == &apos;score&apos;:</div><div class="line">            return 99</div><div class="line">        elif attr == &apos;age&apos;:</div><div class="line">            return lambda: 25</div><div class="line">        else:</div><div class="line">            raise AttributeError(&apos;\&apos;Student\&apos; object has no attribute \&apos;%s\&apos;&apos; % attr)</div><div class="line"></div><div class="line">    def __call__(self):</div><div class="line">        print(&apos;My name is %s.&apos; % self.name)</div><div class="line">stu = Student(&apos;Michael&apos;)</div><div class="line">print(stu)</div><div class="line">print(stu.score)</div><div class="line">print(stu.age)</div><div class="line"># print(stu.phone)</div><div class="line">print(stu())</div><div class="line">callable(stu)</div><div class="line"></div><div class="line"># __getattr__应用:链式调用</div><div class="line">class Chain(object):</div><div class="line">    def __init__(self, path=&apos;&apos;):</div><div class="line">        self._path = path</div><div class="line">    def __getattr__(self, path):</div><div class="line">        return Chain(&apos;%s/%s&apos; % (self._path, path))</div><div class="line">    def __str__(self):</div><div class="line">        return self._path</div><div class="line">print(Chain().status.user.timeline.list)</div></pre></td></tr></table></figure>
</li>
<li><p><strong>iter</strong><br>如果一个类想被用于for … in循环，类似list或tuple那样，就必须实现一个<strong>iter</strong>()方法，该方法返回一个迭代对象，然后，Python的for循环就会不断调用该迭代对象的<strong>next</strong>()方法拿到循环的下一个值，直到遇到StopIteration错误时退出循环</p>
</li>
<li><strong>getitem</strong><br>要表现得像list那样按照下标取出元素，需要实现<strong>getitem</strong>()方法<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"># __iter__和__next__:将斐波那契数列改成可以for循环的形式</div><div class="line"># __getitem__:使其实现取元素的功能</div><div class="line">class Fib(object):</div><div class="line">    def __init__(self):</div><div class="line">        self.a, self.b = 0, 1 # 初始化两个计数器a，b</div><div class="line"></div><div class="line">    def __iter__(self):</div><div class="line">        return self # 实例本身就是迭代对象，故返回自己</div><div class="line"></div><div class="line">    def __next__(self):</div><div class="line">        self.a, self.b = self.b, self.a + self.b # 计算下一个值</div><div class="line">        if self.a &gt; 100: # 退出循环的条件</div><div class="line">            raise StopIteration();</div><div class="line">        return self.a # 返回下一个值</div><div class="line"></div><div class="line">    def __getitem__(self, n):</div><div class="line">        if isinstance(n, int):  # n是索引</div><div class="line">            a, b = 1, 1</div><div class="line">            for x in range(n):</div><div class="line">                a, b = b, a + b</div><div class="line">            return a</div><div class="line">        if isinstance(n, slice):  # n是切片</div><div class="line">            start = n.start</div><div class="line">            stop = n.stop</div><div class="line">            if start is None:</div><div class="line">                start = 0</div><div class="line">            a, b = 1, 1</div><div class="line">            L = []</div><div class="line">            for x in range(stop):</div><div class="line">                if x &gt;= start:</div><div class="line">                    L.append(a)</div><div class="line">                a, b = b, a + b</div><div class="line">            return L</div><div class="line">for n in Fib():</div><div class="line">    print(n)</div><div class="line">f = Fib()</div><div class="line">print(f[3])</div><div class="line">print(f[:5])</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="枚举类"><a href="#枚举类" class="headerlink" title="枚举类"></a>枚举类</h3><p>Enum可以把一组相关常量定义在一个class中，且class不可变<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">@unique</div><div class="line">class Weekday(Enum):</div><div class="line">    Sun = 0 # Sun的value被设定为0</div><div class="line">    Mon = 1</div><div class="line">    Tue = 2</div><div class="line">    Wed = 3</div><div class="line">    Thu = 4</div><div class="line">    Fri = 5</div><div class="line">    Sat = 6</div><div class="line">day1 = Weekday.Mon</div><div class="line">print(Weekday.Tue)</div><div class="line">print(Weekday[&apos;Tue&apos;])</div><div class="line">print(Weekday.Tue.value)</div><div class="line">print(day1 == Weekday.Tue)</div><div class="line">print(Weekday(1))</div><div class="line">print(day1 == Weekday(1))</div></pre></td></tr></table></figure></p>
<h3 id="元类"><a href="#元类" class="headerlink" title="元类"></a>元类</h3><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000" target="_blank" rel="external">http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000</a><br><a href="http://blog.csdn.net/pipisorry/article/details/39909057" target="_blank" rel="external">http://blog.csdn.net/pipisorry/article/details/39909057</a>  </p>
</excerpt>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Java程序员学python3.0--入门篇]]></title>
      <url>https://fangyeqing.github.io/2016/11/05/Java%E7%A8%8B%E5%BA%8F%E5%91%98%E5%AD%A6python3.0--%E5%85%A5%E9%97%A8%E7%AF%87/</url>
      <content type="html"><![CDATA[<excerpt in="" index="" |="" 首页摘要="">   

<p>参考廖雪峰大神的<a href="http://www.liaoxuefeng.com/" target="_blank" rel="external">python3.0教程</a>，适用于有一定基础的Java程序员，会对比着Java来学习python。代码在PyCharm中运行通过，地址为<a href="https://github.com/fangyeqing/hello-python/tree/master" target="_blank" rel="external">github</a>。本篇主要介绍python的一些基础知识，包括安装运行（PyCharm设置）、基础语法、函数、高级特性、函数式编程、模块等。在下一篇会介绍python面向对象相关的知识。</p>
<h2 id="python简介"><a href="#python简介" class="headerlink" title="python简介"></a>python简介</h2><p>Python的哲学就是简单优雅，尽量写容易看明白的代码，尽量写少的代码</p>
<a id="more"></a>  
<the rest="" of="" contents="" |="" 余下全文=""> 

<h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><ul>
<li>首选是网络应用，包括网站、后台服务等等；</li>
<li>其次是许多日常需要的小工具，包括系统管理员需要的脚本任务等等；</li>
<li>另外就是把其他语言开发的程序再包装起来，方便使用。</li>
</ul>
<h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul>
<li>简洁优雅。</li>
<li>非常完善的基础代码库，覆盖了网络、文件、GUI、数据库、文本等大量内容</li>
<li>大量的第三方库</li>
</ul>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul>
<li>运行速度慢：Python是解释型语言，代码在执行时会一行一行地翻译成机器码。但是大量的应用程序不需要这么快的运行速度，因为用户根本感觉不出来</li>
<li>代码不能加密：如果要发布你的Python程序，实际上就是发布源代码</li>
</ul>
<h2 id="安装Python"><a href="#安装Python" class="headerlink" title="安装Python"></a>安装Python</h2><h3 id="linux下安装"><a href="#linux下安装" class="headerlink" title="linux下安装"></a>linux下安装</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">wget https://www.python.org/ftp/python/3.5.2/Python-3.5.2.tgz --no-check-certificate</div><div class="line">tar -zxvf Python-3.5.2.tgz</div><div class="line">cd Python-3.5.2/</div><div class="line">./configure --prefix=/global/exec/fangyeqing/python-3.5.2/</div><div class="line">make&amp;&amp;make install</div></pre></td></tr></table></figure>
<p>从安装日志中可以看到python3自带pip，easyinstall，setup-tools<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Installing collected packages: setuptools, pip</div><div class="line">Successfully installed pip-8.1.1 setuptools-20.10.1</div></pre></td></tr></table></figure></p>
<h4 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h4><p>环境变量添加，将刚才configure设置的地址添加到环境变量中：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vi ~/.bash_profile</div></pre></td></tr></table></figure></p>
<p>内容：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">#python</div><div class="line">export PATH=/global/exec/fangyeqing/python-3.5.2/bin:$PATH</div></pre></td></tr></table></figure></p>
<p>source之后测试是否安装成功:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">source ~/.bash_profile</div><div class="line">python3</div></pre></td></tr></table></figure></p>
<h3 id="windows下安装"><a href="#windows下安装" class="headerlink" title="windows下安装"></a>windows下安装</h3><p>python-3.5.2<a href="https://www.python.org/ftp/python/3.5.2/python-3.5.2.exe" target="_blank" rel="external">官方下载地址</a></p>
<p>安装过程中,务必勾上，就不用自己添加到环境变量了</p>
<ul>
<li>[x] Add Python 3.5 to PATH</li>
</ul>
<p>安装完后测试是否成功<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python</div></pre></td></tr></table></figure></p>
<h3 id="解释器"><a href="#解释器" class="headerlink" title="解释器"></a>解释器</h3><p>当我们编写Python代码时，我们得到的是一个包含Python代码的以.py为扩展名的文本文件。要运行代码，就需要Python解释器去执行.py文件。安装python之后自带了CPython，就用这个 就可以了。</p>
<h3 id="编译器"><a href="#编译器" class="headerlink" title="编译器"></a>编译器</h3><p>Windows下安装PyCharm，官方下载地址为<a href="https://download.jetbrains.com/python/pycharm-professional-2016.2.3.exe" target="_blank" rel="external">pycharm-professional-2016.2.3</a>，第一次打开的时候，选择激活方式为code，填入下方激活码（激活码来自互联网，仅供学习交流之用）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">43B4A73YYJ-eyJsaWNlbnNlSWQiOiI0M0I0QTczWVlKIiwibGljZW5zZWVOYW1lIjoibGFuIHl1IiwiYXNzaWduZWVOYW1lIjoiIiwiYXNzaWduZWVFbWFpbCI6IiIsImxpY2Vuc2VSZXN0cmljdGlvbiI6IkZvciBlZHVjYXRpb25hbCB1c2Ugb25seSIsImNoZWNrQ29uY3VycmVudFVzZSI6ZmFsc2UsInByb2R1Y3RzIjpbeyJjb2RlIjoiSUkiLCJwYWlkVXBUbyI6IjIwMTctMDItMjUifSx7ImNvZGUiOiJBQyIsInBhaWRVcFRvIjoiMjAxNy0wMi0yNSJ9LHsiY29kZSI6IkRQTiIsInBhaWRVcFRvIjoiMjAxNy0wMi0yNSJ9LHsiY29kZSI6IlBTIiwicGFpZFVwVG8iOiIyMDE3LTAyLTI1In0seyJjb2RlIjoiRE0iLCJwYWlkVXBUbyI6IjIwMTctMDItMjUifSx7ImNvZGUiOiJDTCIsInBhaWRVcFRvIjoiMjAxNy0wMi0yNSJ9LHsiY29kZSI6IlJTMCIsInBhaWRVcFRvIjoiMjAxNy0wMi0yNSJ9LHsiY29kZSI6IlJDIiwicGFpZFVwVG8iOiIyMDE3LTAyLTI1In0seyJjb2RlIjoiUEMiLCJwYWlkVXBUbyI6IjIwMTctMDItMjUifSx7ImNvZGUiOiJSTSIsInBhaWRVcFRvIjoiMjAxNy0wMi0yNSJ9LHsiY29kZSI6IldTIiwicGFpZFVwVG8iOiIyMDE3LTAyLTI1In0seyJjb2RlIjoiREIiLCJwYWlkVXBUbyI6IjIwMTctMDItMjUifSx7ImNvZGUiOiJEQyIsInBhaWRVcFRvIjoiMjAxNy0wMi0yNSJ9XSwiaGFzaCI6IjMzOTgyOTkvMCIsImdyYWNlUGVyaW9kRGF5cyI6MCwiYXV0b1Byb2xvbmdhdGVkIjpmYWxzZSwiaXNBdXRvUHJvbG9uZ2F0ZWQiOmZhbHNlfQ==-keaxIkRgXPKE4BR/ZTs7s7UkP92LBxRe57HvWamu1EHVXTcV1B4f/KNQIrpOpN6dgpjig5eMVMPmo7yMPl+bmwQ8pTZaCGFuLqCHD1ngo6ywHKIQy0nR249sAUVaCl2wGJwaO4JeOh1opUx8chzSBVRZBMz0/MGyygi7duYAff9JQqfH3p/BhDTNM8eKl6z5tnneZ8ZG5bG1XvqFTqWk4FhGsEWdK7B+He44hPjBxKQl2gmZAodb6g9YxfTHhVRKQY5hQ7KPXNvh3ikerHkoaL5apgsVBZJOTDE2KdYTnGLmqxghFx6L0ofqKI6hMr48ergMyflDk6wLNGWJvYHLWw==-MIIEPjCCAiagAwIBAgIBBTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTE1MTEwMjA4MjE0OFoXDTE4MTEwMTA4MjE0OFowETEPMA0GA1UEAwwGcHJvZDN5MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAxcQkq+zdxlR2mmRYBPzGbUNdMN6OaXiXzxIWtMEkrJMO/5oUfQJbLLuMSMK0QHFmaI37WShyxZcfRCidwXjot4zmNBKnlyHodDij/78TmVqFl8nOeD5+07B8VEaIu7c3E1N+e1doC6wht4I4+IEmtsPAdoaj5WCQVQbrI8KeT8M9VcBIWX7fD0fhexfg3ZRt0xqwMcXGNp3DdJHiO0rCdU+Itv7EmtnSVq9jBG1usMSFvMowR25mju2JcPFp1+I4ZI+FqgR8gyG8oiNDyNEoAbsR3lOpI7grUYSvkB/xVy/VoklPCK2h0f0GJxFjnye8NT1PAywoyl7RmiAVRE/EKwIDAQABo4GZMIGWMAkGA1UdEwQCMAAwHQYDVR0OBBYEFGEpG9oZGcfLMGNBkY7SgHiMGgTcMEgGA1UdIwRBMD+AFKOetkhnQhI2Qb1t4Lm0oFKLl/GzoRykGjAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBggkA0myxg7KDeeEwEwYDVR0lBAwwCgYIKwYBBQUHAwEwCwYDVR0PBAQDAgWgMA0GCSqGSIb3DQEBCwUAA4ICAQC9WZuYgQedSuOc5TOUSrRigMw4/+wuC5EtZBfvdl4HT/8vzMW/oUlIP4YCvA0XKyBaCJ2iX+ZCDKoPfiYXiaSiH+HxAPV6J79vvouxKrWg2XV6ShFtPLP+0gPdGq3x9R3+kJbmAm8w+FOdlWqAfJrLvpzMGNeDU14YGXiZ9bVzmIQbwrBA+c/F4tlK/DV07dsNExihqFoibnqDiVNTGombaU2dDup2gwKdL81ua8EIcGNExHe82kjF4zwfadHk3bQVvbfdAwxcDy4xBjs3L4raPLU3yenSzr/OEur1+jfOxnQSmEcMXKXgrAQ9U55gwjcOFKrgOxEdek/Sk1VfOjvS+nuM4eyEruFMfaZHzoQiuw4IqgGc45ohFH0UUyjYcuFxxDSU9lMCv8qdHKm+wnPRb0l9l5vXsCBDuhAGYD6ss+Ga+aDY6f/qXZuUCEUOH3QUNbbCUlviSz6+GiRnt1kA9N2Qachl+2yBfaqUqr8h7Z2gsx5LcIf5kYNsqJ0GavXTVyWh7PYiKX4bs354ZQLUwwa/cG++2+wNWP+HtBhVxMRNTdVhSm38AknZlD+PTAsWGu9GyLmhti2EnVwGybSD2Dxmhxk3IPCkhKAK+pl0eWYGZWG3tJ9mZ7SowcXLWDFAk0lRJnKGFMTggrWjV8GYpw5bq23VmIqqDLgkNzuoog==</div></pre></td></tr></table></figure></p>
<h4 id="pycharm配置"><a href="#pycharm配置" class="headerlink" title="pycharm配置"></a>pycharm配置</h4><p>配置的文件在github项目中，直接导入也可以，下载<a href="https://github.com/fangyeqing/hello-python/blob/master/pyCharm_setting/pyCharm-settings.jar" target="_blank" rel="external">地址</a>。不怕麻烦可以按下面一步步设置：</p>
<ol>
<li><p>界面窗口设置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Appearance&amp;&amp;Behavior -&gt; Appearance -&gt; show tool windows bars</div></pre></td></tr></table></figure>
</li>
<li><p>编辑器设置：file -&gt; Setting -&gt;Editor</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">#设置Python自动引入包</div><div class="line">general &gt; autoimport -&gt; python :show popup    </div><div class="line">#“代码自动完成”时间延时设置</div><div class="line">Code Completion   -&gt; Auto code completion in (ms):0  -&gt; Autopopup in (ms):500</div><div class="line">#显示“行号”与“空白字符”</div><div class="line">Appearance  -&gt; 勾选“Show line numbers”、“Show whitespaces”、“Show method separators”</div><div class="line">设置编辑器“颜色与字体”主题</div><div class="line"> Colors &amp; Fonts -&gt; Scheme name -&gt; 选择黑色背景的主题“Darcula”-&gt;Sava as先保存一份-&gt;Size -&gt; 设置为“14”</div><div class="line">#python文件默认编码</div><div class="line">File Encodings&gt; IDE Encoding: UTF-8;Project Encoding: UTF-8;</div></pre></td></tr></table></figure>
</li>
<li><p>python文件模板设置：file and code template&gt;python scripts</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">#!/usr/bin/env python</div><div class="line"># -*- coding: utf-8 -*-</div><div class="line">&quot;&quot;&quot;</div><div class="line">__title__ = &apos;$Package_name&apos;</div><div class="line">__author__ = &apos;$USER&apos;</div><div class="line">__time__ = &apos;$DATE&apos;</div><div class="line"># code is far away from bugs with the god animal protecting</div><div class="line">    I love animals. They taste delicious.</div><div class="line">              ┏┓      ┏┓</div><div class="line">            ┏┛┻━━━┛┻┓</div><div class="line">            ┃      ☃      ┃</div><div class="line">            ┃  ┳┛  ┗┳  ┃</div><div class="line">            ┃      ┻      ┃</div><div class="line">            ┗━┓      ┏━┛</div><div class="line">                ┃      ┗━━━┓</div><div class="line">                ┃  神兽保佑    ┣┓</div><div class="line">                ┃　永无BUG！   ┏┛</div><div class="line">                ┗┓┓┏━┳┓┏┛</div><div class="line">                  ┃┫┫  ┃┫┫</div><div class="line">                  ┗┻┛  ┗┻┛</div><div class="line">&quot;&quot;&quot;</div></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="hello-world"><a href="#hello-world" class="headerlink" title="hello world"></a>hello world</h2><h3 id="PyCharm"><a href="#PyCharm" class="headerlink" title="PyCharm"></a>PyCharm</h3><p>如果前面已经安装好PyCharm，就跟IntelliJ Idea一样，新建项目，新建py文件，直接运行就可以了。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">print(&apos;hello python&apos;)</div><div class="line">print(100+200+300)</div></pre></td></tr></table></figure></p>
<p>后面的示例程序都是在PyCharm中直接运行即可。</p>
<p>当然也可以通过交互式命令行、文本形式、py脚本形式（linux）运行。</p>
<h3 id="交互式命令行"><a href="#交互式命令行" class="headerlink" title="交互式命令行"></a>交互式命令行</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">python3               #进入交互式命令行模式，windows下为python</div><div class="line">100+200+300</div><div class="line">exit()                #退出，Ctrl+D也可以</div></pre></td></tr></table></figure>
<h3 id="文本形式"><a href="#文本形式" class="headerlink" title="文本形式"></a>文本形式</h3><p>编辑文本hello-world.py,内容为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">print(100+200+300)</div></pre></td></tr></table></figure></p>
<p>执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python3 hello-world.py</div></pre></td></tr></table></figure></p>
<h3 id="脚本形式"><a href="#脚本形式" class="headerlink" title="脚本形式"></a>脚本形式</h3><p>linux下如果想直接运行py脚本，在开头加上：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">#!/usr/bin/env python3</div><div class="line">print(100+200+300)</div></pre></td></tr></table></figure></p>
<p>执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hello-world.py</div></pre></td></tr></table></figure></p>
<h2 id="Python基础"><a href="#Python基础" class="headerlink" title="Python基础"></a>Python基础</h2><ul>
<li>#开头的语句是注释 </li>
<li>语句以冒号:结尾时，缩进的语句视为代码块</li>
<li>4个空格的缩进</li>
<li>大小写敏感<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"># print absolute value of an integer:</div><div class="line">a = 100</div><div class="line">if a &gt;= 0:</div><div class="line">    print(a)</div><div class="line">else:</div><div class="line">    print(-a)</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="数据类型和变量"><a href="#数据类型和变量" class="headerlink" title="数据类型和变量"></a>数据类型和变量</h3><h4 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h4><p>数据类型跟Java类似，基本类型主要有以下几种：</p>
<ul>
<li>整数</li>
<li>浮点数</li>
<li>字符串：单引号或者双引号，转义字符“\”</li>
<li>布尔值：True、False</li>
<li>空值：None<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"># 整数</div><div class="line">print(1)</div><div class="line">print(-8080)</div><div class="line">print(0xff00)</div><div class="line"># 浮点数</div><div class="line">print(1.23)</div><div class="line">print(12.3e8)</div><div class="line"># 字符串</div><div class="line">print(&apos;I\&apos;m \&quot;OK\&quot;!&apos;)</div><div class="line"># 布尔值</div><div class="line">print(True)</div><div class="line">print(2 &gt; 3)</div><div class="line"># 空值</div><div class="line">print(None)</div></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h4><p>动态类型，“=”赋值任意类型<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">a = &apos;ABC&apos;</div><div class="line">b = a</div><div class="line">a = &apos;XYZ&apos;</div><div class="line">print(b)</div></pre></td></tr></table></figure></p>
<ul>
<li>执行a = ‘ABC’，解释器创建了字符串’ABC’和变量a，并把a指向’ABC’：</li>
<li>执行b = a，解释器创建了变量b，并把b指向a指向的字符串’ABC’：</li>
<li>执行a = ‘XYZ’，解释器创建了字符串’XYZ’，并把a的指向改为’XYZ’，但b并没有更改：</li>
<li>所以，最后打印变量b的结果自然是’ABC’了。</li>
</ul>
<h4 id="常量"><a href="#常量" class="headerlink" title="常量"></a>常量</h4><p>用全部大写的变量名表示常量。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">PI = 3.14159265359</div><div class="line">print(PI)</div></pre></td></tr></table></figure></p>
<h3 id="字符串和编码"><a href="#字符串和编码" class="headerlink" title="字符串和编码"></a>字符串和编码</h3><h4 id="计算机编码类型"><a href="#计算机编码类型" class="headerlink" title="计算机编码类型"></a>计算机编码类型</h4><ul>
<li>ASCII编码：1 byte，只支持英文</li>
<li>Unicode编码：2 byte，支持中文、英文</li>
<li>UTF-8编码：可变长度1-6byte，英文字母1个字节，汉字通常3个字节，很生僻的字符被编码成4-6个字节。</li>
</ul>
<table>
<thead>
<tr>
<th>字符</th>
<th>ASCII</th>
<th>Unicode</th>
<th>UTF-8</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>01000001</td>
<td>00000000</td>
<td>01000001</td>
<td>01000001</td>
</tr>
<tr>
<td>中</td>
<td>x</td>
<td>01001110</td>
<td>00101101</td>
<td>11100100</td>
<td>10111000</td>
<td>10101101</td>
</tr>
</tbody>
</table>
<ul>
<li>在计算机内存中，统一使用2个字节的Unicode编码，当需要保存到硬盘或者需要传输的时候，就转换为可变长度的UTF-8编码。</li>
<li>用记事本编辑的时候，从文件读取的UTF-8字符被转换为Unicode字符到内存里，编辑完成后，保存的时候再把Unicode转换为UTF-8保存到文件。</li>
<li>浏览网页的时候，服务器会把动态生成的Unicode内容转换为UTF-8再传输到浏览器.很多网页的源码上会有类似<meta charset="UTF-8">的信息，表示该网页正是用的UTF-8编码</li>
</ul>
<h4 id="python编解码"><a href="#python编解码" class="headerlink" title="python编解码"></a>python编解码</h4><h5 id="bytes类型"><a href="#bytes类型" class="headerlink" title="bytes类型"></a>bytes类型</h5><p>bytes类型的数据用带b前缀的单引号或双引号表示。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">x = b&apos;ABC&apos;</div></pre></td></tr></table></figure></p>
<p>纯英文可以用ascii编码成bytes，中文只能用UTF-8编码成bytes，所以最好统一用UTF-8<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">print(&apos;中文&apos;.encode(&apos;utf-8&apos;))</div><div class="line">print(b&apos;\xe4\xb8\xad\xe6\x96\x87&apos;.decode(&apos;utf-8&apos;))</div></pre></td></tr></table></figure></p>
<h5 id="源码的中文处理"><a href="#源码的中文处理" class="headerlink" title="源码的中文处理"></a>源码的中文处理</h5><p>当你的源代码中包含中文的时候，就需要务必指定保存为UTF-8编码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">#!/usr/bin/env python3</div><div class="line"># -*- coding: utf-8 -*-</div></pre></td></tr></table></figure></p>
<h5 id="格式化输出"><a href="#格式化输出" class="headerlink" title="格式化输出"></a>格式化输出</h5><p>与C语言类似，用占位符表示：%d、%f、%s、%x。其中，%%来转义表示一个%。</p>
<p>例如：小明的成绩从去年的72分提升到了今年的85分，请计算小明成绩提升的百分点，并用字符串格式化显示出’xx.x%’，只保留小数点后1位<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">#!/usr/bin/env python3</div><div class="line"># -*- coding: utf-8 -*-</div><div class="line">s1 = 72</div><div class="line">s2 = 85</div><div class="line">s3 = (s1-s2)/s1*100</div><div class="line">print(&apos;%.2f%%&apos; % s3)</div></pre></td></tr></table></figure></p>
<h3 id="python集合类型"><a href="#python集合类型" class="headerlink" title="python集合类型"></a>python集合类型</h3><table>
<thead>
<tr>
<th>python集合类型</th>
<th>创建方式</th>
<th>对应Java类型</th>
</tr>
</thead>
<tbody>
<tr>
<td> list</td>
<td>[]</td>
<td>List</td>
</tr>
<tr>
<td> tuple</td>
<td>()</td>
<td>List</td>
</tr>
<tr>
<td> map</td>
<td>{}</td>
<td>Map</td>
</tr>
<tr>
<td> set</td>
<td>set()</td>
<td>set</td>
</tr>
</tbody>
</table>
<h4 id="list"><a href="#list" class="headerlink" title="list:[]"></a>list:[]</h4><p>list是一种有序的集合，可以随时添加和删除其中的元素。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">classmates = [&apos;Michael&apos;, &apos;Bob&apos;, &apos;Tracy&apos;]    #list初始化</div><div class="line">print(classmates)</div><div class="line">print(len(classmates))                        #list长度len()</div><div class="line">print(classmates[0])                             #取序号处元素</div><div class="line">print(classmates[-1])                      #反向取序号处元素</div><div class="line"></div><div class="line">classmates.append(&apos;Adam&apos;)       #末尾插入</div><div class="line">classmates.insert(1, &apos;Jack&apos;)    #序号处插入</div><div class="line">classmates.pop()                #删除末尾</div><div class="line">classmates.pop(1)               #删除序号处</div><div class="line">classmates[1] = &apos;Sarah&apos;         #序号处替换</div><div class="line">print(classmates)</div></pre></td></tr></table></figure></p>
<p>list里面的元素的数据类型也可以不同，比如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">L = [&apos;Apple&apos;, 123, True]</div></pre></td></tr></table></figure></p>
<p>list元素也可以是另一个list，比如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">s = [&apos;python&apos;, &apos;java&apos;, [&apos;asp&apos;, &apos;php&apos;], &apos;scheme&apos;]</div><div class="line">print(s[2])</div></pre></td></tr></table></figure></p>
<p>如果一个list中一个元素也没有，就是一个空的list，它的长度为0：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">L = []</div><div class="line">print(len(L))</div></pre></td></tr></table></figure></p>
<h4 id="tuple"><a href="#tuple" class="headerlink" title="tuple:()"></a>tuple:()</h4><p>相当于不可变的list，没有append、insert方法，小括号表示。只有1个元素的tuple时，也会加一个逗号，以免你误解成数学计算意义上的括号<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">classmates = (&apos;Michael&apos;, &apos;Bob&apos;, &apos;Tracy&apos;)</div><div class="line">print(classmates)</div><div class="line">t = (1,)</div><div class="line">print(t)</div></pre></td></tr></table></figure></p>
<p>与java的final类似,虽然是不可变的，但是tuple中的list是可变的<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">t = (&apos;a&apos;, &apos;b&apos;, [&apos;A&apos;, &apos;B&apos;])</div><div class="line">t[2][0] = &apos;X&apos;</div><div class="line">t[2][1] = &apos;Y&apos;</div><div class="line">print(t)</div></pre></td></tr></table></figure></p>
<h4 id="dict"><a href="#dict" class="headerlink" title="dict:{}"></a>dict:{}</h4><p>类似于java的map，dict的key必须是不可变对象<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">d = &#123;&apos;Michael&apos;: 95, &apos;Bob&apos;: 75, &apos;Tracy&apos;: 85&#125;     #初始化</div><div class="line">print(d[&apos;Michael&apos;])                             #取key为xxx的值，key不存在会报错</div><div class="line">d[&apos;Adam&apos;] = 67                                  #给key给xxx的赋值</div><div class="line">print(&apos;Thomas&apos; in d)                            #判断key是否存在</div><div class="line">print(d.get(&apos;Thomas&apos;))                          #取key为xxx的值，不存在返回空</div><div class="line">print(d.get(&apos;Thomas&apos;, -1))                      #取key为xxx的值，不存在返回-1</div><div class="line">print(d.pop(&apos;Bob&apos;))                             #删除key为xxx</div></pre></td></tr></table></figure></p>
<h4 id="set"><a href="#set" class="headerlink" title="set"></a>set</h4><p>set和dict的唯一区别仅在于没有存储对应的value。创建set必须以list作为输入集合：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">s = set([1, 2, 3])</div><div class="line">print(s)</div></pre></td></tr></table></figure></p>
<p>set可以看成数学意义上的无序和无重复元素的集合，因此，两个set可以做数学意义上的交集、并集等操作：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">s1 = set([1, 2, 3])</div><div class="line">s2 = set([2, 3, 4])</div><div class="line">print(s1 &amp; s2)</div><div class="line">print(s1 | s2)</div></pre></td></tr></table></figure></p>
<h3 id="不变与可变"><a href="#不变与可变" class="headerlink" title="不变与可变"></a>不变与可变</h3><p>list是可变对象<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">classmates = [&apos;Michael&apos;, &apos;Bob&apos;, &apos;Tracy&apos;]</div><div class="line">classmates.sort()</div><div class="line">print(classmates)</div></pre></td></tr></table></figure></p>
<p>str是不变对象<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">a = &apos;abc&apos;</div><div class="line">b = a.replace(&apos;a&apos;, &apos;A&apos;)</div><div class="line">print(a)</div><div class="line">print(b)</div></pre></td></tr></table></figure></p>
<p>对于不变对象来说，调用对象自身的任意方法，也不会改变该对象自身的内容。相反，这些方法会创建新的对象并返回，这样，就保证了不可变对象本身永远是不可变的。</p>
<p>其实说这么多，就是类似于java中的final类型，不能改变对象的地址，但是可以改变内容。</p>
<h3 id="条件判断"><a href="#条件判断" class="headerlink" title="条件判断"></a>条件判断</h3><p>注意冒号和缩进，else if必须写成elif<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">age = input(&apos;birth:&apos;)           </div><div class="line">age = int(age)                  #相当于java的Integer.parse(String)</div><div class="line">if age &gt;= 18:</div><div class="line">    print(&apos;adult&apos;)</div><div class="line">elif age &gt;= 6:</div><div class="line">    print(&apos;teenager&apos;)</div><div class="line">else:</div><div class="line">    print(&apos;kid&apos;)</div></pre></td></tr></table></figure></p>
<h3 id="循环"><a href="#循环" class="headerlink" title="循环"></a>循环</h3><h4 id="for"><a href="#for" class="headerlink" title="for"></a>for</h4><p>跟java类似<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">names = [&apos;Michael&apos;, &apos;Bob&apos;, &apos;Tracy&apos;]</div><div class="line">for name in names:</div><div class="line">    print(name)</div></pre></td></tr></table></figure></p>
<p>range(i1,i2,n)表示从i1到i2的数组，步进为n，range(i)表示range(0,i)，n省略为1，list(range())表示转化成list<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">print(list(range(1, 5)))</div></pre></td></tr></table></figure></p>
<h4 id="while循环"><a href="#while循环" class="headerlink" title="while循环"></a>while循环</h4><p>跟java类似<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">sum = 0</div><div class="line">n = 99</div><div class="line">while n &gt; 0:</div><div class="line">    sum = sum + n</div><div class="line">    n = n - 2</div><div class="line">print(sum)</div></pre></td></tr></table></figure></p>
<h4 id="break和continue"><a href="#break和continue" class="headerlink" title="break和continue"></a>break和continue</h4><p>跟java一样，break语句可以在循环过程中直接退出循环，而continue语句可以提前结束本轮循环<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">for x in range(20):</div><div class="line">    if x == 10:</div><div class="line">        break</div><div class="line">    if x % 2 == 0:</div><div class="line">        continue</div><div class="line">    print(x)</div></pre></td></tr></table></figure></p>
<h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><h3 id="内置函数"><a href="#内置函数" class="headerlink" title="内置函数"></a>内置函数</h3><p>绝对值、求最大值<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">print(abs(-100))</div><div class="line">print(max(1, 2, 3, 199))</div></pre></td></tr></table></figure></p>
<p>数据类型转换函数：<br>int、float、str、bool<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">print(int(&apos;123&apos;))</div><div class="line">print(int(12.34))</div><div class="line">print(float(&apos;12.34&apos;))</div><div class="line">print(str(1.23))</div><div class="line">print(str(100))</div><div class="line">print(bool(1))</div><div class="line">print(bool(&apos;&apos;))</div></pre></td></tr></table></figure></p>
<h3 id="定义函数"><a href="#定义函数" class="headerlink" title="定义函数"></a>定义函数</h3><p>定义函数，以def开头。没有return语句，返回结果为None<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">def my_abs(x):</div><div class="line">    if not isinstance(x, (int, float)):     #参数检查</div><div class="line">        raise TypeError(&apos;bad operand type&apos;)</div><div class="line">    if x &gt;= 0:</div><div class="line">        return x</div><div class="line">    else:</div><div class="line">        return -x</div><div class="line"></div><div class="line">print(my_abs(-10))</div></pre></td></tr></table></figure></p>
<p>在其他py文件中调用，则需要引入from _2_def.py import my_abs。当然，在PyCharm中只需要Alt+Enter引入。</p>
<h4 id="空函数"><a href="#空函数" class="headerlink" title="空函数"></a>空函数</h4><p>空函数：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">def nop():</div><div class="line">    pass</div></pre></td></tr></table></figure></p>
<p>pass还可以用在其他语句里<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">if age &gt;= 18:</div><div class="line">    pass</div></pre></td></tr></table></figure></p>
<h4 id="返回多个值"><a href="#返回多个值" class="headerlink" title="返回多个值"></a>返回多个值</h4><p>游戏中经常需要从一个点移动到另一个点，给出坐标、位移和角度，就可以计算出新的新的坐标。Python函数返回的仍然是单一值，以tuple形式而已。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">import math</div><div class="line"></div><div class="line">def move(x, y, step, angle=0):</div><div class="line">    nx = x + step * math.cos(angle)</div><div class="line">    ny = y - step * math.sin(angle)</div><div class="line">    return nx, ny</div><div class="line"></div><div class="line">a, b = move(100, 100, 60, math.pi / 6)</div><div class="line">print(a, b)</div><div class="line">r = move(100, 100, 60, math.pi / 6)</div><div class="line">print(r)</div></pre></td></tr></table></figure></p>
<h5 id="练习"><a href="#练习" class="headerlink" title="练习"></a>练习</h5><p>请定义一个函数quadratic(a, b, c)，接收3个参数，返回一元二次方程：ax2 + bx + c = 0的两个解。详解见：_3_function/quadratic.py</p>
<h3 id="递归函数"><a href="#递归函数" class="headerlink" title="递归函数"></a>递归函数</h3><p>跟java类似，也要小心栈溢出的问题<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">def fact(n):</div><div class="line">    if n == 1:</div><div class="line">        return 1</div><div class="line">    return n * fact(n - 1)</div><div class="line">print(fact(5))</div><div class="line">print(fact(10))</div><div class="line"># print(fact(1000))</div></pre></td></tr></table></figure></p>
<h3 id="函数参数"><a href="#函数参数" class="headerlink" title="函数参数"></a>函数参数</h3><h4 id="必选参数"><a href="#必选参数" class="headerlink" title="必选参数"></a>必选参数</h4><p>必须传入的参数</p>
<h4 id="默认参数"><a href="#默认参数" class="headerlink" title="默认参数"></a>默认参数</h4><ul>
<li>必选参数在前，默认参数在后</li>
<li>当函数有多个参数时，把变化大的参数放前面，变化小的参数放后面。变化小的参数就可以作为默认参数</li>
<li>默认参数必须指向不变对象<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">def power(x, n=2):</div><div class="line">    s = 1</div><div class="line">    while n &gt; 0:</div><div class="line">        n -= 1</div><div class="line">        s = s * x</div><div class="line">    return s</div><div class="line">print(power(5))</div><div class="line">print(power(5, 3))</div></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="可变参数"><a href="#可变参数" class="headerlink" title="可变参数"></a>可变参数</h4><p>在入参数前面加了一个*号，表示可变参数在函数调用时自动组装为一个tuple<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">def calc(*numbers):</div><div class="line">    sum = 0</div><div class="line">    for n in numbers:</div><div class="line">        sum = sum + n * n</div><div class="line">    return sum</div><div class="line">print(calc(1, 2, 3))</div></pre></td></tr></table></figure></p>
<h4 id="关键字参数"><a href="#关键字参数" class="headerlink" title="关键字参数"></a>关键字参数</h4><p>在入参数前面加了一个**号,在函数内部自动组装为一个dict<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">def person(name, age, **kw):</div><div class="line">    print(&apos;name:&apos;, name, &apos;age:&apos;, age, &apos;other:&apos;, kw)</div><div class="line">person(&apos;Michael&apos;, 30)</div><div class="line">person(&apos;Bob&apos;, 35, city=&apos;Beijing&apos;)</div><div class="line">person(&apos;Adam&apos;, 45, gender=&apos;M&apos;, job=&apos;Engineer&apos;)</div><div class="line">extra = &#123;&apos;city&apos;: &apos;Beijing&apos;, &apos;job&apos;: &apos;Engineer&apos;&#125;</div><div class="line">person(&apos;Jack&apos;, 24, **extra)</div></pre></td></tr></table></figure></p>
<h4 id="命名关键字"><a href="#命名关键字" class="headerlink" title="命名关键字"></a>命名关键字</h4><p>如果要限制关键字参数的名字，就可以用命名关键字参数。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">def person(name, age, *, city, job):</div><div class="line">    print(name, age, city, job)</div><div class="line">person(&apos;Jack&apos;, 24, city=&apos;Beijing&apos;, job=&apos;Engineer&apos;)</div></pre></td></tr></table></figure></p>
<p>已经有了一个可变参数，命名关键字参数就不再需要一个特殊分隔符*了：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">def person(name, age, *args, city, job):</div><div class="line">    print(name, age, args, city, job)</div><div class="line">person(&apos;Jack&apos;, 24, 3, 1, city=&apos;Beijing&apos;, job=&apos;Engineer&apos;)</div></pre></td></tr></table></figure></p>
<h4 id="参数组合"><a href="#参数组合" class="headerlink" title="参数组合"></a>参数组合</h4><p>参数定义的顺序必须是：必选参数、默认参数、可变参数、命名关键字参数和关键字参数。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">def f1(a, b, c=0, *args, **kw):</div><div class="line">    print(&apos;a =&apos;, a, &apos;b =&apos;, b, &apos;c =&apos;, c, &apos;args =&apos;, args, &apos;kw =&apos;, kw)</div><div class="line">f1(1, 2)</div><div class="line">f1(1, 2, c=3)</div><div class="line">f1(1, 2, 3, &apos;a&apos;, &apos;b&apos;)</div><div class="line">f1(1, 2, 3, &apos;a&apos;, &apos;b&apos;, x=99)</div><div class="line">args = (1, 2, 3, 4)</div><div class="line">kw = &#123;&apos;d&apos;: 99, &apos;x&apos;: &apos;#&apos;&#125;</div><div class="line">f1(*args, **kw)</div><div class="line"></div><div class="line">def f2(a, b, c=0, *, d, **kw):</div><div class="line">    print(&apos;a =&apos;, a, &apos;b =&apos;, b, &apos;c =&apos;, c, &apos;d =&apos;, d, &apos;kw =&apos;, kw)</div><div class="line">f2(1, 2, d=99, ext=None)</div><div class="line">args = (1, 2, 3)</div><div class="line">kw = &#123;&apos;d&apos;: 88, &apos;x&apos;: &apos;#&apos;&#125;</div><div class="line">f2(*args, **kw)</div></pre></td></tr></table></figure></p>
<p>对于任意函数，都可以通过类似func(<em>args, *</em>kw)的形式调用它</p>
<h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><ul>
<li>默认参数一定要用不可变对象，如果是可变对象，程序运行时会有逻辑错误！</li>
<li>要注意定义可变参数和关键字参数的语法：<ul>
<li>*args是可变参数，args接收的是一个tuple；  </li>
<li>**kw是关键字参数，kw接收的是一个dict。</li>
</ul>
</li>
<li>调用函数时如何传入可变参数和关键字参数的语法：<ul>
<li>可变参数既可以直接传入：func(1, 2, 3)，又可以先组装list或tuple，再通过<em>args传入：func(</em>(1, 2, 3))；</li>
<li>关键字参数既可以直接传入：func(a=1, b=2)，又可以先组装dict，再通过<strong>kw传入：func(</strong>{‘a’: 1, ‘b’: 2})。</li>
</ul>
</li>
<li>使用<em>args和*</em>kw是Python的习惯写法，当然也可以用其他参数名，但最好使用习惯用法。</li>
<li>命名的关键字参数是为了限制调用者可以传入的参数名，同时可以提供默认值。</li>
</ul>
<h2 id="高级特性"><a href="#高级特性" class="headerlink" title="高级特性"></a>高级特性</h2><h3 id="切片"><a href="#切片" class="headerlink" title="切片"></a>切片</h3><ul>
<li>L[i1:i2]表示从第i个到第i-2个，间隔为1。i1为负数时，表示从倒数第-i1个开始。</li>
<li>L[i1:]表示到最后一个</li>
<li>L[:i2]表示前i2个</li>
<li>L[i1:i2:n]表示从第i个到第i-2个,间隔为n。</li>
<li>L[:]表示复制L<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">L = [&apos;Michael&apos;, &apos;Sarah&apos;, &apos;Tracy&apos;, &apos;Bob&apos;, &apos;Jack&apos;]</div><div class="line"># 切片</div><div class="line">print(L[0:3])</div><div class="line">print(L[1:3])</div><div class="line">print(L[-1])</div><div class="line">print(L[-3:-1])</div><div class="line"></div><div class="line">L1 = list(range(100))</div><div class="line">print(L1[1:20])</div><div class="line"># 前十个数</div><div class="line">print(L1[:10])</div><div class="line"># 后十个数</div><div class="line">print(L1[-10:])</div><div class="line"># 前十个数，没两个取一个</div><div class="line">print(L1[:10:2])</div><div class="line"># 所有数，每5个取一个</div><div class="line">print(L1[::5])</div><div class="line"># 复制一个list</div><div class="line">print(L1[:])</div><div class="line"></div><div class="line"># tuple切片仍是tuple</div><div class="line">print((0, 1, 2, 3, 4, 5)[:3])</div><div class="line"></div><div class="line"># 切片用于字符串切割</div><div class="line">s = &apos;ABCDEFG&apos;</div><div class="line">s1 = s[:3]</div><div class="line">s2 = s[-4:]</div><div class="line">print(s1, s2,)</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="迭代"><a href="#迭代" class="headerlink" title="迭代"></a>迭代</h3><p>任何可迭代对象都可以作用于for循环，包括我们自定义的数据类型，只要符合迭代条件，就可以使用for循环<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"># dict迭代</div><div class="line">from collections import Iterable</div><div class="line"></div><div class="line">d = &#123;&apos;a&apos;: 1, &apos;b&apos;: 2, &apos;c&apos;: 3&#125;</div><div class="line">for key in d:</div><div class="line">    print(key)</div><div class="line">for value in d.values():</div><div class="line">    print(value)</div><div class="line">for k, v in d.items():</div><div class="line">    print(k, v)</div><div class="line"># 字符串迭代</div><div class="line">for ch in &apos;ABC&apos;:</div><div class="line">    print(ch)</div><div class="line"># 判断是否可以迭代</div><div class="line">print(isinstance(&apos;abc&apos;, Iterable))</div><div class="line">print(isinstance(123, Iterable))</div><div class="line"># 类java下标循环</div><div class="line">for i, value in enumerate([&apos;A&apos;, &apos;B&apos;, &apos;C&apos;]):</div><div class="line">    print(i, value)</div><div class="line"># 两个变量，list元素中为tuple</div><div class="line">for x, y in [(1, 1), (2, 4), (3, 9)]:</div><div class="line">    print(x, y)</div></pre></td></tr></table></figure></p>
<h3 id="列表生成式"><a href="#列表生成式" class="headerlink" title="列表生成式"></a>列表生成式</h3><p>运用列表生成式，可以快速生成list，可以通过一个list推导出另一个list，而代码却十分简洁<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">import os</div><div class="line"># 生成[1x1, 2x2, 3x3, ..., 10x10]</div><div class="line">print([x*x for x in range(1, 11)])</div><div class="line"># 选出仅偶数的平方</div><div class="line">print([x * x for x in range(1, 11) if x % 2 == 0])</div><div class="line"># 两层循环生成全排列</div><div class="line">print([m + n for m in &apos;ABC&apos; for n in &apos;XYZ&apos;])</div><div class="line"># 列出当前目录下的所有文件和目录名</div><div class="line">print([d for d in os.listdir(&apos;.&apos;)])</div><div class="line"># 生成表达式</div><div class="line">d = &#123;&apos;x&apos;: &apos;A&apos;, &apos;y&apos;: &apos;B&apos;, &apos;z&apos;: &apos;C&apos;&#125;</div><div class="line">print([k + &apos;=&apos; + v for k, v in d.items()])</div><div class="line"># list字符串变小写</div><div class="line">L = [&apos;Hello&apos;, &apos;World&apos;, &apos;IBM&apos;, &apos;Apple&apos;]</div><div class="line">print([s.lower() for s in L])</div><div class="line"># test</div><div class="line">L1 = [&apos;Hello&apos;, &apos;World&apos;, 18, &apos;Apple&apos;, None]</div><div class="line">L2 = [s.lower() for s in L1 if isinstance(s, str)]</div><div class="line">print(L2)</div></pre></td></tr></table></figure></p>
<h3 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h3><p>通过列表生成式，我们可以直接创建一个列表。但是，受到内存限制，列表容量肯定是有限的。在循环的过程中不断推算出后续的元素，这样就不必创建完整的list，从而节省大量的空间。在Python中，这种一边循环一边计算的机制，称为生成器：generator。</p>
<ul>
<li>把一个列表生成式的[]改成()，就创建了一个generator</li>
<li>一个函数定义中包含yield关键字，是一个generator函数，generator函数的“调用”实际返回一个generator对象</li>
<li>generator函数在每次next(g)或者for循环调用的时候执行，yield返回结果，再次执行时从上次yield语句处继续执行<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">g = (x * x for x in range(10))</div><div class="line">print(next(g))</div><div class="line">print(next(g))</div><div class="line"></div><div class="line">#斐波拉契数列（Fibonacci），除第一个和第二个数外，任意一个数都可由前两个数相加得到：</div><div class="line"># 1, 1, 2, 3, 5, 8, 13, 21, 34, ...</div><div class="line">def fib(max):</div><div class="line">    n, a, b = 0, 0, 1</div><div class="line">    while n &lt; max:</div><div class="line">        yield b</div><div class="line">        a, b = b, a + b</div><div class="line">        n = n + 1</div><div class="line">    return &apos;done&apos;</div><div class="line">f = fib(6)</div><div class="line">print(f)</div><div class="line">for n in fib(6):</div><div class="line">    print(n)</div><div class="line">    </div><div class="line"># 杨辉三角</div><div class="line">def triangles():</div><div class="line">    L = [1]</div><div class="line">    while True:</div><div class="line">        yield L</div><div class="line">        L.append(0)</div><div class="line">        L = [L[i-1] + L[i]  for i in range(len(L))]</div><div class="line"></div><div class="line">n=0</div><div class="line">for t in triangles():</div><div class="line">    print(t)</div><div class="line">    n += 1</div><div class="line">    if n == 10:</div><div class="line">        break</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="迭代器"><a href="#迭代器" class="headerlink" title="迭代器"></a>迭代器</h3><table>
<thead>
<tr>
<th>对比</th>
<th>Iterable(可迭代对象)</th>
<th>Iterator(迭代器)</th>
</tr>
</thead>
<tbody>
<tr>
<td>特点</td>
<td>可以直接作用于for循环</td>
<td>可作用于next()函数的对象</td>
</tr>
<tr>
<td>举例</td>
<td>集合类型、generator</td>
<td>generator、iter(集合类型)</td>
</tr>
</tbody>
</table>
<p>集合数据类型：如list、tuple、dict、set、str等。<br>generator：包括生成器和带yield的generator function。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"># 可迭代对象：Iterable判断</div><div class="line">print(isinstance([], Iterable))</div><div class="line">print(isinstance(&#123;&#125;, Iterable))</div><div class="line">print(isinstance(&apos;abc&apos;, Iterable))</div><div class="line">print(isinstance((x for x in range(10)), Iterable))</div><div class="line">print(isinstance(100, Iterable))</div><div class="line"># 迭代器：Iterator判断</div><div class="line">print(isinstance((x for x in range(10)), Iterator))</div><div class="line">print(isinstance([], Iterator))</div><div class="line">print(isinstance(&#123;&#125;, Iterator))</div><div class="line">print(isinstance(&apos;abc&apos;, Iterator))</div><div class="line"># iter转化集合类型为Iterator</div><div class="line">print(isinstance(iter([]), Iterator))</div><div class="line">print(isinstance(iter(&apos;abc&apos;), Iterator))</div></pre></td></tr></table></figure></p>
<h2 id="函数式编程"><a href="#函数式编程" class="headerlink" title="函数式编程"></a>函数式编程</h2><h3 id="高阶函数"><a href="#高阶函数" class="headerlink" title="高阶函数"></a>高阶函数</h3><p>把函数作为参数传入，这样的函数称为高阶函数，函数式编程就是指这种高度抽象的编程范式<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"># 变量指向函数</div><div class="line">f = abs</div><div class="line">print(f(-10))</div><div class="line"># 高阶函数</div><div class="line">def add(x, y, f1):</div><div class="line">    return f1(x) + f1(y)</div><div class="line">print(add(-5, 6, abs))</div></pre></td></tr></table></figure></p>
<h4 id="map-reduce"><a href="#map-reduce" class="headerlink" title="map/reduce"></a>map/reduce</h4><ul>
<li>map(函数，Iterator)：将传入的函数依次作用到序列的每个元素(并行计算)，并把结果作为新的Iterator返回<ul>
<li>map(f, [x1, x2, x3, x4]) = [f(x1), f(x2), f(x3), f(x4)]</li>
</ul>
</li>
<li>reduce(函数，Iterator):reduce把结果继续和序列的下一个元素做累积计算(串行计算)<ul>
<li>reduce(f, [x1, x2, x3, x4]) = f(f(f(x1, x2), x3), x4)<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"># 实现int函数：map利用dict将集合str挨个转换为数字，reduce加权累加每位</div><div class="line">def str2int(s):</div><div class="line">    def fn(x, y):</div><div class="line">        return x * 10 + y</div><div class="line">    def char2num(s):</div><div class="line">        L = &#123;&apos;0&apos;: 0, &apos;1&apos;: 1, &apos;2&apos;: 2, &apos;3&apos;: 3, &apos;4&apos;: 4, &apos;5&apos;: 5, &apos;6&apos;: 6, &apos;7&apos;: 7, &apos;8&apos;: 8, &apos;9&apos;: 9&#125;</div><div class="line">        return L[s]</div><div class="line">    return reduce(fn, map(char2num, s))</div><div class="line">print(str2int(&apos;123&apos;))</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h4 id="filter"><a href="#filter" class="headerlink" title="filter"></a>filter</h4><p>filter()用于过滤序列。把传入的函数依次作用于每个元素，然后根据返回值是True还是False决定保留还是丢弃该元素。返回的是一个Iterator<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"># filter:过滤偶数</div><div class="line">def is_odd(n):</div><div class="line">    return n % 2 == 1</div><div class="line">print(list(filter(is_odd, [1, 2, 4, 5, 6, 9, 10, 15])))</div></pre></td></tr></table></figure></p>
<h4 id="sorted"><a href="#sorted" class="headerlink" title="sorted"></a>sorted</h4><p>语法：sorted(L, key=函数, reverse=True/False)</p>
<ul>
<li>L:序列</li>
<li>key：排序规则</li>
<li>reverse：是否逆序<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">L = [36, 5, -12, 9, -21]</div><div class="line">print(sorted(L))</div><div class="line"># sorted：key</div><div class="line">print(sorted(L, key=abs))</div><div class="line">s = [&apos;bob&apos;, &apos;about&apos;, &apos;Zoo&apos;, &apos;Credit&apos;]</div><div class="line">print(sorted(s))</div><div class="line">print(sorted(s, key=str.lower))</div><div class="line"># # sorted：reverse=True逆序</div><div class="line">print(sorted(s, key=str.lower, reverse=True))</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="返回函数"><a href="#返回函数" class="headerlink" title="返回函数"></a>返回函数</h3><ul>
<li>返回的函数并没有立刻执行，而是直到调用了f()才执行</li>
<li>相关参数和变量都保存在返回的函数中，这种称为“闭包（Closure）”</li>
<li>返回函数不要引用任何循环变量，或者后续会发生变化的变量<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">def lazy_sum(*args):</div><div class="line">    def sum():</div><div class="line">        ax = 0</div><div class="line">        for n in args:</div><div class="line">            ax = ax + n</div><div class="line">        return ax</div><div class="line">    return sum</div><div class="line">f = lazy_sum(1, 3, 5, 7, 9)</div><div class="line">print(f)</div><div class="line">print(f())</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="匿名函数"><a href="#匿名函数" class="headerlink" title="匿名函数"></a>匿名函数</h3><ul>
<li>Lambda 函数相当于没有显式声明的函数，定义即用。</li>
<li>只能有一个单独的表达式<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">lambda x, y: x * y</div></pre></td></tr></table></figure>
</li>
</ul>
<p>相当于：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">def f(x, y):</div><div class="line">    return x * y</div></pre></td></tr></table></figure></p>
<h3 id="装饰器"><a href="#装饰器" class="headerlink" title="装饰器"></a>装饰器</h3><h3 id="偏函数"><a href="#偏函数" class="headerlink" title="偏函数"></a>偏函数</h3><p>当函数的参数个数太多，需要简化时，使用functools.partial可以创建一个新的函数，这个新函数可以固定住原函数的部分参数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">print(int(&apos;101&apos;, base=2))</div><div class="line"># 将str转int的int函数改装成2进制,固定base参数为2</div><div class="line">int2 = functools.partial(int, base=2)</div><div class="line">print(int2(&apos;101&apos;))</div></pre></td></tr></table></figure></p>
<h2 id="模块"><a href="#模块" class="headerlink" title="模块"></a>模块</h2><ul>
<li>在Python中，一个.py文件就称之为一个模块（Module）</li>
<li>按目录来组织模块的方法，称为包（Package）</li>
</ul>
<h3 id="使用模块"><a href="#使用模块" class="headerlink" title="使用模块"></a>使用模块</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">import module_name</div></pre></td></tr></table></figure>
<h3 id="安装第三方模块"><a href="#安装第三方模块" class="headerlink" title="安装第三方模块"></a>安装第三方模块</h3><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><ul>
<li>第三方模块搜索：<a href="pypi.python.org">下载地址</a></li>
<li>pip安装:比如要做图片处理Pillow，<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip install Pillow</div></pre></td></tr></table></figure>
</li>
</ul>
<p>图片压缩<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">from PIL import Image</div><div class="line"></div><div class="line">im = Image.open(&apos;xiaolan.jpg&apos;)</div><div class="line">print(im.format, im.size, im.mode)</div><div class="line">im.thumbnail((400, 400))</div><div class="line">im.save(&apos;xiaolan.png&apos;, &apos;JPEG&apos;)</div></pre></td></tr></table></figure></p>
<h4 id="模块搜索路径"><a href="#模块搜索路径" class="headerlink" title="模块搜索路径"></a>模块搜索路径</h4><p>Python解释器会搜索当前目录、所有已安装的内置模块和第三方模块。搜索路径存放在sys模块的path变量中,查看sys.path<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">import sys</div><div class="line">print(sys.path)</div></pre></td></tr></table></figure></p>
<p>如果我们要添加自己的搜索目录，有两种方法：  </p>
<ol>
<li>一是直接修改sys.path，添加要搜索的目录：<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&gt;&gt;&gt; import sys</div><div class="line">&gt;&gt;&gt; sys.path.append(&apos;/Users/michael/my_py_scripts&apos;)</div></pre></td></tr></table></figure>
</li>
</ol>
<p>这种方法是在运行时修改，运行结束后失效。</p>
<ol>
<li>第二种方法是设置环境变量PYTHONPATH，该环境变量的内容会被自动添加到模块搜索路径中。</li>
</ol>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000" target="_blank" rel="external">http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000</a><br><a href="http://blog.csdn.net/pipisorry/article/details/39909057" target="_blank" rel="external">http://blog.csdn.net/pipisorry/article/details/39909057</a>  </p>
</the></excerpt>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[druid.io实践2---集群数据迁移]]></title>
      <url>https://fangyeqing.github.io/2016/10/29/druid.io%E5%AE%9E%E8%B7%B52---%E9%9B%86%E7%BE%A4%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB/</url>
      <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br>数据迁移指的是两套Druid、kafka、HDFS集群之间的数据迁移。其中会用到流处理框架Samza，Hadoop distcp命令，Druid重建索引的insert-segment-to-db工具。</excerpt></p>
<h2 id="整体流程"><a href="#整体流程" class="headerlink" title="整体流程"></a>整体流程</h2><p><img src="http://note.youdao.com/yws/public/resource/eb83866d6603d9a10ca5134681ab7970/xmlnote/5525411332C94BC395CFC3E7EF21F06A/23416" alt="image"></p>
<a id="more"></a>  
<p><the rest="" of="" contents="" |="" 余下全文="">   </the></p>
<h3 id="背景交代"><a href="#背景交代" class="headerlink" title="背景交代"></a>背景交代</h3><p>Druid的DeepStorage采用HDFS。</p>
<p>实时输入流通过tranquility从kafka消费topic进行realtime indexing。<br>批量数据通过camus拉取kafka数据到hdfs，周期提交batch indexing。  </p>
<h3 id="大体思路"><a href="#大体思路" class="headerlink" title="大体思路"></a>大体思路</h3><ul>
<li>kafka镜像流：<br>启动samza任务，从老的kafka集群consume消息，produce到新的kafka集群。直接使用kafka的mirror也可以，由于项目使用的arvo编解码，涉及到schema-id的问题，所以只能通过samza任务。</li>
<li>druid批量数据获取&amp;index：<br>给新druid集群提交任务，camus批量拉取数据，发送post请求提交配置json到overload执行batch index。 </li>
<li>脏数据覆盖(批量路线稳定、数据正确之后)  <ul>
<li>利用hadoop-distcp迁移老hdfs中之前所有的segment数据</li>
<li>利用insert-segment-to-db工具在mysql生成这之前的元数据（索引）。</li>
</ul>
</li>
<li>druid实时数据获取&amp;index：<br>Tranquility任务，获取实时数据，提交给overload执行realtime index   </li>
<li>切换（稳定后）<br>将老的kafka的流的生产者逐个切换到新的kafka上</li>
</ul>
<h2 id="使用工具介绍"><a href="#使用工具介绍" class="headerlink" title="使用工具介绍"></a>使用工具介绍</h2><h3 id="Samza-Task"><a href="#Samza-Task" class="headerlink" title="Samza Task"></a>Samza Task</h3><p>可以参考博客中的<a href="https://fangyeqing.github.io/categories/samza/">Samza相关</a></p>
<h3 id="hadoop-distcp"><a href="#hadoop-distcp" class="headerlink" title="hadoop-distcp"></a>hadoop-distcp</h3><p>迁移老hdfs中之前所有的segment数据  </p>
<h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>DistCp（分布式拷贝）是用于大规模集群内部和集群之间拷贝的工具。 它使用Map/Reduce实现文件分发，错误处理和恢复，以及报告生成。 它把文件和目录的列表作为map任务的输入，每个任务会完成源列表中部分文件的拷贝</p>
<p><a href="https://hadoop.apache.org/docs/r1.0.4/cn/distcp.html" target="_blank" rel="external">https://hadoop.apache.org/docs/r1.0.4/cn/distcp.html</a>  </p>
<p><a href="http://hadoop.apache.org/docs/r2.7.3/hadoop-distcp/DistCp.html" target="_blank" rel="external">http://hadoop.apache.org/docs/r2.7.3/hadoop-distcp/DistCp.html</a>  </p>
<p><a href="http://stackoverflow.com/questions/31862904/how-to-do-i-copy-data-from-one-hdfs-to-another-hdfs" target="_blank" rel="external">http://stackoverflow.com/questions/31862904/how-to-do-i-copy-data-from-one-hdfs-to-another-hdfs</a>  </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Usage: $ hadoop distcp &lt;src&gt; &lt;dst&gt;</div><div class="line"></div><div class="line">example: $ hadoop distcp hdfs://nn1:8020/file1 hdfs://nn2:8020/file2</div></pre></td></tr></table></figure>
<p>默认情况下，如果在拷贝的目的地同名文件已经存在，则会默认跳过这些文件。  </p>
<p>可以通过-overwrite选项指定覆盖掉同名文件，或者通过-update选项来更新同名文件。</p>
<p>-overwrite来覆盖刚开启批量任务时的数据不完整那个小时的数据。</p>
<h3 id="insert-segment-to-db"><a href="#insert-segment-to-db" class="headerlink" title="insert-segment-to-db"></a>insert-segment-to-db</h3><h4 id="介绍-1"><a href="#介绍-1" class="headerlink" title="介绍"></a>介绍</h4><p>HDFS上Segment在新的mysql中生成索引    </p>
<p><a href="https://groups.google.com/forum/#!searchin/druid-user/migration$20cluster|sort:relevance/druid-user/1dOMkCrQGmE/b8exkaI4CwAJ" target="_blank" rel="external">https://groups.google.com/forum/#!searchin/druid-user/migration$20cluster|sort:relevance/druid-user/1dOMkCrQGmE/b8exkaI4CwAJ</a><br><a href="https://groups.google.com/forum/#!topic/druid-user/yvnXsDEOkDU" target="_blank" rel="external">https://groups.google.com/forum/#!topic/druid-user/yvnXsDEOkDU</a><br><a href="http://druid.io/docs/0.9.1.1/operations/insert-segment-to-db.html" target="_blank" rel="external">http://druid.io/docs/0.9.1.1/operations/insert-segment-to-db.html</a></p>
<h4 id="参数说明"><a href="#参数说明" class="headerlink" title="参数说明"></a>参数说明</h4><p>–workingDir：segment位置  </p>
<p>–updateDescriptor：默认true，如果desciptor.json的实际路径与“loadSpec”中的路径是不同的，该工具将更新“loadSpec”字段的描述符。 </p>
<p>例如：将老集群的数据迁移过去之后，desciptor.json中的路径没变，生成索引时会更新成现在的路径<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">hadoop fs -cat hdfs://nn1:port/.../dataSource/20161025T060000.000+0800_20161025T070000.000+0800/2016-10-25T07_33_53.379+08_00/0/descriptor.json</div><div class="line"></div><div class="line">其中loadSpec部分：</div><div class="line"></div><div class="line">&quot;loadSpec&quot;: &#123;</div><div class="line">    &quot;type&quot;: &quot;hdfs&quot;,</div><div class="line">    &quot;path&quot;: &quot;hdfs://nn1:port/.../dataSource/20161025T060000.000+0800_20161025T070000.000+0800/2016-10-25T07_33_53.379+08_00/0/index.zip&quot;</div><div class="line">&#125;,</div></pre></td></tr></table></figure></p>
<h4 id="具体操作"><a href="#具体操作" class="headerlink" title="具体操作"></a>具体操作</h4><p>官方例子<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">java </div><div class="line">-Ddruid.metadata.storage.type=mysql </div><div class="line">-Ddruid.metadata.storage.connector.connectURI=jdbc:mysql://mysql-db:3306/druid</div><div class="line">-Ddruid.metadata.storage.connector.user=userxxx</div><div class="line">-Ddruid.metadata.storage.connector.password=passxxxx</div><div class="line">-Ddruid.extensions.loadList=[\&quot;mysql-metadata-storage\&quot;,\&quot;druid-hdfs-storage\&quot;] </div><div class="line">-Ddruid.storage.type=hdfs</div><div class="line">-cp $DRUID_CLASSPATH </div><div class="line">io.druid.cli.Main tools insert-segment-to-db --workingDir hdfs://nn1:port/.../dataSource</div></pre></td></tr></table></figure></p>
<p>打印的日志：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">2016-10-25T17:15:49,342 INFO [main] io.druid.storage.hdfs.HdfsDataSegmentFinder - Found segment [dataSource_2016-01-13T09:00:00.000+08:00_2016-01-13T10:00:00.000+08:00_2016-01-13T10:34:03.820+08:00_6] located at [hdfs://nn1:port/.../dataSource/20160113T090000.000+0800_20160113T100000.000+0800/2016-01-13T10_34_03.820+08_00/6/index.zip]</div><div class="line">2016-10-25T17:15:49,342 INFO [main] io.druid.storage.hdfs.HdfsDataSegmentFinder - Updating loadSpec in descriptor.json at [hdfs://nn1:port/.../dataSource/20160113T090000.000+0800_20160113T100000.000+0800/2016-01-13T10_34_03.820+08_00/6/descriptor.json] with new path [dataSource/20160113T090000.000+0800_20160113T100000.000+0800/2016-01-13T10_34_03.820+08_00/6/index.zip]</div></pre></td></tr></table></figure></p>
<p>会先更新descriptor.json中的路径：由之前的老集群的绝对路径—新集群的相对路径</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[druid.io实践1---查询速度优化]]></title>
      <url>https://fangyeqing.github.io/2016/10/29/druid.io%E5%AE%9E%E8%B7%B51---%E6%9F%A5%E8%AF%A2%E9%80%9F%E5%BA%A6%E4%BC%98%E5%8C%96/</url>
      <content type="html"><![CDATA[<excerpt in="" index="" |="" 首页摘要="">   

<p>当数据维度比较多，存储时间比较长时，数据量会增加到到T级别。如果historical节点只是单机版，查询会特别慢。在生产过程中，主要做了以下几点优化：</p>
<a id="more"></a>  
<the rest="" of="" contents="" |="" 余下全文=""> 

<h2 id="增加缓存"><a href="#增加缓存" class="headerlink" title="增加缓存"></a>增加缓存</h2><p>当集群机器较少时(官方文档推荐&lt;20台)，在broker节点配置缓存，可以适当增加缓存大小，或者从local替换成memcached。</p>
<p>当集群机器较多时，应当只配置historical节点缓存，减轻broker节点压力。</p>
<h3 id="附：broker部分配置"><a href="#附：broker部分配置" class="headerlink" title="附：broker部分配置"></a>附：broker部分配置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"># Query cache</div><div class="line">druid.broker.cache.useCache=true</div><div class="line">druid.broker.cache.populateCache=true</div><div class="line">druid.cache.type=local</div><div class="line">druid.cache.sizeInBytes=2000000000</div></pre></td></tr></table></figure>
<h2 id="historical节点集群化"><a href="#historical节点集群化" class="headerlink" title="historical节点集群化"></a>historical节点集群化</h2><p>查询为CPU密集型，通过合理的数据分配策略，使数据尽量分散在不同的历史节点。</p>
<h3 id="集群分片"><a href="#集群分片" class="headerlink" title="集群分片"></a>集群分片</h3><p>可以根据查询频率的高低分为冷热数据，公司经常查40天内的数据，40天内的数据显然是hot数据。 </p>
<p>这里涉及到coordinate节点的Load Rules配置，druid 0.9版本有coordinator的UI界面，可以设置每个dataSource的Load Rules。如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">  &quot;type&quot; : &quot;loadByPeriod&quot;,</div><div class="line">  &quot;period&quot; : &quot;P40D&quot;,</div><div class="line">  &quot;tieredReplicants&quot;: &#123;</div><div class="line">      &quot;hot&quot;: 1,</div><div class="line">      &quot;_default_tier&quot; : 1</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line">&#123;</div><div class="line">  &quot;type&quot; : &quot;loadForever&quot;,  </div><div class="line">  &quot;tieredReplicants&quot;: &#123;</div><div class="line">    &quot;_default_tier&quot; : 1</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这里设置了两个Load Rules，loadByPeriod部分表示40天内的数据在hot和_default_tier分片各保存一份副本。loadForever部分表示所有数据在_default_tier保存一份。</p>
<h3 id="增加分片的节点数"><a href="#增加分片的节点数" class="headerlink" title="增加分片的节点数"></a>增加分片的节点数</h3><p>增加_default_tier和hot分片的节点数，并且节点存储空间尽量一致，使segment均匀分散在节点间，降低查询时每个historical节点的CPU负载。</p>
<p>例如：_default_tier分片增加到2-3台，hot分片增加到5-10台机器，热数据分散到更多台。 </p>
<h3 id="调整历史节点配置参数"><a href="#调整历史节点配置参数" class="headerlink" title="调整历史节点配置参数"></a>调整历史节点配置参数</h3><h4 id="druid-server-priority"><a href="#druid-server-priority" class="headerlink" title="druid.server.priority"></a>druid.server.priority</h4><p>默认为0。</p>
<p>broker节点中，druid.broker.select.tier的配置默认为highestPriority，表示如果有重复的数据样本，优先查询优先级高的历史节点。</p>
<p>例如：将hot分片的机器druid.server.priority设置为100，_default_tier分片的默认0，则查询热数据时，不会查询_default_tier，只会去查询hot，而hot集群机器比较多，查询速度快。</p>
<h4 id="druid-processing-numThreads"><a href="#druid-processing-numThreads" class="headerlink" title="druid.processing.numThreads"></a>druid.processing.numThreads</h4><p>可以根据自己机器的情况进行调节，如果机器只用于历史节点，可以设置为（核心数-1），32核机器可以设置为31，或者默认值就是31。</p>
<h4 id="druid-segmentCache-locations"><a href="#druid-segmentCache-locations" class="headerlink" title="druid.segmentCache.locations"></a>druid.segmentCache.locations</h4><p>可以将数据存储分散在不同的磁盘上，可以减轻磁盘的读写压力。</p>
<h4 id="附：history节点部分配置"><a href="#附：history节点部分配置" class="headerlink" title="附：history节点部分配置"></a>附：history节点部分配置</h4><p>hot集群中调优查询速度的相关配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">#集群分片，不写默认_default_tier</div><div class="line">druid.server.tier=hot  </div><div class="line">#查询优先级，不写默认0，_default_tier分片的两个节点为0，hot节点的都改为100。这样，热数据只会查hot节点的机器。</div><div class="line">druid.server.priority=100</div><div class="line"></div><div class="line">#processing.buff，可以注释掉，默认是1G</div><div class="line">#processing.numThreads:默认是繁忙时core-1做process，剩余的1个进程做与zk通信和拉取seg等。</div><div class="line">druid.processing.buffer.sizeBytes=1073741824</div><div class="line">druid.processing.numThreads=31</div><div class="line"></div><div class="line">#segment路径和各路径的空间，例如：在disk1、2、3各配了200G</div><div class="line">druid.segmentCache.locations=[&#123;&quot;path&quot;: &quot;/disk1/druid-0.9.1.1-historical-data/persistent&quot;, &quot;maxSize&quot;: 200000000000&#125;,&#123;&quot;path&quot;: &quot;/disk2/druid-0.9.1.1-historical-data/persistent&quot;, &quot;maxSize&quot;: 200000000000&#125;,&#123;&quot;path&quot;: &quot;/disk3/druid-0.9.1.1-historical-data/persistent&quot;, &quot;maxSize&quot;: 200000000000&#125;]</div><div class="line">#segment总空间（字节）=上述空间之和</div><div class="line">druid.server.maxSize=600000000000</div></pre></td></tr></table></figure></p>
<h2 id="老数据roll-up"><a href="#老数据roll-up" class="headerlink" title="老数据roll up"></a>老数据roll up</h2><p>进行实时和批量indexing的时候，一般配置的按小时的粒度进行roll up，最后存储的就是按小时聚合的数据。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">&quot;granularitySpec&quot;: &#123;</div><div class="line">    &quot;type&quot;: &quot;uniform&quot;,</div><div class="line">    &quot;segmentGranularity&quot;: &quot;HOUR&quot;,</div><div class="line">    &quot;queryGranularity&quot;: &quot;HOUR&quot;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>当数据积累较长时间后，按小时聚合必然数据量巨大，可以将不常用或者不太重要的数据，按天存储，数据量会大大减小，必然可以提高查询速度。</p>
<p>例如：将40天之后的数据提交batch indexing任务按天roll up。</p>
</the></excerpt>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[druid.io 3---druid数据]]></title>
      <url>https://fangyeqing.github.io/2016/10/29/druid.io_3---druid%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3/</url>
      <content type="html"><![CDATA[<excerpt in="" index="" |="" 首页摘要="">   

<h2 id="数据格式"><a href="#数据格式" class="headerlink" title="数据格式"></a>数据格式</h2><ul>
<li><strong>Timestamp列</strong>: 所有的查询都以时间为中心。  </li>
<li><strong>Dimension列（维度）</strong>: Dimensions对应事件的维度,通常用于筛选过滤数据。</li>
<li><strong>Metric列（度量）</strong>: Metrics是用于聚合和计算的列。通常是数字,并且支持count、sum、mean等聚合操作。<br>线上广告的例子：</li>
</ul>
<a id="more"></a>  
<the rest="" of="" contents="" |="" 余下全文=""> 

<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">timestamp             publisher          advertiser  gender  country  click  price</div><div class="line">2011-01-01T01:01:35Z  bieberfever.com    google.com  Male    USA      0      0.65</div><div class="line">2011-01-01T01:03:63Z  bieberfever.com    google.com  Male    USA      0      0.62</div><div class="line">2011-01-01T01:04:51Z  bieberfever.com    google.com  Male    USA      1      0.45</div><div class="line">2011-01-01T01:00:00Z  ultratrimfast.com  google.com  Female  UK       0      0.87</div><div class="line">2011-01-01T02:00:00Z  ultratrimfast.com  google.com  Female  UK       0      0.99</div><div class="line">2011-01-01T02:00:00Z  ultratrimfast.com  google.com  Female  UK       1      1.53</div></pre></td></tr></table></figure>
<p>dimensions: publisher, advertiser, gender, and country。<br>metrics: click和price</p>
<h2 id="预聚合roll-up"><a href="#预聚合roll-up" class="headerlink" title="预聚合roll up"></a>预聚合roll up</h2><p>Roll-up是在一系列维度选定后的数据之上做的初始聚合，一般发生在push/pull数据流阶段，通过realtime node或者tranquility+indexing service的方式。    </p>
<p>通过queryGranularity定义数据roll up的粒度。  </p>
<p>这种预聚合的方式可以很显著的减少数据的存储(可减少100倍)。 Druid也是通过这种方式来减少数据的存储。 这种减少存储的方式也会带来副作用,比如我们没有办法再查询到每条数据具体的明细。换句话说,数据聚合的粒度是我们能查询数据的最小粒度。  </p>
<p>例如定义粒度为HOUR<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">GROUP BY timestamp, publisher, advertiser, gender, country</div><div class="line">  :: impressions = COUNT(1),  clicks = SUM(click),  revenue = SUM(price)</div></pre></td></tr></table></figure></p>
<p>上述例子聚合之后为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">timestamp             publisher          advertiser  gender country impressions clicks revenue</div><div class="line">2011-01-01T01:00:00Z  ultratrimfast.com  google.com  Male   USA     1800        25     15.70</div><div class="line">2011-01-01T01:00:00Z  bieberfever.com    google.com  Male   USA     2912        42     29.18</div><div class="line">2011-01-01T02:00:00Z  ultratrimfast.com  google.com  Male   UK      1953        17     17.31</div><div class="line">2011-01-01T02:00:00Z  bieberfever.com    google.com  Male   UK      3194        170    34.01</div></pre></td></tr></table></figure></p>
<p>也可以将过久时间的历史数据进行自定义的roll up操作，例如近90天的数据按小时进行roll up预处理，然后将90天之后的数据提交batch indexing任务按天roll up。</p>
<h2 id="数据分片"><a href="#数据分片" class="headerlink" title="数据分片"></a>数据分片</h2><p>以segments(段)的形式就行分片,并且以时间作为第一级分片。  </p>
<p>Segments是自包含容器,包含着一个时间段内的数据，通过segmentGranularity定义segments的分片时间粒度。<br>Segments包括基于列的压缩,以及这些列的索引。Druid只需要清楚如何扫描这些segments就可以查询。</p>
<p>Segments通过datasource, interval, version, 和一个可选的partition number来区分。   </p>
<blockquote>
<p>dataSource_interval_version_partitionNumber。</p>
</blockquote>
<p>例如：<br>Segment sampleData_2011-01-01T01:00:00:00Z_2011-01-01T02:00:00:00Z_v1_0 包含<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">2011-01-01T01:00:00Z  ultratrimfast.com  google.com  Male   USA     1800        25     15.70</div><div class="line">2011-01-01T01:00:00Z  bieberfever.com    google.com  Male   USA     2912        42     29.18</div></pre></td></tr></table></figure></p>
<p>Segment sampleData_2011-01-01T02:00:00:00Z_2011-01-01T03:00:00:00Z_v1_0 包含<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">2011-01-01T02:00:00Z  ultratrimfast.com  google.com  Male   UK      1953        17     17.31</div><div class="line">2011-01-01T02:00:00Z  bieberfever.com    google.com  Male   UK      3194        170    34.01</div></pre></td></tr></table></figure></p>
<h2 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h2><p><strong>MVCC</strong>：多版本控制，以HDFS作为DeepStorage为例，HDFS上会保存每次修改的版本，history节点只load最新的数据，即用最新的版本来表示数据。</p>
<p>druid在0.9版本之后，HDFS上存储格式如下:</p>
<p><strong>hdfs://nn1:port/…/ sampleData / startTime_endTime / updateTime / shard / index.zip</strong><br><strong>hdfs://nn1:port/…/ sampleData / startTime_endTime / updateTime / shard / descriptor.json</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">startTime_endTime:看聚合粒度，可能是1个小时之内，可能是1天之内</div><div class="line">updateTime：修改时间，即版本号。取最新的一个版本</div><div class="line">shard:分片，数据比较多，一个分片放不下</div></pre></td></tr></table></figure></p>
<h3 id="HDFS存储举例"><a href="#HDFS存储举例" class="headerlink" title="HDFS存储举例"></a>HDFS存储举例</h3><p><strong>hdfs://nn1:port/…/sampleData/20160801T120000.000+0800_20160801T130000.000+0800/</strong><br>目录下有如下两个版本：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">2016-08-01T12_07_40.483+08_00/	rwxr-xr-x	root/supergroup	    2016-08-01 13:15:12</div><div class="line">2016-08-01T13_17_06.199+08_00/	rwxr-xr-x	root/supergroup	    2016-08-01 13:23:40</div></pre></td></tr></table></figure></p>
<p><strong>2016-08-01T13_17_06.199+08_00</strong>目录下有3个分片：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">0/	rwxr-xr-x	root/supergroup	2016-08-01 13:23:05</div><div class="line">1/	rwxr-xr-x	root/supergroup	2016-08-01 13:23:11</div><div class="line">2/	rwxr-xr-x	root/supergroup	2016-08-01 13:23:46</div></pre></td></tr></table></figure></p>
<p><strong>0/</strong>目录下有两个文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">descriptor.json	rw-r--r--	eadata/supergroup	766 B	128 mb	3	2016-08-01 13:23:05</div><div class="line">index.zip	rw-r--r--	eadata/supergroup	5.56 mb	128 mb	3	2016-08-01 13:23:04</div></pre></td></tr></table></figure></p>
<p>descriptor.json保存的信息：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">    &quot;dataSource&quot;: &quot;sampleData&quot;,//数据源</div><div class="line">    &quot;interval&quot;: &quot;2016-08-01T12:00:00.000+08:00/2016-08-01T13:00:00.000+08:00&quot;,//时间区间</div><div class="line">    &quot;version&quot;: &quot;2016-08-01T13:17:06.199+08:00&quot;,//版本号，即修改时间</div><div class="line">    &quot;loadSpec&quot;: &#123;//存储路径</div><div class="line">        &quot;type&quot;: &quot;hdfs&quot;,</div><div class="line">        &quot;path&quot;: &quot;hdfs://nn1:port/..../sampleData/20160801T120000.000+0800_20160801T130000.000+0800/2016-08-01T13_17_06.199+08_00/0/index.zip&quot;</div><div class="line">    &#125;,</div><div class="line">    &quot;dimensions&quot;: &quot;publisher,advertiser,gender,country&quot;,</div><div class="line">    &quot;metrics&quot;: &quot;click,price&quot;,</div><div class="line">    &quot;shardSpec&quot;: &#123;//分片信息</div><div class="line">        &quot;type&quot;: &quot;hashed&quot;,</div><div class="line">        &quot;partitionNum&quot;: 0,</div><div class="line">        &quot;partitions&quot;: 3,</div><div class="line">        &quot;partitionDimensions&quot;: []</div><div class="line">    &#125;,</div><div class="line">    &quot;binaryVersion&quot;: 9,</div><div class="line">    &quot;size&quot;: 8959843,//index.zip解压后的大小</div><div class="line">    &quot;identifier&quot;: &quot;sampleData_2016-08-01T12:00:00.000+08:00_2016-08-01T13:00:00.000+08:00_2016-08-01T13:17:06.199+08:00&quot;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>当historical节点加载HDFS中的segment到本地存储时，会解压index.zip，解压出00000.smoosh、meta.smoosh、version.bin三个文件。保存在本地路径:</p>
<blockquote>
<p>druid.segmentCache.locations / sampleData / startTime_endTime / updateTime / shard   </p>
</blockquote>
<p>descriptor.json保存在本地路径：</p>
<blockquote>
<p>druid.segmentCache.locations / info_dir / sampleData / startTime_endTime / updateTime / shard</p>
</blockquote>
<p>druid.segmentCache.locations在historical节点配置中配置。</p>
<p><del>druid在0.9版本之前，realtime index放在上述路径中，batch（批量）任务会放在：<br>datasource / datasource / startTime_endTime / updateTime /shard / index.zip</del></p>
<h2 id="数据索引"><a href="#数据索引" class="headerlink" title="数据索引"></a>数据索引</h2><p>Druid是列式存储,每一个列都是单独存储,在查询的过程中只扫描查询所需的列即可。不同的列可以采用不同的压缩方式,也可以关联不同的索引。  </p>
<p>Druid的索引是基于每一个分片(即segment)上的。</p>
<h2 id="数据加载"><a href="#数据加载" class="headerlink" title="数据加载"></a>数据加载</h2><p>Druid使用的通常情况是,联合使用批量和实时数据流的加载方法。近期的数据通过实时方式处理,离线批量处理来来提高精度。 </p>
<p>在一些网络抖动延迟的非正常场景中，实时数据流加载方式有可能出现消息丢失或者消息重复，因此批量再加载方式消除了这种历史数据的潜在错误。或者由于某种原因，需要修改数据，批量再加载方式也提供给你再加载数据的选项。</p>
<h3 id="实时方式"><a href="#实时方式" class="headerlink" title="实时方式"></a>实时方式</h3><ul>
<li>Stream push <ul>
<li><strong>Tranquility+indexing service</strong>，数据来自于一个数据流系统，如Kafka、Storm、Spark Streaming。Tranquility：一个发送数据流到Druid的http客户端。</li>
</ul>
</li>
<li>Stream pull <ul>
<li><strong>Realtime Node</strong>，直接从外部数据源拉数据流进入Druid。  <h3 id="离线批处理方式"><a href="#离线批处理方式" class="headerlink" title="离线批处理方式"></a>离线批处理方式</h3></li>
</ul>
</li>
<li>Files <ul>
<li><strong>Batch Data Ingestion+indexing service</strong>，从HDFS、S3、本地文件、或者其他支持批处理的Hadoop文件系统加载数据。如果在平面文件中你的数据集已经准备好，我们建议使用这种方法。例如：利用camus从kafka拉取数据到hdfs，再利用批处理从hdfs。  </li>
</ul>
</li>
</ul>
<p>下图中，上面的indexing service为realtime，下面的为Batch Data Ingestion<br><img src="http://note.youdao.com/yws/public/resource/32442f2d923ee4564e15f34e1a33fdd5/D6B38A53DFD740328C51FD6093A90BE7" alt="image"></p>
<h2 id="数据查询"><a href="#数据查询" class="headerlink" title="数据查询"></a>数据查询</h2><p>Druid原生的查询方式是通过http发送json,但是社区已经贡献出多种查询库,包括SQL方式的plyql。</p>
<p>Druid被设计为执行单表操作,不支持join操纵(实际上可以做join)。 生产环境需要在ETL阶段进行join,因为数据在加载进Druid之前必须规范化。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://druid.io/docs/0.9.1.1/design/index.html" target="_blank" rel="external">druid.io</a><br><a href="http://druidio.cn/docs/0.9.0/design/" target="_blank" rel="external">druidio.cn</a><br><a href="http://lxw1234.com/archives/2015/11/563.htm" target="_blank" rel="external">lxw的大数据田地–Druid.io实时OLAP数据分析存储系统介绍</a><br><a href="http://dj1211.com/?p=702" target="_blank" rel="external">萌の宇博客–realtime node与index server区别</a><br><a href="http://zqhxuyuan.github.io/2015/12/03/2015-12-03-Druid-Design/#Concepts" target="_blank" rel="external">zqhxuyuan博客–Druid OLAP架构设计</a></p>
</the></excerpt>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[druid.io 2---druid介绍]]></title>
      <url>https://fangyeqing.github.io/2016/10/29/druid.io_2---druid%E4%BB%8B%E7%BB%8D/</url>
      <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要="">   </excerpt></p>
<h2 id="Druid概念"><a href="#Druid概念" class="headerlink" title="Druid概念"></a>Druid概念</h2><p>Druid是一个为大型冷数据集上实时探索查询而设计的开源数据分析和存储系统，提供极具成本效益并且永远在线的实时数据摄取和任意数据处理。  </p>
<p>Druid 是一个开源的，分布式的，列存储的，适用于实时数据分析的存储系统，能够快速聚合、灵活过滤、毫秒级查询、和低延迟数据导入。</p>
<a id="more"></a>  
<p><the rest="" of="" contents="" |="" 余下全文=""><br>优势：</the></p>
<ul>
<li>高容错性：单个节点挂掉不会影响其他部分。详情在<a href="#容错性">文末</a>有介绍。 </li>
<li>多版本控制（MVCC）：通过数据更新时间来区分版本，历史节点只加载最新版本数据。支持实时数据indexing与批量数据indexing同时进行，实时数据索引满足实时需求，批量数据覆盖实时数据满足准确性需求。详情见<a href="https://fangyeqing.github.io/2016/10/29/druid.io_3---druid%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3/#数据加载">druid数据加载</a>。</li>
<li>高聚合性：数据roll up预处理，减少存储数据量。详情见<a href="https://fangyeqing.github.io/2016/10/29/druid.io_3---druid%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3/#预聚合roll-up">druid预聚合roll-up</a>。</li>
<li>高压缩度：使用Bitmap indexing加速列存储的查询速度，并使用CONCISE算法来对bitmap indexing进行压缩，使得生成的segments比原始文本文件小很多  </li>
</ul>
<h2 id="集群组成"><a href="#集群组成" class="headerlink" title="集群组成"></a>集群组成</h2><p>Druid集群包含不同类型的节点，而每种节点都被设计来做好某组事情。这样的设计可以隔离关注并简化整个系统的复杂度。不同节点的运转几乎都是独立的并且和其他的节点有着最小化的交互，因此集群内的通信故障对于数据可用性的影响非常小。</p>
<p>主要分为四大部分：数据生产、数据存储、数据查询、外部依赖。本小节先做一个简单的介绍，后面每个部分会有详细介绍。</p>
<p><img src="http://druidio.cn/docs/img/druid-dataflow-3.png" alt="image"></p>
<h3 id="数据生产"><a href="#数据生产" class="headerlink" title="数据生产"></a>数据生产</h3><ul>
<li>Indexing Service 索引服务节点：<br>由多个worker组成的集群，负责为加载批量的和实时的数据创建索引，并且允许对已经存在的数据进行修改。</li>
<li>Realtime 实时节点：<br>负责加载实时的数据到系统中，在生产使用的几个限制成本上实时节点比索引服务节点更容易搭建。</li>
</ul>
<p>实时数据和批量数据加载的两种方式在上一篇druid数据相关中介绍到了，就不赘述。</p>
<h3 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h3><ul>
<li>Coordinator 协调节点：<br>对历史节点的分组进行监控，以确保数据可用，和最佳的配置。协调节点通过从元数据存储中读取元数据信息来判断哪些segments是应该加载到集群的，使用Zookeeper去判断哪些历史节点是存活的，在Zookeeper中创建任务条目告诉历史节点去加载和删除segments。</li>
<li>Historical 历史节点：<br>负责处理历史数据存储和查询历史数据（非实时），历史节点从“deep storage”下载segments，将结果数据返回给broker节点，historical加载完segment通知Zookeeper，Historical nodes使用Zookeeper监控需要加载或者删除哪些新的segments。</li>
</ul>
<h3 id="数据查询"><a href="#数据查询" class="headerlink" title="数据查询"></a>数据查询</h3><ul>
<li>Broker 代理节点<br>接收来自外部client的查询请求，并转发这些请求给实时节点和历史节点，当代理节点接收到结果时，将来自实时节点和历史节点的结果合并返回给调用方。为了知道整个拓扑结构，代理节点通过使用Zookeeper在确定哪些实时节点和历史节点存活。</li>
</ul>
<h3 id="外部依赖"><a href="#外部依赖" class="headerlink" title="外部依赖"></a>外部依赖</h3><p>Druid的集群需要有一些外部依赖。  </p>
<ul>
<li>Zookeeper</li>
<li>Metadata Storage</li>
<li>Deep Storage</li>
</ul>
<h2 id="Indexing-Service"><a href="#Indexing-Service" class="headerlink" title="Indexing Service"></a>Indexing Service</h2><p>索引服务负责<strong>实时</strong>和<strong>批量</strong>数据的导入、分析、索引、压缩，生成“segment”（数据段），存入Deep Storage（例如HDFS）。<br>实时数据通过<strong>Tranquility</strong>客户端，批量数据通过<strong>Batch Data Ingestion</strong>，将任务提交给overload，分配给Middle Manager创建Poen执行。  </p>
<h3 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h3><p>索引服务是主从结构，由三个部分组成：</p>
<ul>
<li>peon组件：在一个单独的jvm中运行单个任务，通过单独的jvm对任务做资源隔离和日志隔离。  </li>
<li>Middle Manager：用于创建和管理peon的中层管理组件  </li>
<li>overlord组件：管理任务分配到Middle Manager<br><img src="http://note.youdao.com/yws/public/resource/32442f2d923ee4564e15f34e1a33fdd5/8A3B9817DCAE4598A5D8582FB02E012E" alt="image"><br>综合Tranquility和整个系统之后：<br><img src="http://note.youdao.com/yws/public/resource/32442f2d923ee4564e15f34e1a33fdd5/26967A72BB75437786E663C1A91699D8" alt="image"> </li>
</ul>
<h3 id="流程："><a href="#流程：" class="headerlink" title="流程："></a>流程：</h3><ul>
<li>用户的spec文件在Tranquility中定义，首先Tranquility通过spec初始化，获得zk中Overlord的地址，与Overlord通信。</li>
<li>Overlord得到新写入任务后，查询zk节点信息，选择一个Middle Manager节点启动来启动peon，并将信息写入到zk中。</li>
<li>Middle Manager一直监控zk，发现有新的任务分配后，启动一个Peon进程，并监控Peon进程的状态。</li>
<li>Peon与Realtime Node流程基本一致，所不同的是Peon使用的是HTTP接口来接收数据，RealTime Node更多的是内部的线程不断的拉取Kafka的数据。</li>
<li>Tranquility随后通过zk获取Peon机器地址和端口，将数据不断的发送到Peon中。</li>
<li>Peon根据spec规则，定时或者定量将数据build index，handoff到deep storage(HDFS)中。</li>
<li>Coordinator根据Peon在zk中信息，将元数据写入到mysql中，并分配Historical Node去deep storage拉取index数据。</li>
<li>Historical Node到deep storage拉取index数据到本地，重建index到内存中，至此数据流入完成。</li>
</ul>
<h3 id="配置说明"><a href="#配置说明" class="headerlink" title="配置说明"></a>配置说明</h3><p>overload节点配置时<br>druid.indexer.runner.type=local表示overload以本地模式运行，overload同时负责Middle Manager的作用，创建poen和分配任务。local模式下，overload配置需要对poen进行配置。</p>
<h2 id="real-time-node"><a href="#real-time-node" class="headerlink" title="real-time node"></a>real-time node</h2><p>实时节点是进行存储和查询实时数据的工作区。在Zookeeper中通告它们的在线状态和为哪些数据提供服务。</p>
<p>存储：metadata(元数据)写入MySQL，在ZooKeeper中新增一条记录<br>    Segment定期会转存到DeepStorage<br>查询：提供实时查询索引，响应broker的查询   </p>
<p>下图中的master即为coordinator：<br><img src="http://note.youdao.com/yws/public/resource/32442f2d923ee4564e15f34e1a33fdd5/5D9BEA80D1E642C88D707A330CC9D618" alt="image"><br>具体存储过程：</p>
<ul>
<li>实时节点缓存事件数据到内存中的索引上，然后有规律的持久化到磁盘上。在转移之前，持久化的索引会周期性地合并在一起。（查询会同时命中内存中的和已持久化的索引。）  </li>
<li>实时节点周期性的启动后台的计划任务搜索本地的持久化索引，后台计划任务将这些持久化的索引合并到一起并生成一块不可变的数据，这些数据块包含了  </li>
<li>一段时间内的所有已经由实时节点导入的事件数据，称这些数据块为”Segment”。  </li>
<li>在传送阶段，实时节点将这些segment上传到一个永久持久化的备份存储中,即Deep Storage  </li>
</ul>
<h3 id="realtime-node与indexing-service导入数据的区别"><a href="#realtime-node与indexing-service导入数据的区别" class="headerlink" title="realtime node与indexing service导入数据的区别"></a>realtime node与indexing service导入数据的区别</h3><table>
<thead>
<tr>
<th>比较项</th>
<th>RealTime Node</th>
<th>Realtime Indexing Service</th>
</tr>
</thead>
<tbody>
<tr>
<td>角色</td>
<td>RealTime Node</td>
<td>Overloard Nodes，Middle Manager Nodes，Poens</td>
</tr>
<tr>
<td>部署方式</td>
<td>多台服务器或单台服务器上多个RTN，每个RTN指定不同的spec文件启动</td>
<td>仅部署Overloard Nodes和Middle Manager。Middle Manager创建poen去接收不同的realtime日志，不需要指定spec文件，由Tranquility客户端提供</td>
</tr>
<tr>
<td>使用方式</td>
<td>RTN通过spec文件指定消费的Kafka topic，不断的pull</td>
<td>Poen接收Tranquility客户端push过来的数据</td>
</tr>
<tr>
<td>可扩展性与易用性</td>
<td>通过加机器，启动更多的RealTime Nodes进行扩展，但是需要管理所有的RTN的spec文件，消费的各种属性信息，运维复杂</td>
<td>通过加机器，启动更多的Middle Managers来进行扩展，所有的日志消费属性信息都是通过Tranquility自己指定，运维简单</td>
</tr>
</tbody>
</table>
<p>随着Druid业务增多，规模扩大，对Realtime Node的管理变成了非常繁琐的事情，使用Realtime Index Service是必须的</p>
<h2 id="Coordinator-Node"><a href="#Coordinator-Node" class="headerlink" title="Coordinator Node"></a>Coordinator Node</h2><p>协调节点可以认为是Druid中的master，通过Zookeeper管理历史节的segment放置策略，且通过Mysql中的metadata管理数据段。主要作用：</p>
<ul>
<li>通过从元数据存储（MySQL）读取数据段的元数据信息，来决定哪些Segments应该在集群中被加载。</li>
<li>使用ZK来确定哪个Historical节点存在</li>
<li>创建ZK条目告诉Historical节点管理Segments：加载新的Segments,删除旧的Segments,或者移动Segments进行负载均衡。  </li>
</ul>
<h3 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h3><p>协调节点每次运行时，</p>
<p>计算每一个historical tier（节点层）利用率最高的和最低的差异值。  </p>
<p>如果差异超过某个阈值,部分segment将从最高的节点迁移到最低的节点，并且移动的segment是随机选择的。</p>
<p>每次协调节点运行时，能够迁移的segment的数量是可配置的。</p>
<h4 id="例子："><a href="#例子：" class="headerlink" title="例子："></a>例子：</h4><p>在实际生产过程中，hot节点层本身只有两台机器，增加hot层到5台。负载最高的机器数据会往低的迁移。到最后每台机器上的数据大致相等。</p>
<h2 id="Historical-Node"><a href="#Historical-Node" class="headerlink" title="Historical Node"></a>Historical Node</h2><p>历史节点负责加载历史Segment并且提供针对这些历史Segment的查询。Historical Nodes可分为多个tier， 比如热数据放在一个tier， 冷数据放到另外一个tier，以达到冷热数据分开处理的目的。</p>
<h3 id="Historical节点segment创建流程"><a href="#Historical节点segment创建流程" class="headerlink" title="Historical节点segment创建流程"></a>Historical节点segment创建流程</h3><ul>
<li>Coordinator在ZK下与Historical节点相关联的加载队列路径下创建一个临时记录。</li>
<li>每个历史节点与ZK保持一个长连接监测ZK。</li>
<li>当一个历史节点发现在Zookeeper中与它关联的加载队列目录下有一个新的加载记录时。</li>
<li>它首先检查本地磁盘目录（缓存）中关于新的Segment的信息。如果缓存中没有关于新的Segment的信息，历史节点将下载新的Segment的元数据信息并告知Zookeeper。元数据包含新的Segment在“Deep Storage”中的存储位置，怎样去解压缩和处理新的Segment的信息。</li>
<li>一旦一个历史节点处理完成一个Segment，该Segment在Zoookeeper与该节点关联的服务Segments路径中公布可以提供服务。</li>
<li>此刻，这个Segment可以用于查询。</li>
</ul>
<h2 id="Broker-Node"><a href="#Broker-Node" class="headerlink" title="Broker Node"></a>Broker Node</h2><p>broker（代理）提供针对segment的路由查询，代理节点从Zookeeper获取Segments存储在哪些节点和怎样找到正确的节点的元数据。将查询转发到Realtime和Historical节点。把来自于所有单个节点的结果合并在一起。  </p>
<h3 id="转发查询"><a href="#转发查询" class="headerlink" title="转发查询"></a>转发查询</h3><p>Zookeeper维护有关历史和实时的节点信息和他们所能提供服务的Segment。  </p>
<p>在Zookeeper的每一个数据源，代理节点建立相关Segments的时间轴和为这些Segments提供服务的节点。</p>
<p>当收到一个特定数据源和时间间隔的查询请求，代理节点执行查找与查询数据源时间间隔相关的时间轴和检索包含数据查询的节点。代理节点然后将查询转发到所选节点。</p>
<h3 id="缓存策略"><a href="#缓存策略" class="headerlink" title="缓存策略"></a>缓存策略</h3><p>Broker节点包含一个支持LRU失效策略的缓存。</p>
<ul>
<li>首先将这个查询映射到一组Segments，这些Segment结果的子集可能在缓存中已经存在，在缓存中已经存在的结果可以被直接拉取。  </li>
<li>对于一些缓存中不存在的结果。代理节点会转发查询到历史节点。一旦历史节点返回其结果，代理节点将结果存储到缓存中。  </li>
<li>实时节点返回的结果将永远不会被缓存，因此实时节点的查询请求将永远被转发到实时节点。实时节点的数据是不断变化的，缓存实时节点的结果是不可靠的。</li>
</ul>
<h2 id="外部依赖-1"><a href="#外部依赖-1" class="headerlink" title="外部依赖"></a>外部依赖</h2><p><img src="http://note.youdao.com/yws/public/resource/32442f2d923ee4564e15f34e1a33fdd5/0E59F34342744B8ABBDCE92DA750B186" alt="image"></p>
<h3 id="Metadata-Storage（Mysql）"><a href="#Metadata-Storage（Mysql）" class="headerlink" title="Metadata Storage（Mysql）"></a>Metadata Storage（Mysql）</h3><p>存储segments的元数据和配置，而不是存储实际数据，包含3张表：<br>“druid_config”（通常是空的）,<br>“druid_rules”（协作节点使用的一些规则信息，比如哪个segment从哪个node去load）<br>“druid_segments”（存储 每个segment的metadata信息） </p>
<h3 id="Deep-storage"><a href="#Deep-storage" class="headerlink" title="Deep storage"></a>Deep storage</h3><p>segments的永久备份，Druid目前已经支持本地磁盘、NFS挂载磁盘、HDFS、S3等。<br>创建segments的服务上传segments到Deep storage,然后historical节点下载。  </p>
<h3 id="ZooKeeper"><a href="#ZooKeeper" class="headerlink" title="ZooKeeper"></a>ZooKeeper</h3><p>管理当前集群状态, 发现和维持当前的数据拓扑。（节点状态、数据操作、数据同步） </p>
<ul>
<li>realtime-node和historical-node在Zookeeper中通告它们的在线状态和为哪些数据提供服务。 </li>
<li>管理当前cluster的状态，比如记录哪些segments从实时节点移到了历史节点  </li>
</ul>
<p>主要发生：</p>
<ul>
<li>协调节点的leader选举</li>
<li>历史和实时节点发布segment协议</li>
<li>协调节点和历史节点之间的segment Load/Drop协议</li>
<li>overlord的leader选举</li>
<li>索引服务任务管理</li>
</ul>
<h2 id="数据流过程"><a href="#数据流过程" class="headerlink" title="数据流过程"></a>数据流过程</h2><p><img src="http://note.youdao.com/yws/public/resource/32442f2d923ee4564e15f34e1a33fdd5/69D6BCF5B4A3476898CF5599ED461232" alt="image">  </p>
<ol>
<li>实时数据写入到实时节点,会创建索引结构的Segment  </li>
<li>实时节点的Segment经过一段时间会转存到DeepStorage  </li>
<li>元数据写入MySQL; 实时节点转存的Segment会在ZooKeeper中新增一条记录  </li>
<li>协调节点从MySQL获取元数据,比如schema信息(维度列和指标列)  </li>
<li>协调节点监测ZK中有新分配/要删除的Segment,写入ZooKeeper信息:历史节点需要加载/删除Segment  </li>
<li>历史节点监测ZK, 从ZooKeeper中得到要执行任务的Segment  </li>
<li>历史节点从DeepStorage下载Segment并加载到内存/或者将已经保存的Segment删除掉  </li>
<li>历史节点的Segment可以用于Broker的查询路由  </li>
</ol>
<h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><p>上述流程中的实时节点，换成indexing service，流程基本一致。</p>
<h2 id="容错性"><a href="#容错性" class="headerlink" title="容错性"></a>容错性</h2><h3 id="历史节点挂掉"><a href="#历史节点挂掉" class="headerlink" title="历史节点挂掉"></a>历史节点挂掉</h3><p>该节点就不会服务这个节点上的Segments。<br>但是只要这些Segments仍然存在于DeepStorage,其他节点就会下载它们并服务这些Segments。   </p>
<p>可以从集群中移除所有的历史节点,并且重新发布它们,也不会有任何的数据损失(因为数据最终都保存到DeepStorage中)</p>
<h3 id="DeepStorage不可用"><a href="#DeepStorage不可用" class="headerlink" title="DeepStorage不可用"></a>DeepStorage不可用</h3><p>历史节点上已经加载了DeepStorage的Segments,仍然可用于查询。<br>但是新进来的数据无法进入到集群中(DS挂掉)。</p>
<h3 id="协调节点挂掉"><a href="#协调节点挂掉" class="headerlink" title="协调节点挂掉"></a>协调节点挂掉</h3><p>数据的拓扑(data topology)停止服务,就不会有新的数据以及数据的负载均衡。因为协调节点会通知历史节点下载新数据。   </p>
<p>如果实时节点将Segment转存到DeepStorage,而没有历史节点去下载这些数据,会导致实时节点最终会丢弃这份过期的数据。</p>
<h3 id="Broker挂掉"><a href="#Broker挂掉" class="headerlink" title="Broker挂掉"></a>Broker挂掉</h3><p>还会有其他的Broker接管请求,但是要至少保证有多余的Broker。<br>当然如果不向Broker发送请求,而只关心最新的实时数据,可以直接访问实时节点. 不过这种情况是很少见的.</p>
<h3 id="实时节点"><a href="#实时节点" class="headerlink" title="实时节点"></a>实时节点</h3><p>根据发送流的语义,可以有多个实时节点或者tranquility同时运行,处理同一个输入流,每个实时节点分担输入流的一部分数据.</p>
<h3 id="元数据存储挂掉"><a href="#元数据存储挂掉" class="headerlink" title="元数据存储挂掉"></a>元数据存储挂掉</h3><p>协调节点就无法找到集群中新的Segments(因为新的Segment一定会写入记录到元数据存储中)。但仍然可以提供当前集群的数据视图.</p>
<h3 id="ZooKeeper挂掉"><a href="#ZooKeeper挂掉" class="headerlink" title="ZooKeeper挂掉"></a>ZooKeeper挂掉</h3><p>数据拓扑不会被更新(同协调节点挂掉),但是Broker仍然可以维护最近的数据拓扑,并继续提供查询的服务。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://druid.io/docs/0.9.1.1/design/index.html" target="_blank" rel="external">druid.io</a><br><a href="http://druidio.cn/docs/0.9.0/design/" target="_blank" rel="external">druidio.cn</a><br><a href="http://lxw1234.com/archives/2015/11/563.htm" target="_blank" rel="external">lxw的大数据田地–Druid.io实时OLAP数据分析存储系统介绍</a><br><a href="http://dj1211.com/?p=702" target="_blank" rel="external">萌の宇博客–realtime node与index server区别</a><br><a href="http://zqhxuyuan.github.io/2015/12/03/2015-12-03-Druid-Design/#Concepts" target="_blank" rel="external">zqhxuyuan博客–Druid OLAP架构设计</a></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[druid.io 1---OLAP概念]]></title>
      <url>https://fangyeqing.github.io/2016/10/29/druid.io_1---OLAP%E6%A6%82%E5%BF%B5/</url>
      <content type="html"><![CDATA[<excerpt in="" index="" |="" 首页摘要="">   

<h2 id="OLAP"><a href="#OLAP" class="headerlink" title="OLAP"></a>OLAP</h2><ul>
<li>OLAP的主要特点是直接仿照用户的多角度思考模式，预先为用户组建多维的数据模型。</li>
<li>维指的是用户的分析角度，例如对销售数据的分析，时间周期是一个维度，产品类别、分销渠道、地理分布、客户群类也分别是不同的维度。  </li>
<li>一旦多维数据模型建立完成，用户可以快速地从各个分析角度获取数据，也能动态地在各个角度之间切换数据或者进行多角度综合分析，具有极大的分析灵活性。</li>
</ul>
<a id="more"></a>  
<the rest="" of="" contents="" |="" 余下全文=""> 

<h3 id="主要名词"><a href="#主要名词" class="headerlink" title="主要名词"></a>主要名词</h3><ul>
<li>维(Dimension)：是用户观察数据的特定角度，是问题的一类属性，属性集合构成一个维(时间维、地理维等)。</li>
<li>维的层次(Level)：用户观察数据的某个特定角度(即某个维)还可能存在细节程度不同的各个描述方面(时间维包括日期、月份、季度、年)。  </li>
<li>维的成员(Member)：即维的一个取值，是数据项在某个维中位置的描述，如“某年某月某日”是在时间维上的位置描述。  </li>
<li>度量(Measure)：多维数组的取值。  </li>
</ul>
<h3 id="多维分析操作"><a href="#多维分析操作" class="headerlink" title="多维分析操作"></a>多维分析操作</h3><ul>
<li>钻取（Drill-up和Drill-down）：改变维的层次，变换分析的粒度。它包括向下钻取(Drill-down)和向上钻取(Drill-up)/上滚(Roll-up)。向上钻取是在某一维上将低层次的细节数据概括到高层次的汇总数据，或者减少维数;而向下钻取则相反，从汇总数据深入到细节数据进行观察或增加新维。  </li>
<li>切片和切块（Slice&amp;Dice）：在一部分维上选定值后，关心度量数据在剩余维上的分布。如果剩余的维只有两个，则是切片;如果有三个或以上，则是切块。  </li>
<li>旋转（Pivot）：变换维的方向，即在表格中重新安排维的放置(如行列互换)。</li>
</ul>
<h3 id="与OLTP区别"><a href="#与OLTP区别" class="headerlink" title="与OLTP区别"></a>与OLTP区别</h3><ul>
<li>联机事务处理OLTP（on-line transaction processing）：<br>传统的关系型数据库的主要应用，主要是基本的、日常的事务处理，例如银行交易。  </li>
<li>联机分析处理OLAP（On-Line Analytical Processing）：<br>数据仓库系统的主要应用，支持复杂的分析操作，侧重决策支持，并且提供直观易懂的查询结果。   </li>
</ul>
<table>
<thead>
<tr>
<th>比较</th>
<th>OLTP</th>
<th>OLAP</th>
</tr>
</thead>
<tbody>
<tr>
<td>用户</td>
<td>操作人员,低层管理人员</td>
<td>决策人员,高级管理人员</td>
</tr>
<tr>
<td>功能</td>
<td>日常操作处理</td>
<td>分析决策</td>
</tr>
<tr>
<td>DB设计</td>
<td>面向应用</td>
<td>面向主题</td>
</tr>
<tr>
<td>数据</td>
<td>当前的, 最新的细节的,二维的分立的</td>
<td>历史的, 聚集的, 多维的集成的, 统一的</td>
</tr>
<tr>
<td>存</td>
<td>简单快速的insert和update</td>
<td>定期批量任务更新</td>
</tr>
<tr>
<td>取</td>
<td>简单的读取少量结果</td>
<td>读取大量结果并做聚合操作</td>
</tr>
<tr>
<td>工作单位</td>
<td>简单的事务</td>
<td>复杂的查询</td>
</tr>
<tr>
<td>用户数</td>
<td>上千个</td>
<td>上百个</td>
</tr>
<tr>
<td>DB 大小</td>
<td>100MB-GB</td>
<td>100GB-TB</td>
</tr>
<tr>
<td>主要应用</td>
<td>数据库</td>
<td>数据仓库</td>
</tr>
</tbody>
</table>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://datawarehouse4u.info/OLTP-vs-OLAP.html" target="_blank" rel="external">http://datawarehouse4u.info/OLTP-vs-OLAP.html</a><br><a href="http://www.voidcn.com/blog/nisjlvhudy/article/p-3330989.html" target="_blank" rel="external">http://www.voidcn.com/blog/nisjlvhudy/article/p-3330989.html</a></p>
</the></excerpt>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[kafka---部署]]></title>
      <url>https://fangyeqing.github.io/2016/10/28/kafka---%E9%83%A8%E7%BD%B2/</url>
      <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br>Kafka是一种分布式的消息系统。本文基于0.9.0版本，利用自带的zookeeper，部署了3个broker节点的kafka集群。</excerpt></p>
<h2 id="下载、配置"><a href="#下载、配置" class="headerlink" title="下载、配置"></a>下载、配置</h2><p>下载or拷贝<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">wget http://mirrors.cnnic.cn/apache/kafka/0.9.0.0/kafka_2.11-0.9.0.0.tgz</div><div class="line">tar -xzf kafka_2.11-0.9.0.0.tgz</div><div class="line">cd kafka_2.11-0.9.0.0</div></pre></td></tr></table></figure></p>
<a id="more"></a>  
<the rest="" of="" contents="" |="" 余下全文=""> 

<h2 id="启动zookeeper"><a href="#启动zookeeper" class="headerlink" title="启动zookeeper"></a>启动zookeeper</h2><ul>
<li><p>config/zookeeper.properties,配置可以改数据目录，端口可以不改</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">dataDir=data/zookeeper              #数据目录，默认/tmp/zookeeper</div><div class="line">clientPort=2181                     #默认2181</div></pre></td></tr></table></figure>
</li>
<li><p>启动zk</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">nohup bin/zookeeper-server-start.sh config/zookeeper.properties &gt;&gt; zk.log &amp;</div></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="启动kafka-broker"><a href="#启动kafka-broker" class="headerlink" title="启动kafka-broker"></a>启动kafka-broker</h2><h3 id="broker配置"><a href="#broker配置" class="headerlink" title="broker配置"></a>broker配置</h3><ul>
<li>配置可以改一下日志目录，端口冲突了可以改一下端口。</li>
<li>kafka配置：config/server.properties<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">log.dirs=data/kafka-logs            #数据目录，默认/tmp/kafka-logs</div><div class="line">broker.id=0</div><div class="line">listeners=PLAINTEXT://:9092         #默认PLAINTEXT://:9092</div><div class="line">port=9092                           #端口默认为9092</div><div class="line">zookeeper.connect=localhost:2181    #zk连接信息</div><div class="line">delete.topic.enable=true            #在最后添加：可以删除topic</div></pre></td></tr></table></figure>
</li>
</ul>
<p>另外两个broker配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cp config/server.properties config/server-1.properties</div><div class="line">cp config/server.properties config/server-2.properties</div></pre></td></tr></table></figure></p>
<p>config/server-1.properties:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">broker.id=1</div><div class="line">port=9093</div><div class="line">listeners=PLAINTEXT://:9093</div><div class="line">log.dir=data/kafka-logs-1</div></pre></td></tr></table></figure></p>
<p>config/server-2.properties:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">broker.id=2</div><div class="line">port=9094</div><div class="line">listeners=PLAINTEXT://:9094</div><div class="line">log.dir=data/kafka-logs-2</div><div class="line">```   </div><div class="line">### 启动broker</div></pre></td></tr></table></figure></p>
<p>nohup bin/kafka-server-start.sh config/server.properties &gt;&gt; broker1.log &amp;<br>nohup bin/kafka-server-start.sh config/server-1.properties &gt;&gt; broker2.log &amp;<br>nohup bin/kafka-server-start.sh config/server-2.properties &gt;&gt; broker3.log &amp;<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">## 创建topic</div><div class="line">- 创建topic：</div></pre></td></tr></table></figure></p>
<p>bin/kafka-topics.sh –create –zookeeper localhost:2181 –partitions 3 –topic test3partitions –replication-factor 1  #包含3个分区，1个副本<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">为Topic创建分区时，分区数最好是broker数量的整数倍,这样才能是一个Topic的分区均匀的分布在整个Kafka集群中。  </div><div class="line"></div><div class="line">- 查看已经创建的topic：</div></pre></td></tr></table></figure></p>
<p>bin/kafka-topics.sh –list –zookeeper localhost:2181<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">- 查看某个topic：</div></pre></td></tr></table></figure></p>
<p>bin/kafka-topics.sh –describe –zookeeper localhost:2181 –topic test3partitions<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">- 删除topic：</div></pre></td></tr></table></figure></p>
<p>bin/kafka-topics.sh –delete –topic test3partitions –zookeeper localhost:2181<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">## producer</div><div class="line">在一终端A启动producer</div></pre></td></tr></table></figure></p>
<p>bin/kafka-console-producer.sh –broker-list localhost:9092,localhost:9093,localhost:9094 –topic test3partitions<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">## consumer</div><div class="line">config/consumer.properties修改：</div></pre></td></tr></table></figure></p>
<p>zookeeper.connect=localhost:2181    #zookeeper，后面以host:port,host port,….<br>group.id=test-consumer-group          #消费者group-id<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">在另外的终端B、C、D启动consumer：</div></pre></td></tr></table></figure></p>
<p>bin/kafka-console-consumer.sh –zookeeper localhost:2181 –topic test3partitions</p>
<p>bin/kafka-console-consumer.sh –zookeeper localhost:2181 –consumer.config config/consumer.properties –topic test3partitions</p>
<p>bin/kafka-console-consumer.sh –zookeeper localhost:2181 –consumer.config config/consumer.properties –topic test3partitions</p>
<p>bin/kafka-console-consumer.sh –zookeeper localhost:2181 –consumer.config config/consumer.properties –topic test3partitions<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">后面加 --from-beginning表示从头开始收消息</div><div class="line"></div><div class="line">其中，B终端不配置group-id,将会为console-consumer-，加上随机数字。C、D、E终端读取配置文件中的group.id，为tet-consumer-group。</div><div class="line"></div><div class="line">### 测试</div><div class="line">在producer终端输入消息从1-20。可以看到B终端会输出1-20全部消息，图中B所示。而C、D、E终端由于属于同一个Consumer Group，partitions数量等于consumer，每个consumer消费了一个partition里的消息。图中为C、D、E。</div><div class="line"></div><div class="line">将C终端断开，剩下B、D、E去消费消息。B终端还是会输出1-20全部消息，图中为B1所示。而D、E属于同一个Consumer Group，且consumer数量少于partition数，可以看到D消费了两个partition中的数据，见图中D1所示。    </div><div class="line">![image](http://note.youdao.com/yws/public/resource/027eae2659928c104735afa6fe77369a/xmlnote/A6002CC243CC471FBF51E6BFDE0E1BA2/23687)  </div><div class="line"></div><div class="line">### Java api 测试</div><div class="line">利用Java api自己写一个与上面测试用例相同的例子。</div><div class="line"></div><div class="line">Producer</div></pre></td></tr></table></figure></p>
<p>public class NewProducerSimple {<br>    public static void main(String [] args) {<br>        Properties props = new Properties();<br>        props.put(“bootstrap.servers”, “localhost:9092,localhost:9093,localhost:9094”);<br>        props.put(“acks”, “all”);<br>        props.put(“retries”, 0);<br>        props.put(“batch.size”, 16384);<br>        props.put(“linger.ms”, 1);<br>        props.put(“buffer.memory”, 33554432);<br>        props.put(“key.serializer”, “org.apache.kafka.common.serialization.StringSerializer”);<br>        props.put(“value.serializer”, “org.apache.kafka.common.serialization.StringSerializer”);<br>        props.put(“partitioner.class”,”com.youdao.newClient.SimplePartitioner”);<br>        Producer<string, string=""> producer = new KafkaProducer&lt;&gt;(props);<br>        for(int i = 0; i &lt; 20; i++)<br>            producer.send(new ProducerRecord<string, string="">(“test3partitions”, Integer.toString(i), Integer.toString(i)));</string,></string,></p>
<pre><code>    producer.close();
}
</code></pre><p>}<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">分区规则，key.hash%3</div></pre></td></tr></table></figure></p>
<p>public class SimplePartitioner implements Partitioner {</p>
<pre><code>@Override
public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
    int partitionNum = 3;
    String k = (String)key;
    int partition = Math.abs(k.hashCode()) % partitionNum;
    return partition;
}
@Override
public void close() {
}
@Override
public void configure(Map&lt;String, ?&gt; map) {
}
</code></pre><p>}<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Consumer,同样，可以启动3个相同的consumer</div></pre></td></tr></table></figure></p>
<p>public class NewConsumerSimple {<br>    public static void main(String [] args) {<br>        Properties props = new Properties();<br>        props.put(“bootstrap.servers”, “localhost:9092,localhost:9093,localhost:9094”);<br>        props.put(“group.id”, “test”);<br>        props.put(“enable.auto.commit”, “true”);<br>        props.put(“auto.commit.interval.ms”, “1000”);<br>        props.put(“key.deserializer”, “org.apache.kafka.common.serialization.StringDeserializer”);<br>        props.put(“value.deserializer”, “org.apache.kafka.common.serialization.StringDeserializer”);<br>        KafkaConsumer<string, string=""> consumer = new KafkaConsumer&lt;&gt;(props);<br>        consumer.subscribe(Arrays.asList(“test3partitions”));<br>        while (true) {<br>            ConsumerRecords<string, string=""> records = consumer.poll(100);<br>            for (ConsumerRecord<string, string=""> record : records)<br>                System.out.printf(“offset = %d, key = %s, value = %s%n”, record.offset(), record.key(), record.value());<br>        }<br>    }<br>}<br>```</string,></string,></string,></p>
</the>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[kafka---介绍]]></title>
      <url>https://fangyeqing.github.io/2016/10/28/kafka---%E4%BB%8B%E7%BB%8D/</url>
      <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br>Kafka是一种分布式的消息系统。本文基于0.9.0版本，新版kafka加入了流处理组件kafka stream，最新的官方文档又自称分布式流处理平台。</excerpt></p>
<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><ul>
<li>Broker<br>Kafka的节点。kafka集群包含一个或多个broker</li>
<li>Producer<br>消息的生产者。负责发布消息到Kafka broker</li>
</ul>
<a id="more"></a>  
<the rest="" of="" contents="" |="" 余下全文="">   

<ul>
<li>Consumer<br>消息的消费者。每个consumer属于一个特定的consumer group（若不指定group id则属于默认的group）。使用consumer high level API时，同一topic的一条消息只能被同一个consumer group内的一个consumer消费，但多个consumer group可同时消费这一消息。</li>
<li>Topic<br>消息主题。例如pv日志、click日志、转化日志都可以作为topic。</li>
<li>Partition<br>topic物理上的分组。每个topic包含一个或多个partition，创建topic时可指定parition数量。每个partition是一个有序的队列，对应于一个文件夹，该文件夹下存储该partition的数据和索引文件。在发送一条消息时，生产者可以指定这条消息的key和分区机制来发送到不同的分区。</li>
<li>offset<br>每个partition中的每条消息被分配的有序id，是消息的唯一标识。每个partition都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partition中。<h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><img src="http://kafka.apache.org/090/images/producer_consumer.png" alt="image"><br>producers(生产者)通过网络将不同topic的messages(消息)发送到Kafka 集群，consumers(消费者)在集群订阅自己想要消费的topic。</li>
</ul>
<p>一个典型的kafka集群中包含若干producer（可以是web前端产生的page view，或者是服务器日志，系统CPU、memory等），若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干consumer group，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在consumer group发生变化时进行rebalance。producer使用push模式将消息发布到broker，consumer使用pull模式从broker订阅并消费消息。 　</p>
<h2 id="topic-amp-amp-partitions"><a href="#topic-amp-amp-partitions" class="headerlink" title="topic&amp;&amp;partitions"></a>topic&amp;&amp;partitions</h2><p>对于每个Topic，Kafka会为其维护一个如下图所示的分区的日志文件<br><img src="http://kafka.apache.org/090/images/log_anatomy.png" alt="image"><br>每个partition(分区)是一个有序的、不可修改的消息组成的队列；这些消息是被不断的appended到这个commit log（提交日志文件）上的。在这些patitions之中的每个消息都会被赋予一个叫做offset的顺序id编号，用来在partition之中唯一性的标示这个消息。</p>
<p>Kafka集群会保存一个时间段内所有被发布出来的信息，无论这个消息是否已经被消费过。</p>
<h3 id="partition内有序"><a href="#partition内有序" class="headerlink" title="partition内有序"></a>partition内有序</h3><p>Kafka仅仅提供提供partition之内的消息的全局有序，在不同的partition之间不能担保。partition的消息有序性加上可以按照指定的key划分消息的partition，这基本上满足了大部分应用的需求。如果你必须要实现一个全局有序的消息队列，那么可以采用Topic只划分1个partition来实现。但是这就意味着你的每个消费组只能有唯一的一个消费者进程。</p>
<h2 id="Consumer-Group"><a href="#Consumer-Group" class="headerlink" title="Consumer Group"></a>Consumer Group</h2><p>每一个consumer实例都属于一个consumer group，每一条消息都会被所有订阅了该topic的consumer group消费。通过group id指定consumer group。</p>
<p>并且使用high-level consumer时，同一个consumer group里只有一个consumer能消费到该消息。  </p>
<p>因为high level不用client关心offset, 会自动的读zookeeper中该Consumer group的last offset，相当于所有consumer都公用这个offset。当其中一个consumer消费一条消息时，offset就移动到下一条。  </p>
<p><img src="http://note.youdao.com/yws/public/resource/027eae2659928c104735afa6fe77369a/xmlnote/41CC44BBC283484B9E01F28C50A8991D/23720" alt="image">  </p>
<h3 id="不同形式的消息播发"><a href="#不同形式的消息播发" class="headerlink" title="不同形式的消息播发"></a>不同形式的消息播发</h3><p>订阅模式:每个Consumer都采用不同的group，每一条消息都会发送给所有消费者<br>消息队列模式:所有的Consumer在同一个Group里，消费者之间负载均衡  </p>
<h2 id="Producer-amp-amp-Consumer-amp-amp-partitions"><a href="#Producer-amp-amp-Consumer-amp-amp-partitions" class="headerlink" title="Producer&amp;&amp;Consumer&amp;&amp;partitions"></a>Producer&amp;&amp;Consumer&amp;&amp;partitions</h2><p>新建topic时，通过–partitions 可以设置分区数。可以指定partitions数为broker的整数倍，这样，每个broker会对应相同个数的partitions。</p>
<p>生产者在生产数据的时候，可以为每条消息指定Key，这样消息被发送到broker时，会根据分区规则选择被存储到哪一个partitions中。如果分区规则设置的合理，那么所有的消息将会被均匀的分布到不同的partitions中，这样就实现了负载均衡和水平扩展。</p>
<p>Kafka保证同一consumer group中只有一个consumer会消费某条消息，实际上，Kafka保证的是稳定状态下每一个consumer实例只会消费某一个或多个特定partition的数据，而某个partition的数据只会被某一个特定的consumer实例所消费。其中consumer和partition数量关系如下表所示：</p>
<table>
<thead>
<tr>
<th>consumer和partition数量关系</th>
<th>消费情况</th>
</tr>
</thead>
<tbody>
<tr>
<td>小于</td>
<td>至少有一个consumer会消费多个partition的数据</td>
</tr>
<tr>
<td>相等</td>
<td>一个consumer消费一个partition的数据</td>
</tr>
<tr>
<td>大于</td>
<td>部分consumer无法消费该topic下任何一条消息，浪费</td>
</tr>
</tbody>
</table>
<p>增减consumer，broker，partition会导致rebalance，rebalance后consumer对应的partition会发生变化，在后面的实例中也可以看到。</p>
<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>利用kafka中自带的生产者和消费者例子来做个简单的测试。具体步骤在另一篇kakfa部署。</p>
<p>kafka集群有3个broker节点。新建一个partitions数量为3的topic。启动一个A终端为生产者，启动B、C、D、E终端为消费者。C、D、E终端为一个consumer group，B为单独的一个consumer group。</p>
<p>在producer终端输入消息从1-20。可以看到B终端会输出1-20全部消息，图中B所示。而C、D、E终端由于属于同一个Consumer Group，partitions数量等于consumer，每个consumer消费了一个partition里的消息。图中为C、D、E。</p>
<p>将C终端断开，剩下B、D、E去消费消息。B终端还是会输出1-20全部消息，图中为B1所示。而D、E属于同一个Consumer Group，且consumer数量少于partition数，可以看到D消费了两个partition中的数据，见图中D1所示。<br><img src="http://note.youdao.com/yws/public/resource/027eae2659928c104735afa6fe77369a/xmlnote/A6002CC243CC471FBF51E6BFDE0E1BA2/23687" alt="image">  </p>
<h2 id="Replication-amp-amp-broker节点故障处理"><a href="#Replication-amp-amp-broker节点故障处理" class="headerlink" title="Replication&amp;&amp;broker节点故障处理"></a>Replication&amp;&amp;broker节点故障处理</h2><h3 id="Replication"><a href="#Replication" class="headerlink" title="Replication"></a>Replication</h3><p>replication策略是基于partition。kafka通过创建topic时可以通过–replication-factor配置partition副本数。配置副本之后,每个partition都有一个唯一的leader，有0个或多个follower。</p>
<p>所有的读写操作都在leader上完成，leader批量从leader上pull数据。followers从leader消费消息来复制message，就跟普通的consumer消费消息一样。</p>
<p>一般情况下partition的数量大于等于broker的数量，并且所有partition的leader均匀分布在broker上。</p>
<h3 id="follower故障处理"><a href="#follower故障处理" class="headerlink" title="follower故障处理"></a>follower故障处理</h3><p>broker是否alive包含两个条件：</p>
<ul>
<li>一是它必须维护与Zookeeper的session(这个通过Zookeeper的heartbeat机制来实现)。</li>
<li>二是follower必须能够及时将leader的writing复制过来，不能“落后太多”。</li>
</ul>
<p>leader会track“in sync”的node list。如果一个follower宕机，或者落后太多，leader将把它从”in sync” list中移除。</p>
<p>一条消息只有被“in sync” list里的所有follower都从leader复制过去才会被认为已提交。这样就避免了部分数据被写进了leader，还没来得及被任何follower复制就宕机了，而造成数据丢失（consumer无法消费这些数据）</p>
<p>而对于producer而言，它可以选择是否等待消息commit，这可以通过producer的“acks”来设置。默认为acks=all ，这意味着leader将等待所有follower复制完消息。</p>
<h3 id="leader故障处理"><a href="#leader故障处理" class="headerlink" title="leader故障处理"></a>leader故障处理</h3><p>leader挂掉后，怎样在follower中选举出新的leader？</p>
<p>Kafka在Zookeeper中动态维护了一个ISR（in-sync replicas） set，这个set里的所有replica都跟上了leader，只有ISR里的成员才有被选为leader的可能。</p>
<p>如果某一个partition的所有replica都挂了，就无法保证数据不丢失了。这种情况下有两种可行的方案：</p>
<ul>
<li>一致性高：等待ISR中的任一个replica“活”过来，并且选它作为leader。可能会等待比较长的时间</li>
<li>可用性高：选择第一个“活”过来的replica（不一定是ISR中的）作为leader。有可能会丢失数据</li>
</ul>
<p>kafka采用第二种方案，可以通过配置unclean.leader.election.enable来关闭这种方案。</p>
<h3 id="测试-1"><a href="#测试-1" class="headerlink" title="测试"></a>测试</h3><p>kafka集群有3个broker节点。具体部署在另一篇kafka部署中。</p>
<p>做个简单的测试，创建一个3分区的topic，不指定副本数，可以看到默认一个副本，Partition均匀分布在各broker。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[fangyeqing@xxxx kafka_2.11-0.9.0.0]$bin/kafka-topics.sh --create --zookeeper localhost:2181 --partitions 3 --topic test3partitions</div><div class="line">[fangyeqing@xxxx kafka_2.11-0.9.0.0]$bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic test3partitions</div><div class="line">Topic:test3partitions	PartitionCount:3	ReplicationFactor:1	Configs:</div><div class="line">	Topic: test3partitions	Partition: 0	Leader: 1	Replicas: 1	Isr: 1</div><div class="line">	Topic: test3partitions	Partition: 1	Leader: 2	Replicas: 2	Isr: 2</div><div class="line">	Topic: test3partitions	Partition: 2	Leader: 0	Replicas: 0	Isr: 0</div></pre></td></tr></table></figure></p>
<p>创建一个3分区2副本的topic，可以看到Replicas和Isr中有1个follower。例如Partitions：0的Leader为broker：1,follower为broker：2，并且2在Isr中，理论上当Leader挂掉之后，2会顶上。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[fangyeqing@xxxx kafka_2.11-0.9.0.0]$bin/kafka-topics.sh --create --zookeeper localhost:2181 --partitions 3 --topic test3partition2replication --replication-factor 2</div><div class="line">[fangyeqing@xxxx kafka_2.11-0.9.0.0]$ bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic test3partition2replication</div><div class="line">Topic:test3partition2replication	PartitionCount:3	ReplicationFactor:2	Configs:</div><div class="line">	Topic: test3partition2replication	Partition: 0	Leader: 1	Replicas: 1,2	Isr: 1,2</div><div class="line">	Topic: test3partition2replication	Partition: 1	Leader: 2	Replicas: 2,0	Isr: 2,0</div><div class="line">	Topic: test3partition2replication	Partition: 2	Leader: 0	Replicas: 0,1	Isr: 0,1</div></pre></td></tr></table></figure></p>
<p>创建一个3分区2副本的topic，可以看到Replicas和Isr中有2个follower<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">[fangyeqing@xxxx kafka_2.11-0.9.0.0]$bin/kafka-topics.sh --create --zookeeper localhost:2181 --partitions 3 --topic test3partition3replication --replication-factor 3</div><div class="line">[fangyeqing@xxxx kafka_2.11-0.9.0.0]$ bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic test3partition3replication</div><div class="line">Topic:test3partition3replication	PartitionCount:3	ReplicationFactor:3	Configs:</div><div class="line">	Topic: test3partition3replication	Partition: 0	Leader: 1	Replicas: 1,0,2	Isr: 1,0,2</div><div class="line">	Topic: test3partition3replication	Partition: 1	Leader: 2	Replicas: 2,1,0	Isr: 2,1,0</div><div class="line">	Topic: test3partition3replication	Partition: 2	Leader: 0	Replicas: 0,2,1	Isr: 0,2,1</div></pre></td></tr></table></figure></p>
<h2 id="Message-delivery-guarantees"><a href="#Message-delivery-guarantees" class="headerlink" title="Message delivery guarantees"></a>Message delivery guarantees</h2><p>目前有下面几种消息确保机制：</p>
<ul>
<li>At most once 消息可能会丢，但绝不会重复传输</li>
<li>At least one 消息绝不会丢，但可能会重复传输</li>
<li>Exactly once 每条消息肯定会被传输一次且仅传输一次，很多时候这是用户所想要的。</li>
</ul>
<p>Kafka默认保证At least once，并且允许通过设置producer异步提交来实现At most once。下面分阶段分析：</p>
<h3 id="Producer向broker发送消息"><a href="#Producer向broker发送消息" class="headerlink" title="Producer向broker发送消息"></a>Producer向broker发送消息</h3><p>当Producer向broker发送消息，由上述Replication的分析可知，一旦这条消息已经被commit，如果这个topic有多个replication（副本），某个broker挂掉也不会丢失消息。</p>
<p>Producer发送数据给broker的过程中，如果遇到网络问题而造成通信中断：</p>
<ul>
<li>At least once：Producer就无法判断该条消息是否已经commit，再重复提交时就会是At least once。</li>
<li>Exactly once：在以后的版本中producer可以生成一种类似于primary key的东西，发生故障时幂等性的retry多次</li>
<li>At most once：Producer异步提交来实现At most once</li>
</ul>
<h3 id="Consumer从broker消费消息"><a href="#Consumer从broker消费消息" class="headerlink" title="Consumer从broker消费消息"></a>Consumer从broker消费消息</h3><p>当Consumer从broker消费消息时，consumer如果在消费消息时crash：</p>
<ul>
<li>At least once：读完消息先处理再commit消费状态(保存offset)</li>
<li>At most once：读完消息先commit消费状态(保存offset)再处理消息</li>
<li>Exactly once：需要协调offset和实际操作的输出，目前比较麻烦。</li>
</ul>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://www.jasongj.com/2015/01/02/Kafka%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90/" target="_blank" rel="external">http://www.jasongj.com/2015/01/02/Kafka%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90/</a><br><a href="http://kafkadoc.beanmr.com/010_getting_started/01_introduction_cn.html" target="_blank" rel="external">http://kafkadoc.beanmr.com/010_getting_started/01_introduction_cn.html</a><br><a href="http://tech.meituan.com/kafka-fs-design-theory.html" target="_blank" rel="external">http://tech.meituan.com/kafka-fs-design-theory.html</a>  </p>
</the>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[hexo+github page搭建博客]]></title>
      <url>https://fangyeqing.github.io/2016/10/28/hexo+github_page%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/</url>
      <content type="html"><![CDATA[<excerpt in="" index="" |="" 首页摘要="">   

<h2 id="环境安装"><a href="#环境安装" class="headerlink" title="环境安装"></a>环境安装</h2><p>在windows和linux下都配置了，感觉还是Linux方便一点</p>
<a id="more"></a>  
<the rest="" of="" contents="" |="" 余下全文="">   

<h3 id="node-js环境-windows-linux略"><a href="#node-js环境-windows-linux略" class="headerlink" title="node.js环境(windows,linux略)"></a>node.js环境(windows,linux略)</h3><p><a href="https://nodejs.org/en/download/" target="_blank" rel="external">官方下载地址</a>，选择对应版本，改个安装路径，然后一路下一步。  </p>
<p>安装完成可以在windows命令行，查看是否安装成功。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">node -v</div><div class="line">npm -v</div></pre></td></tr></table></figure></p>
<h3 id="git环境"><a href="#git环境" class="headerlink" title="git环境"></a>git环境</h3><p>略</p>
<h2 id="配置github"><a href="#配置github" class="headerlink" title="配置github"></a>配置github</h2><p><a href="https://github.com/" target="_blank" rel="external">https://github.com/</a></p>
<h3 id="新建repository"><a href="#新建repository" class="headerlink" title="新建repository"></a>新建repository</h3><p>点击<strong>New repository</strong>  </p>
<p><strong>Repository name</strong>下填写博客目录，例如：username.github.io<br><strong>Description</strong>下填写描述，例如：我的博客  </p>
<h3 id="生成github-page"><a href="#生成github-page" class="headerlink" title="生成github page"></a>生成github page</h3><p>创建目录后进入该目录，“<strong>Setting</strong>”进行设置。  </p>
<p>下拉到“<strong>GitHub Pages</strong>”模块，点击“<strong>Launch automatic page generator</strong>”按钮，生成github page。</p>
<p>刚才配置的“username.github.io”已经可以访问了。</p>
<h2 id="Hexo"><a href="#Hexo" class="headerlink" title="Hexo"></a>Hexo</h2><p>linux的cd很简单，但是windows有点坑爹，中间加一个/d。</p>
<p>通过cmd命令行窗口进入到想要安装的目录。当然也可以通过文件系统进入当该目录，shift+右键点进去。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cd /d D:\coding files\Workspace\hexo</div></pre></td></tr></table></figure></p>
<p>然后执行安装命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">npm install hexo-cli -g</div></pre></td></tr></table></figure></p>
<p>等待比较久之后安装完了，会有WARN，但没事，查看是否成功<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hexo -v</div></pre></td></tr></table></figure></p>
<p>初始化。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">hexo init              #不加路径表示当前文件夹作为hexo目录 </div><div class="line">npm install</div><div class="line">hexo generate          #生成静态文件,从source/_post目录将md转成public中的html</div><div class="line">hexo server            #启动本地server，端口4000</div></pre></td></tr></table></figure></p>
<p>到这里已经可以在本地访问到了，<a href="http://localhost:4000" target="_blank" rel="external">http://localhost:4000</a></p>
<h3 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h3><p>修改配置文件：_config.yml。主要配置网站url、deploy到github的地址。每个冒号后面一定要有空格。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"># Site</div><div class="line">title: 小懒的博客</div><div class="line">subtitle:</div><div class="line">description:Re0: 从零开始的程序猿世界</div><div class="line">author: 小懒</div><div class="line">language: zh-Hans</div><div class="line">timezone: Asia/Shanghai</div><div class="line"></div><div class="line"># URL</div><div class="line">url: https://fangyeqing.github.io/</div><div class="line">root: /</div><div class="line"></div><div class="line"># Deployment</div><div class="line">deploy:</div><div class="line">  type: git</div><div class="line">  repo: https://github.com/fangyeqing/fangyeqing.github.io.git</div><div class="line">  branch: master</div></pre></td></tr></table></figure></p>
<h2 id="部署到github-page"><a href="#部署到github-page" class="headerlink" title="部署到github page"></a>部署到github page</h2><p>部署之前安装一下hexo-git部署插件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">npm install hexo-deployer-git --save</div></pre></td></tr></table></figure></p>
<p>部署加-g参数表示部署之前执行生成静态文件操作，相当于<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hexo deploy -g</div></pre></td></tr></table></figure></p>
<h3 id="出现问题"><a href="#出现问题" class="headerlink" title="出现问题"></a>出现问题</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Username for &apos;https://github.com&apos;: error: unable to read askpass response from &apos;/usr/libexec/openssh/gnome-ssh-askpass&apos;</div></pre></td></tr></table></figure>
<p>执行如下指令，或者直接把它加入到.bash_profile中<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">unset SSH_ASKPASS</div></pre></td></tr></table></figure></p>
<h2 id="添加新文章"><a href="#添加新文章" class="headerlink" title="添加新文章"></a>添加新文章</h2><p>source/_post文件夹: 新建md类型的文档,新建的文章头需要添加一些yml信息，如下所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">---</div><div class="line">title: Samza学习</div><div class="line">date: 2016-10-28 17:40:00</div><div class="line">categories: samza</div><div class="line">toc: true</div><div class="line">---</div></pre></td></tr></table></figure></p>
<p>categories：分类<br>toc：设定是否开启目录，需要主题支持。</p>
<p>可以现在本地测试一下，确认没问题再deploy上去<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hexo g</div><div class="line">hexo s</div></pre></td></tr></table></figure></p>
<p>重新发布<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hexo d -g</div></pre></td></tr></table></figure></p>
<h2 id="主题修改"><a href="#主题修改" class="headerlink" title="主题修改"></a>主题修改</h2><p>去<a href="https://github.com/hexojs/hexo/wiki/Themes" target="_blank" rel="external">hexo的github</a>下载主题，放到themes目录下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git clone https://github.com/MOxFIVE/hexo-theme-yelee.git themes/yelee</div></pre></td></tr></table></figure></p>
<p>然后根据<a href="http://moxfive.coding.me/yelee/" target="_blank" rel="external">作者的gitbook</a>修改_config.yml文件，实现各种配置</p>
<p>改完继续重新发布出去</p>
<p>其中比较重要的如下：</p>
<h3 id="评论系统"><a href="#评论系统" class="headerlink" title="评论系统"></a>评论系统</h3><p>利用多说，fangyeqing.duoshuo.com</p>
<h3 id="站内搜索"><a href="#站内搜索" class="headerlink" title="站内搜索"></a>站内搜索</h3><p>需要先安装一个插件，然后修改配置文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">npm install hexo-generator-search --save</div><div class="line"></div><div class="line">#主题配置themes/yelee/_config.yml</div><div class="line">search: </div><div class="line">  on: true</div><div class="line">  onload: false</div><div class="line">#根目录配置_config.yml  </div><div class="line">search:</div><div class="line">  path: search.xml</div><div class="line">  field: all</div></pre></td></tr></table></figure></p>
<h3 id="文章摘要"><a href="#文章摘要" class="headerlink" title="文章摘要"></a>文章摘要</h3><p>在首页显示摘要，非全文<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">---</div><div class="line">title: Hello World</div><div class="line">date: 2015-12-03 00:00:00</div><div class="line">categories: samza</div><div class="line">tags: [samza,学习,hello world] </div><div class="line">toc: true</div><div class="line">---</div><div class="line">&lt;Excerpt in index | 首页摘要&gt; </div><div class="line">摘要内容...</div><div class="line">&lt;!-- more --&gt;</div><div class="line">&lt;The rest of contents | 余下全文&gt;</div><div class="line">余下的全文内容...</div></pre></td></tr></table></figure></p>
<h3 id="关于我"><a href="#关于我" class="headerlink" title="关于我"></a>关于我</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hexo new page about</div></pre></td></tr></table></figure>
<h3 id="标签云"><a href="#标签云" class="headerlink" title="标签云"></a>标签云</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hexo new page tags</div></pre></td></tr></table></figure>
</the></excerpt>]]></content>
    </entry>
    
  
  
    
    <entry>
      <title><![CDATA[about]]></title>
      <url>https://fangyeqing.github.io/about/index.html</url>
      <content type="html"><![CDATA[<p>程序员并不是木头和绝缘体，是有血有肉的逗比</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[tags]]></title>
      <url>https://fangyeqing.github.io/tags/index.html</url>
      <content type="html"></content>
    </entry>
    
  
</search>
